{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework#3V3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Cd0694vpcI8l","colab_type":"code","outputId":"eee7219c-d0ca-4468-aeb9-9646d2c20afd","executionInfo":{"status":"ok","timestamp":1554905522151,"user_tz":-180,"elapsed":2100,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import files, auth, drive\n","from urllib.request import urlopen\n","from typing import List, Dict, Callable\n","from collections import Counter\n","from os import path\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.optim import SGD, Adam\n","from matplotlib import pyplot as plt\n","import glob\n","import json\n","import unicodedata\n","import string\n","\n","############################## CONSTANTS #######################################\n","def findFiles(path): return glob.glob(path)\n","\n","def readfile(filepath: str) -> str:\n","    \"\"\"\n","    Reads file and returns its content as a string.\n","    \"\"\"\n","    #response = urlopen(url)\n","    #body = response.read().decode('utf-8')\n","    with open(filepath, \"r\") as f:\n","        body = f.read()\n","    \n","    return body.encode('ascii', 'ignore').decode(\"utf-8\")\n","\n","ROOT_COLAB_FOLDER = \"/content\"\n","filename = \"train-data.json\" #modify filename here\n","filepath = path.join(ROOT_COLAB_FOLDER, filename)\n","\n","with open(filepath, \"r\") as f:\n","  trainData = json.load(f)\n","\n","\n","filename_gt = \"code-train-gt.json\"\n","filepath_gt = path.join(ROOT_COLAB_FOLDER, filename_gt)\n","\n","with open(filepath_gt, \"r\") as f:\n","  trainData_gt = json.load(f)\n","\n","filename_test = \"test-data.json\" #modify filename here\n","filepath_test = path.join(ROOT_COLAB_FOLDER, filename_test)\n","\n","with open(filepath_test, \"r\") as f:\n","  _testData = json.load(f)\n","\n","\n","filename_test_gt = \"code-test-gt.json\"\n","filepath_test_gt = path.join(ROOT_COLAB_FOLDER, filename_test_gt)\n","\n","with open(filepath_test_gt, \"r\") as f:\n","  testData_gt = json.load(f)\n","\n","languages2Labels = {\n","    \"JavaScript\" : 0,\n","    \"Java\" : 1,\n","    \"SQL\" : 2,\n","    \"Python\" : 3,\n","    \"c++\" : 4,\n","    \"c#\" : 5\n","}\n","nrLanguages = len(languages2Labels.keys())\n","\n","trainData_gt_labels = {}\n","for key, value in trainData_gt.items():\n","  trainData_gt_labels[key] = languages2Labels[value]\n","  \n","print(trainData_gt_labels[\"00025cd483baf04e1862328f61b99f8c40c62da4V_PO_DETAILS_0\"])\n","\n","for key, value in trainData.items():\n","  try:\n","    label = trainData_gt_labels[key] # check for no KeyErrors\n","  except:\n","    print(key)\n","    \n","testData_gt_labels = {}\n","for key, value in testData_gt.items():\n","  testData_gt_labels[key] = languages2Labels[value]"],"execution_count":1,"outputs":[{"output_type":"stream","text":["2\n"],"name":"stdout"}]},{"metadata":{"id":"J7811cUEdhfb","colab_type":"code","outputId":"391db6f1-4232-40e4-bf1e-f2de4c9dc571","executionInfo":{"status":"ok","timestamp":1554905522803,"user_tz":-180,"elapsed":2730,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["class Vocabulary:\n","    \"\"\"\n","    Helper class that maps characters to unique indices and the other way around\n","    \"\"\"\n","    def __init__(self, text: str):\n","        #special character for padding shorter sequences in a mini-batch\n","        characters_set = set(\"<PAD>\") \n","        characters_set.update(text)\n","        \n","        self.char_to_idx = {char:idx for (idx, char) \n","                            in enumerate(characters_set)}\n","        self.idx_to_char = {idx:char for (idx, char) \n","                            in enumerate(characters_set)}\n","   \n","    def size(self):\n","        return len(self.char_to_idx)\n","      \n","    def __str__(self):\n","        return str(self.char_to_idx)\n","\n","text = \"\"\n","for key, value in trainData.items():\n","  text = text + value\n","\n","vocab = Vocabulary(text)\n","print(\"Vocabulary size: \", vocab.size())\n","print(\"Vocabulary: \\n\", vocab)\n","\n","print(len(trainData.keys()))\n","print(len(_testData.keys()))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Vocabulary size:  98\n","Vocabulary: \n"," {'A': 0, 'u': 1, 'a': 2, 'J': 3, 'B': 4, '?': 5, 'N': 6, 'e': 7, 'r': 8, '/': 9, '`': 10, '2': 11, 'R': 12, 'h': 13, '1': 14, '_': 15, 'f': 16, ']': 17, '3': 18, 'I': 19, 'n': 20, '=': 21, 'q': 22, 'K': 23, '9': 24, 'F': 25, 'd': 26, 'P': 27, '}': 28, 'E': 29, '#': 30, '*': 31, 'i': 32, 'x': 33, 'p': 34, '8': 35, 't': 36, '^': 37, '[': 38, '\\\\': 39, 'o': 40, '{': 41, 'G': 42, 'l': 43, '(': 44, '|': 45, ' ': 46, 'w': 47, '4': 48, ':': 49, 'X': 50, 'b': 51, '-': 52, '\\x01': 53, 'y': 54, '.': 55, '>': 56, 'C': 57, 'Z': 58, 'v': 59, '@': 60, 'j': 61, 'Y': 62, '\\t': 63, '~': 64, ';': 65, 'W': 66, 'k': 67, 'g': 68, '$': 69, 'c': 70, 'z': 71, 'M': 72, '<': 73, 'O': 74, 'T': 75, '6': 76, '%': 77, 'H': 78, '0': 79, 'Q': 80, '\\n': 81, 'U': 82, '5': 83, '+': 84, 's': 85, '7': 86, 'V': 87, 'L': 88, \"'\": 89, '!': 90, ',': 91, '\"': 92, '&': 93, ')': 94, 'D': 95, 'm': 96, 'S': 97}\n","11100\n","2995\n"],"name":"stdout"}]},{"metadata":{"id":"NwB6tcHqdlA8","colab_type":"code","outputId":"1961be31-df32-492a-938d-997909fe8a1f","executionInfo":{"status":"ok","timestamp":1554905529037,"user_tz":-180,"elapsed":8945,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["def text_to_tensor(text: str, vocab: Vocabulary) -> torch.LongTensor:\n","    \"\"\"\n","    Convert a string to a Tensor with corresponding character indices\n","    e.g. \"We have\" -> [12, 6, 20, 13, 1, 25, 6] \n","    \"\"\"\n","    text_indices = [vocab.char_to_idx[c] for c in text]\n","    \n","    return torch.tensor(text_indices)\n","  \n","def tensor_to_text(x: torch.LongTensor, vocab: Vocabulary) -> str:\n","    \"\"\"\n","    Convert a Tensor of character indices to its string representation\n","    e.g. [12, 6, 20, 13, 1, 25, 6] -> \"We have\"\n","    \"\"\"\n","    return \"\".join(vocab.idx_to_char[idx.item()] for idx in x)\n","\n","def batch_tensor_to_text(x: torch.LongTensor, vocab: Vocabulary) -> List[str]:\n","    \"\"\"\n","    The batched version of tensor_to_text\n","    E.g. [[2, 1, 3, 0, 0], [3, 1, 20]] -> [bac, cat]\n","    :param x: Tensor of size (batch_size x time_steps)\n","    :return: a list of corresponding strings \n","    \"\"\"\n","    assert len(x.size()) == 2, \"wrong number of dimensions (should be 2)\"\n","    outputs = []\n","    for batch_idx in range(len(x)):\n","        outputs.append(tensor_to_text(x[batch_idx], vocab))\n","            \n","    return outputs \n","  \n","#check that a random text is correctly converted to numbers and back to text\n","random_text = \"I have apples\"\n","encoded_text = text_to_tensor(random_text, vocab)\n","decoded_text = tensor_to_text(encoded_text, vocab)\n","assert random_text == decoded_text, \"Not the same text as the original\"\n","print(encoded_text)\n","print(decoded_text)\n","\n","#convert input text to numbers\n","data = {}\n","for key, value in trainData.items():\n","  data[key] = text_to_tensor(value, vocab)\n","  #print(\"Size of input tensor is: \", data[key].size(0))\n","  \n","#convert input text to numbers\n","testData = {}\n","for key, value in _testData.items():\n","  testData[key] = text_to_tensor(value, vocab)\n","\n","#setup device (CPU/GPU)\n","if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')\n","\n","print(device)\n","#move tensor to CUDA if available\n","for key, value in data.items(): # move data\n","  data[key] = data[key].to(device)\n","\n","for key, value in testData.items(): # move data\n","  testData[key] = testData[key].to(device)\n","\n","for key, value in trainData_gt_labels.items(): # also move labels and convert to tensor\n","  trainData_gt_labels[key] = torch.ones(1).to(device) * trainData_gt_labels[key]\n","\n","for key, value in testData_gt_labels.items(): # also move labels and convert to tensor\n","  testData_gt_labels[key] = torch.ones(1).to(device) * testData_gt_labels[key]"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([19, 46, 13,  2, 59,  7, 46,  2, 34, 34, 43,  7, 85])\n","I have apples\n","cuda:0\n"],"name":"stdout"}]},{"metadata":{"id":"s1v8RKHLduRN","colab_type":"code","outputId":"8a62b62f-5572-4c32-d670-5e8671a86e18","executionInfo":{"status":"ok","timestamp":1554905530466,"user_tz":-180,"elapsed":10356,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":17663}},"cell_type":"code","source":["# CREATE TENSORS OF THE BATCHES - FOR TRAIN\n","# Will have 2 dicts : batches_x and batches_y, mapping from batchNumber to a tensor\n","\n","keys = list(data.keys())\n","nrKeys = len(keys)\n","\n","#from random import shuffle\n","\n","#shuffle(keys)\n","\n","batch_size = 32\n","max_len = 250\n","\n","nrBatches = nrKeys // batch_size\n","batches_x = {}\n","batches_y = {}\n","for i in range(nrBatches):\n","  currentKeys = keys[i*batch_size : (i+1)*batch_size]\n","  batch_x = torch.Tensor(())\n","  batch_x = batch_x.to(device)\n","  batch_y = torch.Tensor(())\n","  batch_y = batch_y.to(device)\n","  for j in range(batch_size):\n","    current_x = data[currentKeys[j]][:max_len]\n","    current_x = current_x.view((1, max_len))\n","    \n","    current_y = trainData_gt_labels[currentKeys[j]]\n","    ##current_y = current_y.view((1, 1))\n","    #current_y = torch.zeros((1, nrLanguages))\n","    #current_y[0, trainData_gt_labels[currentKeys[j]].long()] = 1\n","    #current_y = current_y.to(device)\n","    \n","    batch_x = torch.cat((batch_x, current_x.float()), 0)\n","    batch_y = torch.cat((batch_y, current_y.float()), 0)\n","  \n","  batches_x[i] = batch_x\n","  batches_y[i] = batch_y\n","  print(batch_x.shape)\n","  print(batch_y.shape)\n","  print(i, 'out of', nrBatches)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([32, 250])\n","torch.Size([32])\n","0 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","1 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","2 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","3 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","4 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","5 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","6 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","7 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","8 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","9 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","10 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","11 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","12 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","13 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","14 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","15 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","16 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","17 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","18 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","19 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","20 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","21 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","22 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","23 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","24 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","25 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","26 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","27 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","28 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","29 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","30 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","31 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","32 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","33 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","34 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","35 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","36 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","37 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","38 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","39 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","40 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","41 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","42 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","43 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","44 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","45 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","46 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","47 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","48 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","49 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","50 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","51 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","52 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","53 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","54 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","55 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","56 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","57 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","58 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","59 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","60 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","61 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","62 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","63 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","64 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","65 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","66 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","67 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","68 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","69 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","70 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","71 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","72 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","73 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","74 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","75 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","76 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","77 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","78 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","79 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","80 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","81 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","82 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","83 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","84 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","85 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","86 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","87 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","88 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","89 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","90 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","91 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","92 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","93 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","94 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","95 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","96 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","97 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","98 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","99 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","100 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","101 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","102 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","103 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","104 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","105 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","106 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","107 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","108 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","109 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","110 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","111 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","112 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","113 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","114 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","115 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","116 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","117 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","118 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","119 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","120 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","121 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","122 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","123 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","124 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","125 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","126 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","127 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","128 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","129 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","130 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","131 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","132 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","133 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","134 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","135 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","136 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","137 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","138 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","139 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","140 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","141 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","142 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","143 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","144 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","145 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","146 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","147 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","148 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","149 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","150 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","151 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","152 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","153 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","154 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","155 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","156 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","157 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","158 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","159 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","160 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","161 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","162 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","163 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","164 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","165 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","166 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","167 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","168 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","169 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","170 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","171 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","172 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","173 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","174 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","175 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","176 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","177 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","178 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","179 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","180 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","181 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","182 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","183 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","184 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","185 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","186 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","187 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","188 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","189 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","190 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","191 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","192 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","193 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","194 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","195 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","196 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","197 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","198 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","199 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","200 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","201 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","202 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","203 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","204 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","205 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","206 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","207 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","208 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","209 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","210 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","211 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","212 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","213 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","214 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","215 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","216 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","217 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","218 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","219 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","220 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","221 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","222 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","223 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","224 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","225 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","226 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","227 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","228 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","229 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","230 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","231 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","232 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","233 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","234 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","235 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","236 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","237 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","238 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","239 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","240 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","241 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","242 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","243 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","244 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","245 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","246 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","247 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","248 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","249 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","250 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","251 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","252 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","253 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","254 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","255 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","256 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","257 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","258 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","259 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","260 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","261 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","262 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","263 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","264 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","265 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","266 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","267 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","268 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","269 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","270 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","271 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","272 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","273 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","274 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","275 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","276 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","277 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","278 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","279 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","280 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","281 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","282 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","283 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","284 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","285 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","286 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","287 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","288 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","289 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","290 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","291 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","292 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","293 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","294 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","295 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","296 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","297 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","298 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","299 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","300 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","301 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","302 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","303 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","304 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","305 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","306 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","307 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","308 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","309 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","310 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","311 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","312 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","313 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","314 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","315 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","316 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","317 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","318 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","319 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","320 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","321 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","322 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","323 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","324 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","325 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","326 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","327 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","328 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","329 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","330 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","331 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","332 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","333 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","334 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","335 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","336 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","337 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","338 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","339 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","340 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","341 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","342 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","343 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","344 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","345 out of 346\n"],"name":"stdout"}]},{"metadata":{"id":"UbiRw5INdzz2","colab_type":"code","outputId":"ca693eca-93ba-4439-b93a-9e316fb567aa","executionInfo":{"status":"ok","timestamp":1554905532000,"user_tz":-180,"elapsed":11862,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":17663}},"cell_type":"code","source":["# CREATE TENSORS OF THE BATCHES - FOR TRAIN\n","# Will have 2 dicts : batches_x and batches_y, mapping from batchNumber to a tensor\n","\n","keys = list(data.keys())\n","nrKeys = len(keys)\n","\n","#from random import shuffle\n","\n","#shuffle(keys)\n","\n","batch_size = 32\n","max_len = 250\n","\n","nrBatches = nrKeys // batch_size\n","batches_x = {}\n","batches_y = {}\n","for i in range(nrBatches):\n","  currentKeys = keys[i*batch_size : (i+1)*batch_size]\n","  batch_x = torch.Tensor(())\n","  batch_x = batch_x.to(device)\n","  batch_y = torch.Tensor(())\n","  batch_y = batch_y.to(device)\n","  for j in range(batch_size):\n","    current_x = data[currentKeys[j]][:max_len]\n","    current_x = current_x.view((1, max_len))\n","    \n","    current_y = trainData_gt_labels[currentKeys[j]]\n","    ##current_y = current_y.view((1, 1))\n","    #current_y = torch.zeros((1, nrLanguages))\n","    #current_y[0, trainData_gt_labels[currentKeys[j]].long()] = 1\n","    #current_y = current_y.to(device)\n","    \n","    batch_x = torch.cat((batch_x, current_x.float()), 0)\n","    batch_y = torch.cat((batch_y, current_y.float()), 0)\n","  \n","  batches_x[i] = batch_x\n","  batches_y[i] = batch_y\n","  print(batch_x.shape)\n","  print(batch_y.shape)\n","  print(i, 'out of', nrBatches)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([32, 250])\n","torch.Size([32])\n","0 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","1 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","2 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","3 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","4 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","5 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","6 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","7 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","8 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","9 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","10 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","11 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","12 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","13 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","14 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","15 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","16 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","17 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","18 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","19 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","20 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","21 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","22 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","23 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","24 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","25 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","26 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","27 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","28 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","29 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","30 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","31 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","32 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","33 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","34 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","35 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","36 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","37 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","38 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","39 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","40 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","41 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","42 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","43 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","44 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","45 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","46 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","47 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","48 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","49 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","50 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","51 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","52 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","53 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","54 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","55 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","56 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","57 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","58 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","59 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","60 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","61 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","62 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","63 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","64 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","65 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","66 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","67 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","68 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","69 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","70 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","71 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","72 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","73 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","74 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","75 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","76 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","77 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","78 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","79 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","80 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","81 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","82 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","83 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","84 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","85 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","86 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","87 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","88 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","89 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","90 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","91 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","92 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","93 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","94 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","95 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","96 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","97 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","98 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","99 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","100 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","101 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","102 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","103 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","104 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","105 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","106 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","107 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","108 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","109 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","110 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","111 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","112 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","113 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","114 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","115 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","116 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","117 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","118 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","119 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","120 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","121 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","122 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","123 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","124 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","125 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","126 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","127 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","128 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","129 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","130 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","131 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","132 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","133 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","134 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","135 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","136 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","137 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","138 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","139 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","140 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","141 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","142 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","143 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","144 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","145 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","146 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","147 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","148 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","149 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","150 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","151 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","152 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","153 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","154 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","155 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","156 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","157 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","158 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","159 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","160 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","161 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","162 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","163 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","164 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","165 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","166 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","167 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","168 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","169 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","170 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","171 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","172 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","173 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","174 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","175 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","176 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","177 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","178 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","179 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","180 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","181 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","182 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","183 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","184 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","185 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","186 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","187 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","188 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","189 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","190 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","191 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","192 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","193 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","194 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","195 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","196 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","197 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","198 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","199 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","200 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","201 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","202 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","203 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","204 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","205 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","206 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","207 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","208 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","209 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","210 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","211 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","212 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","213 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","214 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","215 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","216 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","217 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","218 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","219 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","220 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","221 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","222 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","223 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","224 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","225 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","226 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","227 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","228 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","229 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","230 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","231 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","232 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","233 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","234 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","235 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","236 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","237 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","238 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","239 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","240 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","241 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","242 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","243 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","244 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","245 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","246 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","247 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","248 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","249 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","250 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","251 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","252 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","253 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","254 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","255 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","256 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","257 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","258 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","259 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","260 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","261 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","262 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","263 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","264 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","265 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","266 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","267 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","268 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","269 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","270 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","271 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","272 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","273 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","274 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","275 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","276 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","277 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","278 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","279 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","280 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","281 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","282 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","283 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","284 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","285 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","286 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","287 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","288 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","289 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","290 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","291 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","292 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","293 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","294 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","295 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","296 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","297 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","298 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","299 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","300 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","301 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","302 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","303 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","304 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","305 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","306 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","307 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","308 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","309 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","310 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","311 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","312 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","313 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","314 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","315 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","316 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","317 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","318 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","319 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","320 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","321 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","322 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","323 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","324 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","325 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","326 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","327 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","328 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","329 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","330 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","331 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","332 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","333 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","334 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","335 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","336 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","337 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","338 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","339 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","340 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","341 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","342 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","343 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","344 out of 346\n","torch.Size([32, 250])\n","torch.Size([32])\n","345 out of 346\n"],"name":"stdout"}]},{"metadata":{"id":"CMtl22yJd2ay","colab_type":"code","outputId":"62b3c0cc-186b-4202-e6b7-5a7b2c6a750e","executionInfo":{"status":"ok","timestamp":1554905532001,"user_tz":-180,"elapsed":11841,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["print('Total nr. of batches :', nrBatches)\n","\n","#split corpus into training/eval set\n","train_dev_cutoff = int(nrBatches * 0.8)\n","\n","train_data_x = {}\n","train_data_y = {}\n","for i in range(train_dev_cutoff):\n","  train_data_x[i] = batches_x[i].long()\n","  train_data_y[i] = batches_y[i].long()\n","  \n","dev_data_x = {}\n","dev_data_y = {}\n","for i in range(train_dev_cutoff, nrBatches):\n","  dev_data_x[i] = batches_x[i].long()\n","  dev_data_y[i] = batches_y[i].long()\n","\n","nrBatchesTrain = len(train_data_x.keys())\n","print(train_dev_cutoff)\n","print(nrBatchesTrain)\n","nrBatchesDev = len(dev_data_x.keys())\n","print(nrBatchesDev)\n","print(nrBatches - nrBatchesTrain)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Total nr. of batches : 346\n","276\n","276\n","70\n","70\n"],"name":"stdout"}]},{"metadata":{"id":"cdReVVnQd527","colab_type":"code","outputId":"244705ba-4e0a-4523-eab3-ebccd884fcc8","executionInfo":{"status":"ok","timestamp":1554905532004,"user_tz":-180,"elapsed":11819,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["print(train_data_x[0].device)\n","print(train_data_x[0].type())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["cuda:0\n","torch.cuda.LongTensor\n"],"name":"stdout"}]},{"metadata":{"id":"FDZWZHL2eJx5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":445},"outputId":"5fd5920c-3ee5-4956-f4aa-9543d3026740","executionInfo":{"status":"ok","timestamp":1554905532006,"user_tz":-180,"elapsed":11802,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}}},"cell_type":"code","source":["char_idx = torch.LongTensor([7])\n","\n","#create one-hot representation for 7\n","#this is a vector of zeroes, except for the 7th position, where it has a one\n","char_one_hot = torch.zeros(vocab.size())\n","char_one_hot[char_idx] = 1\n","print(\"One-hot representation for 7th caracter: \", char_one_hot)\n","print(\"Lungimea: \", len(char_one_hot))\n","#create an Embedding layer that outputs vectors of size 100; \n","#behind the scenes, this is just a weight matrix of size vocab_size x 100\n","emb_layer = nn.Embedding(vocab.size(), 100)\n","W = emb_layer.weight #this is the actual weight matrix \n","print(\"Embedding matrix size: \", W.size())\n","\n","#multiplying the one-hot vector for 7 by the weight matrix results in a vector \n","#equal to the 7th row of the matrix\n","emb_one_hot = char_one_hot @ W\n","print(\"emb_one_hot size: \", emb_one_hot.size())\n","\n","#the emb_layer receives an index and returns the corresponding row at that index\n","#in the weight matrix\n","emb_idx = emb_layer(char_idx).squeeze()\n","print(\"emb_idx size: \", emb_idx.size())\n","\n","if emb_one_hot.equal(emb_idx):\n","    print(\"Same embedding\")\n","print(\"Linia de la embeding: \",emb_one_hot)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["One-hot representation for 7th caracter:  tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.])\n","Lungimea:  98\n","Embedding matrix size:  torch.Size([98, 100])\n","emb_one_hot size:  torch.Size([100])\n","emb_idx size:  torch.Size([100])\n","Same embedding\n","Linia de la embeding:  tensor([-1.6235,  0.9393,  0.8173, -2.0041, -1.4562, -2.5784, -0.5761, -0.0266,\n","         0.7691, -0.0843,  1.7956, -0.3173,  1.7894, -0.7176,  0.7972,  1.0033,\n","        -0.0489,  1.4673, -0.4491,  1.2312, -0.3215, -1.2506,  1.9888,  0.9312,\n","         0.3012, -1.3068,  1.1241, -1.5193,  0.8069, -0.3610, -1.2656,  1.0549,\n","         0.5975,  0.0557,  0.5559,  0.6804, -0.3021, -0.9031,  0.4769, -0.3284,\n","        -0.3745,  0.5086, -1.0521,  0.7302, -0.6412,  0.7826, -0.2435, -1.4400,\n","         0.2719, -0.6096,  0.0688, -1.8922, -1.5986,  1.6688, -1.0371,  0.9993,\n","         0.0418,  0.9898, -0.6545,  0.5158, -0.5690,  0.7074, -0.4730,  0.8725,\n","         0.0189,  0.0802, -0.3212, -0.4551, -1.3183, -1.9367, -0.5858, -0.7133,\n","        -1.8558, -0.4459, -0.6509, -0.7227,  0.7692,  0.6612, -0.0039, -1.5505,\n","         1.9366,  0.4819, -0.8733,  0.4613,  0.9744,  0.1083, -0.7088,  0.4018,\n","         0.1855, -0.9804,  0.0072, -0.0196,  0.2826, -0.0657,  0.6095, -1.3477,\n","         0.3398,  2.3731, -1.5618,  0.4038], grad_fn=<SqueezeBackward3>)\n"],"name":"stdout"}]},{"metadata":{"id":"XbDPo5lQlHPI","colab_type":"code","colab":{}},"cell_type":"code","source":["############################## PARAMETERS ######################################\n","_hyperparameters_dict = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 10,\n","    \"max_len\": 250,\n","    \"embedding_size\": 100, \n","    \"rnn_size\": 512,\n","    \"learning_algo\": \"adam\",\n","    \"learning_rate\": 0.001,\n","    \"max_grad_norm\": 5.0\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nYFDCcdhlJJk","colab_type":"code","colab":{}},"cell_type":"code","source":["class RNNLM(nn.Module):\n","    def __init__(self, vocab_size: int, char_embedding_size: int, \n","                 rnn_size: int):\n","        super().__init__()\n","        #TODO\n","        self.vocab_size = vocab_size\n","        self.char_embedding_size = char_embedding_size\n","        self.rnn_size = rnn_size\n","        \n","        self.embedding = nn.Embedding(num_embeddings = vocab_size, \n","                                      embedding_dim = char_embedding_size)\n","\n","        self.rnn_cell = nn.GRUCell(input_size = char_embedding_size,\n","                                   hidden_size = rnn_size)\n","        self.logits = nn.Linear(in_features=rnn_size, out_features=6)\n","        self.softmax = nn.Softmax(dim = 2)\n","        \n","        self.loss = nn.CrossEntropyLoss()\n","    \n","    def get_loss(self, logits: torch.FloatTensor, y: torch.FloatTensor):\n","        \"\"\"\n","        Computes loss for a batch of sequences. The sequence loss is the \n","        average of the individual losses at each timestep. The batch loss is\n","        the average of sequence losses across all batches.\n","\n","        :param logits: unnormalized probabilities for T timesteps, size\n","                       batch_size x max_timesteps x vocab_size\n","        :param y: ground truth values (index of correct characters), size\n","                  batch_size x max_timesteps\n","        :returns: loss as a scalar\n","        \"\"\"\n","        #print('Logits shape :', logits.shape)\n","        #print('Target shape :', y.shape)\n","        return self.loss(logits, y)\n","        \n","    \n","    def get_logits(self, hidden_states: torch.FloatTensor, \n","                   temperature: float = 1.0):\n","        \"\"\"\n","        Computes the unnormalized probabilities from hidden states. Optionally\n","        divide logits by a temperature, in order to influence predictions at \n","        test time (https://www.quora.com/What-is-Temperature-in-LSTM)\n","        \n","        :param hidden_states: tensor of size batch_size x timesteps x rnn_size\n","        :param temperature: coefficient that scales outputs before turning them \n","        to probabilities. A low temperature (0.1) results in more conservative \n","        predictions, while a higher temperature (0.9) results in more diverse\n","        predictions\n","        \n","        :return: tensor of size batch_size x timesteps x vocab_size\n","        \"\"\"\n","        #print('Hidden states shape :', hidden_states.shape)\n","        return self.logits(hidden_states) / temperature\n","        \n","    def forward(self, x: torch.LongTensor, \n","                hidden_start: torch.FloatTensor = None) -> torch.FloatTensor:\n","        \"\"\"\n","        Computes the hidden states\n","        for the current batch (x, y). \n","        :param x: input of size batch_size x max_len\n","        :param hidden_start: hidden state at time step t = 0, \n","                             size batch_size x rnn_size\n","        :return: hidden states at all timesteps, \n","                 size batch_size x timesteps x rnn_size\n","        \"\"\"\n","        max_len = x.size(1)\n","        \n","        #batch_size x max_len x embedding_dim\n","        x_embedded = self.embedding(x)\n","        \n","        #compute hidden states and logits for each time step\n","        prev_hidden = hidden_start\n","        for t in range(max_len):\n","            hidden_state = self.rnn_cell(x_embedded[:,t,:], prev_hidden)\n","            prev_hidden = hidden_state\n","        \n","        return hidden_state"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fkOL--jdlNao","colab_type":"code","colab":{}},"cell_type":"code","source":["#instantiate the RNNLM module\n","network = RNNLM(vocab.size(), \n","            _hyperparameters_dict['embedding_size'], \n","            _hyperparameters_dict['rnn_size'])\n","\n","# move network to GPU if available\n","network = network.to(device)\n","\n","optimizer = Adam(params = network.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yft8Ont1lO7E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"7e63e68c-b569-4ec7-a3c1-b39b7912f36b","executionInfo":{"status":"ok","timestamp":1554905532467,"user_tz":-180,"elapsed":12208,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}}},"cell_type":"code","source":["# CHECKPOINT: make sure you understand each parameter size\n","print(\"Neural network parameters: \")\n","for param_name, param in network.named_parameters():\n","    print(\"\\t\" + param_name, \" size: \", param.size())"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Neural network parameters: \n","\tembedding.weight  size:  torch.Size([98, 100])\n","\trnn_cell.weight_ih  size:  torch.Size([1536, 100])\n","\trnn_cell.weight_hh  size:  torch.Size([1536, 512])\n","\trnn_cell.bias_ih  size:  torch.Size([1536])\n","\trnn_cell.bias_hh  size:  torch.Size([1536])\n","\tlogits.weight  size:  torch.Size([6, 512])\n","\tlogits.bias  size:  torch.Size([6])\n"],"name":"stdout"}]},{"metadata":{"id":"dmzEpsKElQhC","colab_type":"code","colab":{}},"cell_type":"code","source":["# CHECKPOINT: make sure you can feedforward and backpropagate through network\n","xb, yb = batches_x[0].long(), batches_y[0].long()\n","\n","hidden_start = torch.zeros(_hyperparameters_dict[\"batch_size\"],\n","                            _hyperparameters_dict[\"rnn_size\"]).to(device)\n","hidden_states = network(xb, hidden_start)\n","logits = network.get_logits(hidden_states)\n","loss = network.get_loss(logits, yb)\n","loss.backward()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hhoCXxxAlSiL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"f849671b-e45f-4e89-a44a-c0c6c6827391","executionInfo":{"status":"ok","timestamp":1554905603681,"user_tz":-180,"elapsed":83396,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}}},"cell_type":"code","source":["#train the network for 60 iterations and save save hidden states (one slice of \n","#the batch) every 30 iterations\n","\n","prev_hidden = torch.zeros(_hyperparameters_dict[\"batch_size\"],\n","                           _hyperparameters_dict[\"rnn_size\"]).to(device)\n","\n","for i in range(nrBatches):\n","    #print(i, 'out of', nrBatches)\n","    xb, yb = batches_x[i], batches_y[i]\n","    \n","    #gradients are set to zero every new batch\n","    optimizer.zero_grad()\n","    \n","    #feedforward\n","    hidden_states = network(xb.long(), prev_hidden)\n","    logits = network.get_logits(hidden_states)\n","    loss = network.get_loss(logits, yb.long())\n","    \n","    #backpropagation -> compute gradient of loss with respect to all weights\n","    loss.backward()\n","    \n","    #clip gradients if they get have norm > 5.0\n","    torch.nn.utils.clip_grad_norm_(list(network.parameters()), 5.0)\n","    \n","    #update weights \n","    optimizer.step()\n","\n","    #the hidden states from iteration it should no longer be linked to \n","    #the hidden states from iteration (it+1)\n","    hidden_states.detach_()\n","    \n","    if i % 60 == 0:\n","        print(\"Iteration %d, loss = %f\" %(i, loss))\n","    \n","    prev_hidden = hidden_states"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Iteration 0, loss = 1.811685\n","Iteration 60, loss = 1.438825\n","Iteration 120, loss = 1.430934\n","Iteration 180, loss = 1.311178\n","Iteration 240, loss = 1.565592\n","Iteration 300, loss = 0.517341\n"],"name":"stdout"}]},{"metadata":{"id":"aXr7riuflUuq","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class Trainer:\n","    def __init__(self, model: nn.Module, \n","                 train_data_x: torch.LongTensor,\n","                 train_data_y: torch.LongTensor,\n","                 dev_data_x: torch.LongTensor,\n","                 dev_data_y: torch.LongTensor,\n","                 test_data_x: torch.LongTensor,\n","                 test_data_y: torch.LongTensor,\n","                 vocab: Vocabulary, \n","                 hyperparams: Dict):\n","        self.model = model\n","        self.train_data_x = train_data_x\n","        self.train_data_y = train_data_y\n","        self.dev_data_x = dev_data_x\n","        self.dev_data_y = dev_data_y\n","        self.test_data_x = test_data_x\n","        self.test_data_y = test_data_y\n","        self.vocab = vocab\n","        if hyperparams['learning_algo'] == 'adam':\n","            self.optimizer = Adam(params = self.model.parameters(),\n","                                  lr = hyperparams['learning_rate'])\n","        else:\n","            self.optimizer = SGD(params = self.model.parameters(), \n","                                 lr = hyperparams['learning_rate'])\n","        self.num_epochs = hyperparams['num_epochs']\n","        #self.max_len = hyperparams['max_len'] # batch-urile sunt deja construite cu \n","        self.batch_size = hyperparams['batch_size']\n","        self.rnn_size = hyperparams['rnn_size']\n","        self.max_grad_norm = hyperparams['max_grad_norm']\n","        \n","        #number of characters in training/dev data\n","        self.nrTrainBatches = len(train_data_x.keys())\n","        self.nrDevBatches = len(dev_data_x.keys())\n","        self.nrTestBatches = len(test_data_x.keys())\n","        \n","        self.temperature = hyperparams['temperature']\n","        \n","    def train_epoch(self, epoch_num: int) -> float:\n","        \"\"\"\n","        Compute the loss on the training set\n","        :param epoch_num: number of current epoch\n","        \"\"\"\n","        self.model.train()\n","        epoch_loss = 0.0\n","        hidden_start = torch.zeros(self.batch_size, self.rnn_size).to(device)\n","        \n","        for i in range(train_dev_cutoff):\n","            #print(i, 'out of', nrBatches)\n","            x, y = self.train_data_x[i], self.train_data_y[i]\n","\n","            # reset gradients\n","            self.optimizer.zero_grad()\n","          \n","            # compute hidden states\n","            # batch x timesteps x hidden_size\n","            hidden_states = self.model(x, hidden_start)\n","            \n","            # compute unnormalized probabilities\n","            # batch x timesteps x vocab_size\n","            logits = self.model.get_logits(hidden_states, self.temperature)\n","            \n","            # compute loss\n","            # scalar\n","            batch_loss = self.model.get_loss(logits, y)\n","            epoch_loss += batch_loss.item()\n","                       \n","            # backpropagate loss\n","            batch_loss.backward()\n","            \n","            # clip gradients if they get too large\n","            torch.nn.utils.clip_grad_norm_(list(self.model.parameters()), \n","                                           self.max_grad_norm)\n","            \n","            # update parameters\n","            self.optimizer.step()\n","            \n","            # we use a stateful RNN, which means the first hidden state for the\n","            # next batch is the last hidden state of the current batch\n","            hidden_states.detach_()\n","            hidden_start = hidden_states\n","            \n","            if i % 100 == 0:\n","                print(\"epoch %d, %d/%d batches, batch loss = %f\"\n","                      % (epoch_num, (i + 1), \n","                         self.nrTrainBatches, batch_loss.item()))\n","\n","        epoch_loss /= self.nrTrainBatches\n","        \n","        return epoch_loss\n","\n","    def eval_epoch(self, epoch_num: int) -> float:\n","        \"\"\"\n","        Compute the loss on the validation set\n","        :param epoch_num: number of current epoch\n","        \"\"\"\n","        epoch_loss = 0.0\n","        hidden_start = torch.zeros(self.batch_size, self.rnn_size).to(device)\n","        with torch.no_grad():\n","            for i in range(train_dev_cutoff, nrBatches):\n","                #print(i, 'out of', nrBatches)\n","                x, y = self.dev_data_x[i], self.dev_data_y[i]\n","                \n","                #batch x timesteps x hidden_size\n","                hidden_states = self.model(x, hidden_start)\n","            \n","                #batch x timesteps x vocab_size\n","                logits = self.model.get_logits(hidden_states, self.temperature)\n","            \n","                batch_loss = self.model.get_loss(logits, y)\n","                epoch_loss += batch_loss.item()\n","                \n","                # we use a stateful RNN, which means the first hidden state for \n","                # the next batch is the last hidden state of the current batch\n","                hidden_states.detach_()\n","                hidden_start = hidden_states\n","                \n","            epoch_loss /= self.nrDevBatches\n","        \n","        return epoch_loss    \n","            \n","    def train(self) -> Dict:\n","        train_losses, dev_losses = [], []\n","        for epoch in range(self.num_epochs):\n","            epoch_train_loss = self.train_epoch(epoch)\n","            epoch_dev_loss = self.eval_epoch(epoch)\n","            train_losses.append(epoch_train_loss)\n","            dev_losses.append(epoch_dev_loss)\n","        return {\"train_losses\": train_losses,\n","                \"dev_losses\": dev_losses}\n","      \n","    def test(self):\n","        hidden_start = torch.zeros(self.batch_size, self.rnn_size).to(device)\n","        with torch.no_grad():\n","            cnt = 0\n","            meanAcc = 0\n","            conf_mat = torch.zeros((nrLanguages, nrLanguages))\n","            #for i in range(train_dev_cutoff, nrBatches):\n","            for i in range(nrBatchesTest):\n","                cnt = cnt + 1\n","                #print(i, 'out of', nrBatches)\n","                #x, y = self.dev_data_x[i], self.dev_data_y[i]\n","                x, y = self.test_data_x[i], self.test_data_y[i]\n","                \n","                #batch x timesteps x hidden_size\n","                hidden_states = self.model(x, hidden_start)\n","            \n","                #batch x timesteps x vocab_size\n","                logits = self.model.get_logits(hidden_states, self.temperature)\n","            \n","                sft = F.softmax(logits)\n","                pred = torch.argmax(sft, dim=1)\n","\n","                nrPredictedOk = (pred == y).sum()\n","\n","                acc = float(nrPredictedOk) / batch_size\n","                meanAcc = meanAcc + acc\n","                \n","                #print(acc)\n","                # update confusion matrix\n","                for it in range(batch_size):\n","                    p = pred[it]\n","                    t = y[it].long()\n","                    \n","                    conf_mat[t][p] = conf_mat[t][p] + 1\n","                \n","                # we use a stateful RNN, which means the first hidden state for \n","                # the next batch is the last hidden state of the current batch\n","                hidden_states.detach_()\n","                hidden_start = hidden_states\n","                        \n","        meanAcc = meanAcc / cnt\n","        return meanAcc, conf_mat\n","\n","def plot_losses(metrics: Dict):\n","    \"\"\"\n","    Plots training/validation losses.\n","    :param metrics: dictionar\n","    \"\"\"\n","    plt.figure()\n","    plt.plot(metrics['train_losses'], c='b', label='Train')\n","    plt.plot(metrics['dev_losses'], c='g', label='Valid')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Iteration')\n","    plt.legend()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"olweQYUelfPK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":217},"outputId":"dba4ee47-a59b-495e-ef01-87f50a319e80","executionInfo":{"status":"error","timestamp":1554905743634,"user_tz":-180,"elapsed":941,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}}},"cell_type":"code","source":["#train network for some epoch\n","trainer = Trainer(network, train_data_x, train_data_y, dev_data_x, dev_data_y, test_data_x, test_data_y, vocab, _hyperparameters_dict)\n","\n","metrics = trainer.train()"],"execution_count":18,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-9451f366c1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_data_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_hyperparameters_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_data_x' is not defined"]}]},{"metadata":{"id":"MZ52cAU6liq8","colab_type":"code","colab":{}},"cell_type":"code","source":["#plot training and validations losses each epoch\n","plot_losses(metrics)"],"execution_count":0,"outputs":[]}]}