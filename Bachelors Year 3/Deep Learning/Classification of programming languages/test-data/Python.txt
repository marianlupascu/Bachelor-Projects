class IOService:
    def __init__(self):
        self.controller = {}
    def setController(self, ip, port, user, passwd):
        self.controller["ip"] = ip
        self.controller["port"] = port
        self.controller["user"] = user
        self.controller["passwd"] = passwd
    def get(self, url):
        url = "http://" + str(self.controller["ip"]) + ":" + str(self.controller["port"]) + url
        
        h = httplib2.Http(".Cache")
        h.add_credentials(self.controller["user"], self.controller["passwd"])
        resp,content = h.request(url, "GET")
        
        return content
    def put(self, url, content):
        url = "http://" + str(self.controller["ip"]) + ":" + str(self.controller["port"]) + url
        
        h = httplib2.Http(".Cache")
        h.add_credentials(self.controller["user"], self.controller["passwd"])
        resp = h.request(url, "PUT", body=str(json.dumps(content)), \
                        headers={"Content-Type":"application/json"})
        pr
io.use_plugin('pil')
priority_plugin = 'pil'
def setup_module():
def teardown_module():
    io.reset_plugins()
@contextmanager
def protect_preferred_plugins():
    """Contexts where `preferred_plugins` can be modified w/o side-effects."""
    preferred_plugins = manage_plugins.preferred_plugins.copy()
    try:
        yield
    finally:
        manage_plugins.preferred_plugins = preferred_plugins
def test_read():
    io.imread('test.png', as_grey=True, dtype='i4', plugin='test')
def test_save():
    io.imsave('test.png', [1, 2, 3], plugin='test')
def test_show():
    io.imshow([1, 2, 3], plugin_arg=(1, 2), plugin='test')
def test_collection():
    io.imread_collection('*.png', conserve_memory=False, plugin='test')
def test_use():
    manage_plugins.use_plugin('test')
    manage_plugins.use_plugin('test', 'imshow')
@raises(ValueError)
def test_failed_use():
    manage_plugins.use_plugin('asd')
def test_use_priority():
    manage_plugins.use_plugin(priority_plugin)
    plug, func = manag

    assert_equal(plug, priority_plugin)
    manage_plugins.use_plugin('test')
    plug, func = manage_plugins.plugin_store['imread'][0]
    assert_equal(plug, 'test')
def test_use_priority_with_func():
    manage_plugins.use_plugin('pil')
    plug, func = manage_plugins.plugin_store['imread'][0]
    assert_equal(plug, 'pil')
    manage_plugins.use_plugin('test', 'imread')
    plug, func = manage_plugins.plugin_store['imread'][0]
    assert_equal(plug, 'test')
    plug, func = manage_plugins.plugin_store['imsave'][0]
    assert_equal(plug, 'pil')
    manage_plugins.use_plugin('test')
    plug, func = manage_plugins.plugin_store['imsave'][0]
    assert_equal(plug, 'test')
def test_plugin_order():
    p = io.plugin_order()
    assert 'imread' in p
    assert 'test' in p['imread']
def test_available():
    assert 'qt' in io.available_plugins
    assert 'test' in io.find_available_plugins(loaded=True)
def test_load_preferred_plugins_all():
    with protect_preferred_plugins():
        mana
try:
except:
    raise ImportError("pyqt module is missing")
class SaveMenu(QMenu):
    """
    """
    def __init__(self, parent):
        super(SaveMenu, self).__init__(parent) 
        self.parent = parent
        self.setTitle('&Save')
        
        savePrintOutAction = myqtcommon.createAction(self,
            "&All work to text file", self.onSavePrintOut)
        savePlotASCII = myqtcommon.createAction(self, 
            "&Save current plot to text file", self.onSavePlotASCII)
        self.addActions([savePrintOutAction, savePlotASCII])
        
    def onSavePrintOut(self):
        """
        """
        printOutFilename= QFileDialog.getSaveFileName(self,
                "Save as PRT file...", ".prt", "PRT files (*.prt)")
        self.parent.textBox.selectAll()
        text = self.parent.textBox.toPlainText()
        fout = open(printOutFilename,'w')
        fout.write(text)
        fout.close()
        self.parent.txtPltBox.clear()
        self.parent.txtPltBox.append('Save
t = md.load('conf.gro')
trajs = md.load('traj0.xtc',top='conf.gro')
print "Preparation done, now begin clustering..."
kcenters=KCenters(n_clusters=25,metric='rmsd').fit(trajs)
traj2=kcenters.cluster_centers_
traj2.save_pdb('Gens_total.pdb')
sys.exit()
traj2[0].save_pdb('Gens0.pdb')
traj2[1].save_pdb('Gens1.pdb')
traj2[2].save_pdb('Gens2.pdb')
traj2[3].save_pdb('Gens3.pdb')
traj2[4].save_pdb('Gens4.pdb')
traj2[5].save_pdb('Gens5.pdb')
traj2[6].save_pdb('Gens6.pdb')
traj2[7].save_pdb('Gens7.pdb')
traj2[8].save_pdb('Gens8.pdb')
traj2[9].save_pdb('Gens9.pdb')
traj2[10].save_pdb('Gens10.pdb')
traj2[11].save_pdb('Gens11.pdb')
traj2[12].save_pdb('Gens12.pdb')
traj2[13].save_pdb('Gens13.pdb')
traj2[14].save_pdb('Gens14.pdb')
traj2[15].save_pdb('Gens15.pdb')
traj2[16].save_pdb('Gens16.pdb')
traj2[17].save_pdb('Gens17.pdb')
traj2[18].save_pdb('Gens18.pdb')
traj2[19].save_pdb('Gens19.pdb')
traj2[20].save_pdb('Gens20.pdb')
traj2[21].save_pdb('Gens21.pdb')
traj2[22].save_pdb('Gens22.pdb')
traj2[23]
def initialize(context):
    from Products.PluginIndexes.FieldIndex.FieldIndex \
    from Products.PluginIndexes.FieldIndex.FieldIndex \
    context.registerClass(FieldIndex,
                          permission='Add Pluggable Index',
                          constructors=(manage_addFieldIndexForm,
                                        manage_addFieldIndex),
                          icon='www/index.gif',
                          visibility=None,
                         )
    from Products.PluginIndexes.KeywordIndex.KeywordIndex \
    from Products.PluginIndexes.KeywordIndex.KeywordIndex \
    context.registerClass(KeywordIndex,
                          permission='Add Pluggable Index',
                          constructors=(manage_addKeywordIndexForm,
                                        manage_addKeywordIndex),
                          icon='www/index.gif',
                          visibility=None,
                         )
    from Products.PluginIndexes.TopicIndex.Topi

    from Products.PluginIndexes.TopicIndex.TopicIndex \
    context.registerClass(TopicIndex,
                          permission='Add Pluggable Index',
                          constructors=(manage_addTopicIndexForm,
                                        manage_addTopicIndex),
                          icon='www/index.gif',
                          visibility=None,
                         )
    from Products.PluginIndexes.DateIndex.DateIndex \
    from Products.PluginIndexes.DateIndex.DateIndex \
    context.registerClass(DateIndex,
                          permission='Add Pluggable Index',
                          constructors=(manage_addDateIndexForm,
                                        manage_addDateIndex),
                          icon='www/index.gif',
                          visibility=None,
                         )
    from Products.PluginIndexes.DateRangeIndex.DateRangeIndex \
    from Products.PluginIndexes.DateRangeIndex.DateRangeIndex \
    from Products.Pl

    context.registerClass(DateRangeIndex,
                          permission='Add Pluggable Index',
                          constructors=(manage_addDateRangeIndexForm,
                                        manage_addDateRangeIndex),
                          icon='www/index.gif',
                          visibility=None,
                         )
    from Products.PluginIndexes.PathIndex.PathIndex \
    from Products.PluginIndexes.PathIndex.PathIndex \
    context.registerClass(PathIndex,
                          permission='Add Pluggable Index',
                          constructors=(manage_addPathIndexForm,
                                        manage_addPathIndex),
                          icon='www/index.gif',
                          visibility=None,
                         )
        manage_addBooleanIndex
        manage_addBooleanIndexForm
    context.registerClass(BooleanIndex,
                          permission='Add Pluggable Index',
                          
SITE_SLUG = "(?P<site_slug>[-_\w]+)"
COMIC_SLUG = "(?P<comic_slug>[-_\w]+)"
SLUG = "(?P<slug>[-_\w]+)"
urlpatterns = [
    url(r'^$', views.home, name='home'),
    url(r'n/(?P<n>[0-9]+)', views.single_by_numerical_order, name='single_by_numerical_order'),
    url(r'c/' + COMIC_SLUG, views.single, name='single'),
    url(r'^manage/' + SITE_SLUG + '/preview/' + COMIC_SLUG, views.preview, name='preview'),
    url(r'^archives$', views.archives, name='archives'),
    url(r'^archives/' + SLUG, views.tag, name='tag'),
    url(r'^search$', views.search, name='search'),
    url(r'^manage/' + SITE_SLUG + '/$', views.manage, name='manage'),
    url(r'^manage/' + SITE_SLUG + '/trash$', views.trash, name='trash'),
    url(r'^manage/' + SITE_SLUG + '/tag/'+ SLUG, views.manage_tag, name='manage_tag'),
    url(r'^manage/' + SITE_SLUG + '/create$', views.create, name='create'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/$', views.update, name='update'),
    url(r'^manage/' + SITE_SLU

    url(r'^blog$', views.blog, name='blog'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/create_blog$', views.create_blog, name='create_blog'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/update_blog/' + SLUG, views.update_blog, name='update_blog'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/delete_blog/' + SLUG, views.delete_blog, name='delete_blog'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/create_video$', views.create_video, name='create_video'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/update_video/' + SLUG, views.update_video, name='update_video'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/delete_video/' + SLUG, views.delete_video, name='delete_video'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/create_image$', views.create_image, name='create_image'),
    url(r'^manage/' + SITE_SLUG + '/update/' + COMIC_SLUG + '/update_image/' + SLUG, views.upda
__author__ = 'alirezasadeghi'
    RequestBuyProduct
customer_port_number = random.randint(1235, 50000)
BROKER_PORT = 1234
money = 1000
borker_scrips = []
vendor_scrips = []
products = []
broker_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
try:
    broker_sock.connect(("127.0.0.1", BROKER_PORT))
except socket.error as errmsg:
    traceback.print_exc()
    print("Something bad happened when trying to connect to broker.")
    sys.exit()
vendor_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)
vendor_sock.setblocking(0)
vendor_port_number = 0
while vendor_port_number != -1:
    vendor_port_number = input("Enter vendor port to connect to?")
    try:
        vendor_sock.connect(("127.0.0.1", vendor_port_number))
    except socket.error as e:
        traceback.print_exc()
        vendor_port_number = random.randint(1235, 50000)
        continue
customer_sock.listen(128)
io_loop = ioloop.IOLoop.instance()
callback = functools.partial(customer_connection_ready, customer_so

io_loop.add_handler(customer_sock.fileno(), callback, io_loop.READ)
def handle_connection(connection, address, arg):
    message = connection.recv(1024)
    print("msg received : ", message)
    msg = process_msg(message)
    if msg["type"] == "ResponseBrokerScrip":
        scrip = parse_scrip(msg["data"][0])
        money -= scrip.amount
        add_broker_scrip(scrip)
        
        is_scrip_valid(scrip, "md5")
        
    
    elif msg["type"] == "ResponseVendorScrip":
        vendor_scrip = parse_scrip(msg["data"][0])
        
        add_vendor_scrip(vendor_scrip)
        
        broker_change = msg["data"][1]
        if broker_change:
            broker_change_scrip = parse_scrip(broker_change)
        add_broker_scrip(broker_change_scrip)
        
    
    elif msg["type"] == "ResponseProductInfo":
     
    
    elif msg["type"] == "ResponseBuyProduct":
        vendor_change = msg["data"][1]
        if vendor_change:
            add_vendor_scrip(parse_scrip(vendor_change))

def send_msg(message, socket, crypto=None, key=None):
    '''
    sends the message into network. receiver
    '''
    socket.send(message.as_json().encode('utf-8'))
def add_broker_scrip(self, scrip):
    borker_scrips.append(scrip)
        
def add_vendor_scrip(self, scrip):
    vendor_scrips.append(scrip)    
def buy_broker_scrip(self, amount):
    '''
    requests a scrip from broker with the amount given.
    money will be reduced in processing the response.
    '''
    send_msg(RequestBrokerScrip(id, self.network.broker_id, amount), broker_sock)
    
def buy_vendor_scrip(amount, vendor_id):
    send_msg(RequestVendorScrip(id, broker_id, vendor_id, amount, broker_scrip))
def buy_product(vendor_id, product_price):
    vendor_scrip = find_vendor_scrip(product_price)
    send_msg(RequestBuyProduct(id, vendor_id, vendor_scrip))
        
    
def find_broker_scrip(amount):
    return __find_scrip(amount, borker_scrips)
     
def find_vendor_scrip(amount):
    return __find_scrip(amount
"""
inst_save.py by xianhu
"""
class SaverAsync(object):
    """
    class of SaverAsync, must include function save()
    """
    def __init__(self,  save_pipe=sys.stdout):
        """
        constructor
        """
        return
    async def save(self, url: str, keys: object, item: (list, tuple)) -> bool:
        """
        save the item of a url, must "try, except" and don't change the parameters and return
        :return save_result: True or False
        """
        logging.debug("%s start: keys=%s, url=%s", self.__class__.__name__, keys, url)
        try:
            self._save_pip.write("\t".join([url, str(keys)] + [str(i) for i in item]) + "\n")
            self._save_pip.flush()
            save_result = True
        except Exception as excep:
            save_result = False
            logging.error("%s error: %s, keys=%s, url=%s", self.__class__.__name__, excep, keys, url)
        logging.debug("%s end: save_result=%s, url=%s", self.__class__.__name__, save_result, url)
ACTION_SAVE_INSERT = 'insert'
ACTION_SAVE_UPDATE = 'update'
class BaseModel(models.Model):
    class Meta:
        abstract = True
    def save(self):
        """
        Override model save method to modify the object before and after saving.
        """
        instance = super(BaseModel, self)
        if self.id:
            action = ACTION_SAVE_UPDATE
        else:
            action = ACTION_SAVE_INSERT
        try:
            self.before_save(action)
        except AttributeError:
            pass
        instance.save()
        try:
            self.after_save(action)
        except AttributeError:
            pass
        return instance
class ContentModel(BaseModel):
    class Meta:
        abstract = True
    title = models.CharField(max_length=255)
    status = models.IntegerField(default=1)
    created = models.DateTimeField(auto_now_add=True)
    changed = models.DateTimeField(auto_now=True)
class NodeContentModel(ContentModel):
    class Meta:
        abstract = True
   
"""Condition choices and operators for repositories and SCMTools."""
                                        ConditionChoices)
                                          BaseConditionOperator,
                                          ConditionOperators,
                                          IsNotOneOfOperator,
                                          IsOneOfOperator,
                                          UnsetOperator)
class RepositoryConditionChoiceMixin(object):
    """Mixin for condition choices that operate off repositories.
    This will set state needed to match against the choice.
    """
    value_kwarg = 'repository'
class IsRepositoryPrivateOperator(BaseConditionOperator):
    """An operator for matching private repositories."""
    operator_id = 'is-private'
    name = _('Is private')
    value_field = None
    def matches(self, match_value, **kwargs):
        """Return whether the repository is private.
        Args:
            match_value (reviewboard.scmtools.mo

                The repository to match.
            **kwargs (dict):
                Unused keyword arguments.
        Returns:
            bool:
            ``True`` if the repository is private. ``False`` if public.
        """
        return match_value is not None and not match_value.public
class IsRepositoryPublicOperator(BaseConditionOperator):
    """An operator for matching public repositories."""
    operator_id = 'is-public'
    name = _('Is public')
    value_field = None
    def matches(self, match_value, **kwargs):
        """Return whether the repository is public.
        Args:
            match_value (reviewboard.scmtools.models.Repository):
                The repository to match.
            **kwargs (dict):
                Unused keyword arguments.
        Returns:
            bool:
            ``True`` if the repository is public. ``False`` if private.
        """
        return match_value is not None and match_value.public
class RepositoriesChoice(LocalSiteModel

                         RepositoryConditionChoiceMixin,
                         BaseConditionModelMultipleChoice):
    """A condition choice for matching repositories.
    This is used to match a :py:class:`~reviewboard.scmtools.models.Repository`
    against a list of repositories, against no repository (``None``), or
    against a repository public/private state.
    """
    queryset = Repository.objects.all()
    choice_id = 'repository'
    name = _('Repository')
    operators = ConditionOperators([
        AnyOperator.with_overrides(name=_('Any repository')),
        UnsetOperator.with_overrides(name=_('No repository')),
        IsOneOfOperator,
        IsNotOneOfOperator,
        IsRepositoryPublicOperator,
        IsRepositoryPrivateOperator,
    ])
    def get_match_value(self, repository, **kwargs):
        """Return the value used for matching.
        This will return the provided repository directly.
        Args:
            repository (reviewboard.scmtools.models.Repos
__version__ = '1.0'
def broker(broker_ip, broker_port):
	b = Broker(broker_ip, broker_port)
def client(args):
	c = Client(args.brokerhost, args.port, args.username, args.password)
def parsing():
	"""generate and return a parser from the command line"""
	parser = argparse.ArgumentParser(prog='HolePunching', 
        description='NAT traversal programm in Python. '\
        'Several clients are behind a firewall '\
        'and they want to communicate directly between them. '\
        'Broker is accessible since the outside and it initializes '\
        'the direct connection between clients ')
	parser.add_argument('--version', action='version',
		version='%(prog)s ' + __version__)
	subparsers = parser.add_subparsers()
	brokerparser = subparsers.add_parser('broker',
		help='Broker mode')
	brokerparser.set_defaults(mode='broker')
	brokerparser.add_argument('host', default='127.0.0.1', help='IP address to listen on')
	brokerparser.add_argument('port', type = int, 
		default = 4242, help='
class TestRepository(unittest.TestCase):
    def testQueryListReturnsNoneForNoMatches(self):
        repository = Repository("fakedir")
        theList = ["foo", "bar", "biz", "bat"]
        self.assertEquals(None, repository._queryList("bilbo", theList))
        
    def testQueryListReturnsBestMatch(self):
        repository = Repository("fakedir")
        theList = ["bil", "billbo", "BILbiz", "BILBO"]
        self.assertEquals("BILBO",repository._queryList("bilbo", theList))
        
    def testScoreNameIncreasesByTenForExactMatches(self):
        repository = Repository("fakedir")
        masterList = [[0,"bil"], [1,"billbo"], [2,"BILbiz"], [3,"BILBO"]]
        repository._scoreName("bilbo", masterList)
        self.assertEquals([13,"BILBO"],masterList[3])
    def testScoreNameIncreasesByOneForPartialMatches(self):
        repository = Repository("fakedir")
        masterList = [[0,"bil"], [1,"billbo"], [2,"BILbiz"], [3,"BILBO"]]
        repository._scoreName("bi",masterList)
    
//--------------------------------------------------
// Django
//--------------------------------------------------
source venv/bin/activate
./manage.py runserver &
python manage.py inspectdb > somefile.txt
./manage.py shell
./manage.py sqlclear app_name | ./manage.py dbshell 
./manage.py syncdb
./manage.py schemamigration --initial southtut
./manage.py migrate southtut
./manage.py schemamigration my_app_name --auto --stdout
./manage.py migrate myapp --db-dry-run
./manage.py migrate --list
$ ./manage.py dbshell
./manage.py schemamigration main --auto --update
- python manage.py validate //– Checks for any errors in the construction of your models.
- python manage.py sqlcustom app_name //– Outputs any custom SQL statements 
//(such as table modifications or constraints) that are defined for the application.
- python manage.py sqlclear app_name //– Outputs the necessary DROP TABLE statements for this app, 
// according to which tables already exist in your database (if any).
- python man
"""
    Helper function for django projects
    Requires using virtualenv and project helpers
"""
def django_env(command, use_sudo=False):
    """
        run command in django environment
    """
    func = use_sudo and sudo or run
    with venv():
        with in_project():
            func(command)
def django_manage(manage_command, use_sudo=False):
    """
        run django managment commands
    """
    command = 'python manage.py %s' % manage_command
    django_env(command, use_sudo)
@task
def django_syncdb(use_sudo=False):
    """
        Run python manage.py syncdb --no-input
    """
    django_manage('syncdb --noinput', use_sudo)
@task
def django_migration(use_sudo=False):
    """
        Run python manage.py migrate --no-input
    """
    django_manage('migrate --noinput', use_sudo)
@task
def django_collectstatic(use_sudo=False):
    """
        Run python manage.py collectstatic --no-input
    """
    django_manage('collectstatic --noinput', use_sudo)
@task
def django_cleanp
urlpatterns = [
    url(r'^$', admin_index_redirect,
        name='admin_index_redirect'),
    url(r'^index/?$',
        admin_index, name='admin_index'),
    url(r'^organization/list/?$', ListOrganization.as_view(),
        name='manage_organization_list'),
    url(r'^organization/(?P<id>\d+)/?$', ShowOrganization.as_view(),
        name='manage_organization_show'),
    url(r'^organization/(?P<id>\d+)/manager/?$', OrganzationManager.as_view(),
        name='manage_organization_manage'),
    url(r'^account/list/?$', ListAccount.as_view(), name='manage_account_list'),
    url(r'^account/(?P<id>\d+)/?$', ShowAccount.as_view(),
        name='manage_account_show'),
    url(r'^infor/list/?$', ListInfor.as_view(), name='manage_infor_list'),
    url(r'^infor/post/?$', PostInfor.as_view(), name='manage_infor_post'),
    url(r'^infor/(?P<id>\d+)/?$', Information.as_view(),
        name='manage_infor_infor'),
    url(r'^organization/?$',
        organization_manage,
        name='organization_ma
SERVICE_PORT = int(os.environ.get('uls_service_port', 19680))
BATCH_CUTOFF = int(os.environ.get('uls_batch_cutoff', 3))
CELERY_TASK_NAME = os.environ.get('uls_celery_task_name', 'mmf.core.tasks.update_user_last_seen_task')
CELERY_QUEUE = os.environ.get('uls_celery_queue', 'update_user_last_login')
class CeleryConfig(object):
    BROKER_HOST = os.environ.get('uls_broker_host', 'localhost')
    BROKER_PORT = int(os.environ.get('uls_broker_port', 5672))
    BROKER_USER = os.environ.get('uls_broker_usr', 'guest')
    BROKER_PASSWORD = os.environ.get('uls_broker_password', 'guest')
    BROKER_VHOST = os.environ.get('uls_broker_vhost', '/')
    CELERY_ROUTES = {
        CELERY_TASK_NAME: {'queue': CELERY_QUEUE},
    }    
mmf_celery = celery.Celery()
mmf_celery.config_from_object(CeleryConfig)
def celery_task_errback(error):
    raise error
def send_celery_task(batch):    
    print str(batch)
    d = threads.deferToThread(mmf_celery.send_task,
                              CELERY_TASK_NAME,
freebayes_repository_name = 'freebayes_0040'
freebayes_repository_description = "Galaxy's freebayes tool for test 0040"
freebayes_repository_long_description = "Long description of Galaxy's freebayes tool for test 0040"
filtering_repository_name = 'filtering_0040'
filtering_repository_description = "Galaxy's filtering tool for test 0040"
filtering_repository_long_description = "Long description of Galaxy's filtering tool for test 0040"
class TestRepositoryCircularDependencies( ShedTwillTestCase ):
    '''Verify that the code correctly displays repositories with circular repository dependencies.'''
    def test_0000_initiate_users( self ):
        """Create necessary user accounts."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % test_user_1_email
        

        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % admin_email
        admin_user_private_role = test_db_util.get_private_role( admin_user )
  
    def test_0005_create_category( self ):
        """Create a category for this test suite"""
        self.create_category( name='test_0040_repository_circular_dependencies', description='Testing handling of circular repository dependencies.' )
    def test_0010_create_freebayes_repository( self ):
        '''Create and populate freebayes_0040.'''
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        repository = self.get_or_create_repository( name=freebayes_repository_name, 
                                                    description=freebayes_repository_description

                                                    long_description=freebayes_repository_long_description, 
                                                    owner=common.test_user_1_name,
                                                    categories=[ 'test_0040_repository_circular_dependencies' ], 
                                                    strings_displayed=[] )
        self.upload_file( repository, 
                          filename='freebayes/freebayes.tar', 
                          filepath=None,
                          valid_tools_only=True,
                          uncompress_file=True,
                          remove_repo_files_not_in_tar=False,
                          commit_message='Uploaded the tool tarball.',
                          strings_displayed=[], 
                          strings_not_displayed=[] )
    def test_0015_create_filtering_repository( self ):
        '''Create and populate filtering_0040.'''
        self.logout()
        self.log
app = Flask(__name__)
api_base = "/api/v1"
@app.route(api_base + '/repos/', methods=['GET'])
def list_repositories():
    repository_list = repositories.load_repository_list()
    return jsonify({"repositories": repository_list})
@app.route(api_base + '/repos/<namespace>/<repository>', methods=['GET'])
def get_repository(namespace, repository):
    repository_info = repositories.load_repository_info('%s/%s' % (namespace, repository))
    return jsonify(repository_info)
@app.route(api_base + '/repos/<namespace>/<repository>/builds/<build_id>/logs', methods=['GET'])
def get_build_logs(namespace, repository, build_id):
    return jsonify(repositories.load_build_logs('%s/%s' % (namespace, repository), build_id))
@app.route(api_base + '/github/pushes/<organization>/', methods=['POST'])
def receive_github_webhook(organization):
    print request.get_json()
    github.handle_push(request.get_json())
    return jsonify({"success": True})
if __name__ == '__main__':
    print os.environ
    app.
def repository_list(request):
    """all repository list"""
    repositories = [(index+1, item) for index, item in enumerate(Repository.objects.filter(active=True).order_by('-created_date'))]
    return render(request, 'repository/repository_page.html',
        {'repositories': repositories})
def repository_main(request, repo_id):
    """显示仓库目录信息"""
    reference_name = request.GET.get('reference_name', '')
    file_path = request.GET.get('file_path', '')
    repository = Repository.objects.get(id=repo_id)
    repo_option = RepoOptions(repository.path)
    repo = repo_option.repo
    last_commit = ''
    if not reference_name and repo.references:
        reference_name = repo.references[0].name
    if reference_name:
        last_commit = repo.commit(reference_name)
    result = repo_option.ls_tree(reference_name, file_path)
    request.session['repository_id'] = repo_id
    request.session['repository_name'] = repository.name
    href = '/repository/repository_main/%s?reference_name=%

    current_path = path_to_url(file_path, href)
    if current_path:
        current_path = '/' + current_path
    current_path = '<a href="/repository/repository_main/%s">%s</a>' % (repository.id, repository.name) + current_path
    commit_count = repo_option.reference_commit_count(reference_name)
    return render(request, 'repository/repository.html', {'repository': repository, 'references': repo.references,
        'current_reference': reference_name, 'last_commit': last_commit, 'file_list': result,
        'current_path': current_path, 'commit_count': commit_count})
def add_repository(request):
    """create new repository"""
    repository_name = request.POST.get('repository_name', '')
    repository_description = request.POST.get('repository_description', '')
    repository_path = os.path.join(GIT_REPOSITORIES, repository_name)
    if not repository_path.endswith('.git'):
        repository_path = ''.join([repository_path, '.git'])
    os.makedirs(repository_path)
    repo = Re

    repository = Repository(name=repository_name, path=repository_path, created_date=get_current_time(), description=repository_description)
    repository.save()
    return HttpResponseRedirect('/repository/repository_list/')
def repository_file_content(request, repo_id):
    """show repository file content"""
    revision = request.GET.get('revision', '')
    file_path = request.GET.get('file_path', '')
    repository = Repository.objects.get(id=repo_id)
    repo_option = RepoOptions(repository.path)
    file_content = repo_option.show_file_content(revision, file_path).replace('\n', '<br>')
    return render(request, 'repository/file_content.html', {'repository':repository, 'file_path': file_path,'file_content': file_content})
def reference_log(request, repo_id):
    """show refernce all log"""
    reference_name = request.GET.get('reference_name', '')
    repository = Repository.objects.get(id=repo_id)
    repo_option = RepoOptions(repository.path)
    status, all_commit = repo_opt
def main():
    rootobj_def = pb.getObjectAt("localhost", 8800, 30)
    rootobj_def.addCallbacks(got_rootobj)
    obj2_def = getSomeObjectAt("localhost", 8800, 30, "two")
    obj2_def.addCallbacks(got_obj2)
    obj3_def = getSomeObjectAt("localhost", 8800, 30, "three")
    obj3_def.addCallbacks(got_obj3)
    reactor.run()
def got_rootobj(rootobj):
    print "got root object:", rootobj
    print "telling root object to do foo(A)"
    rootobj.callRemote("foo", "A")
def got_obj2(obj2):
    print "got second object:", obj2
    print "telling second object to do foo(B)"
    obj2.callRemote("foo", "B")
def got_obj3(obj3):
    print "got third object:", obj3
    print "telling third object to do foo(C)"
    obj3.callRemote("foo", "C")
class my_ObjectRetrieval(pb._ObjectRetrieval):
    def __init__(self, broker, d, objname):
        pb._ObjectRetrieval.__init__(self, broker, d)
        self.objname = objname
    def connectionMade(self):
        assert not self.term, "How did this get called?"
urlpatterns = patterns('pydesk.apps.configuration.user.views',
    url(r'^/list[/]?$', 'user_list', name='user_list'),
    url(r'^/edit[/]?$', 'user_edit', name='user_edit'),
    url(r'^/add[/]?$', 'user_add', name='user_add'),
    url(r'^/ajax/list[/]?$', 'user_ajax_list', name='user_ajax_list'),
    url(r'^/ajax/add/save[/]?$', 'user_ajax_add_save', name='user_ajax_add_save'),
    url(r'^/ajax/edit/save[/]?$', 'user_ajax_edit_save', name='user_ajax_edit_save'),
    url(r'^/enterprise/edit[/]?$', 'user_enterprise_edit', name='user_enterprise_edit'),
    url(r'^/enterprise/ajax/edit/save[/]?$', 'user_enterprise_ajax_edit_save', name='user_enterprise_ajax_edit_save'),
    url(r'^/equip/edit[/]?$', 'user_equip_edit', name='user_equip_edit'),
    url(r'^/equip/ajax/edit/save[/]?$', 'user_equip_ajax_edit_save', name='user_equip_ajax_edit_save'),
    url(r'^/project/edit[/]?$', 'user_project_edit', name='user_project_edit'),
    url(r'^/project/ajax/edit/save[/]?$', 'user_project_ajax_edit_
def setup_routing(app):
    app.route('/img/<filename>', 'GET', AssetsController.img)
    app.route('/js/<filename>', 'GET', AssetsController.js)
    app.route('/js/lib/<filename>', 'GET', AssetsController.js_lib)
    app.route('/css/<filename>', 'GET', AssetsController.css)
    app.route('/css/lib/<filename>', 'GET', AssetsController.css_lib)
    app.route('/css/lib/font/<filename>', 'GET', AssetsController.css_lib_font)
    app.route('/css/fonts/<filename>', 'GET', AssetsController.css_fonts)
    app.route('/swf/<filename>', 'GET', AssetsController.swf)
    app.route('/favicon.ico', 'GET', AssetsController.favicon)
    app.route('/favicon.png', 'GET', AssetsController.favicon)
    app.route('/files/movies/<filename>', 'GET', FilesController.movies)
    app.route('/error/404', 'GET', ErrorsController().error_404)
    app.route('/error/500', 'GET', ErrorsController().error_500)
    app.route('/', 'GET', IndexController().index)
    app.route('/music', 'GET', MusicController().index)
  
datatypes_repository_name = 'emboss_datatypes_0020'
datatypes_repository_description = "Galaxy applicable data formats used by Emboss tools."
datatypes_repository_long_description = "Galaxy applicable data formats used by Emboss tools.  This repository contains no tools."
emboss_repository_name = 'emboss_0020'
emboss_repository_description = 'Galaxy wrappers for Emboss version 5.0.0 tools for test 0020'
emboss_repository_long_description = 'Galaxy wrappers for Emboss version 5.0.0 tools for test 0020'
base_datatypes_count = 0
repository_datatypes_count = 0
class ToolWithRepositoryDependencies( ShedTwillTestCase ):
    '''Test installing a repository with repository dependencies.'''
  
    def test_0000_initiate_users( self ):
        """Create necessary user accounts."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is no

        test_user_1_private_role = self.test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
        self.galaxy_logout()
        self.galaxy_login( email=common.admin_email, username=common.admin_username )
        galaxy_admin_user = self.test_db_util.get_galaxy_user( common.admin_email )
        assert galaxy_admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        galaxy_admin_user_private_role = self.test_db_util.get_galaxy_private_role( galaxy_admin_user )
    def test_0005_ensure_repositories_and_categories_exist( self ):
        '''Create the 0020 category and any mi

        global repository_datatypes_count
        category = self.create_category( name='Test 0020 Basic Repository Dependencies', description='Test 0020 Basic Repository Dependencies' )
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        datatypes_repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                                              description=datatypes_repository_description, 
                                                              long_description=datatypes_repository_long_description, 
                                                              owner=common.test_user_1_name,
                                                              category_id=self.security.encode_id( category.id ), 
                                                              strings_displayed=[] )
        if self.repository_is_new( datatypes_repository ):
            self.upload_file
class ControllerTestCase(unittest.TestCase):
    @patch('chaser.controller.gpio')
    def test_init(self, io):
        io.OUT = True
        calls = [call(4, True), call(17, True), call(24, True), call(25, True)]
        MotorController()
        io.setup.assert_has_calls(calls)
    @patch('chaser.controller.gpio')
    def test_shut_down(self, io):
        controller = MotorController()
        io.reset_mock()
        controller.shut_down()
        calls = [call(4, False), call(17, False), call(24, False), call(25, False)]
        io.output.assert_has_calls(calls)
    @patch('chaser.controller.gpio')
    def test_left(self, io):
        controller = MotorController()
        controller.left()
        calls = [call(24, True), call(25, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'left')
    @patch('chaser.controller.gpio')
    def test_left_stop(self, io):
        controller = MotorController()
        controller.turn_keys.add(LEFT_KEY)
  

        calls = [call(24, False), call(25, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'stopped')
    @patch('chaser.controller.gpio')
    def test_right(self, io):
        controller = MotorController()
        controller.right()
        calls = [call(25, True), call(24, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'right')
    @patch('chaser.controller.gpio')
    def test_right_stop(self, io):
        controller = MotorController()
        controller.turn_keys.add(RIGHT_KEY)
        controller.right()
        calls = [call(25, False), call(24, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'stopped')
    @patch('chaser.controller.gpio')
    def test_forward(self, io):
        controller = MotorController()
        controller.forward()
        calls = [call(4, True), call(17, False)]
        io.output.assert_has_calls(calls)
        self.asser

    @patch('chaser.controller.gpio')
    def test_forward_stop(self, io):
        controller = MotorController()
        controller.progress_keys.add(UP_KEY)
        controller.forward()
        calls = [call(4, False), call(17, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'stopped')
    @patch('chaser.controller.gpio')
    def test_reverse(self, io):
        controller = MotorController()
        controller.reverse()
        calls = [call(17, True), call(4, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'backwards')
    @patch('chaser.controller.gpio')
    def test_reverse_stop(self, io):
        controller = MotorController()
        controller.progress_keys.add(DOWN_KEY)
        controller.reverse()
        calls = [call(17, False), call(4, False)]
        io.output.assert_has_calls(calls)
        self.assertEqual(controller.state, 'stopped')
    @patch('chaser.controller.gpio')
    def te
BROKER_HOST = 'localhost'
BROKER_PORT = 5672
BROKER_USER = "test"
BROKER_PASSWORD = "test"
BROKER_VHOST = "/"
def get_pika_connection():
    """Set up a connection with a messages broker using pika library."""
    credentials = pika.PlainCredentials(BROKER_USER,
                                        BROKER_PASSWORD)
    parameters = pika.ConnectionParameters(credentials=credentials,
                                           host=BROKER_HOST,
                                           virtual_host=BROKER_VHOST)
    connection = pika.BlockingConnection(parameters)
    return connection
def get_channel(pika_connection, queue):
    """Set up a channel and a queue for a given pika connection."""
    channel = pika_connection.channel()
    channel.queue_declare(queue=queue, durable=True,
                          exclusive=False, auto_delete=False)
    return channel
def publish_message(message, channel, routing_key):
    """Publish a message to a channel with a specific routing key."""
 
DB_SHARED_THREAD = """\
DatabaseWrapper objects created in a thread can only \
be used in that same thread.  The object with alias '{0}' \
was created in thread id {1} and this is thread id {2}.\
"""
def patch_thread_ident():
    if getattr(patch_thread_ident, 'called', False):
        return
    try:
        if 'validate_thread_sharing' in BaseDatabaseWrapper.__dict__:
            _get_ident = thread.get_ident
            __old__init__ = BaseDatabaseWrapper.__init__
            def _init(self, *args, **kwargs):
                __old__init__(self, *args, **kwargs)
                self._thread_ident = _get_ident()
            def _validate_thread_sharing(self):
                if (not self.allow_thread_sharing
                        and self._thread_ident != _get_ident()):
                    raise DatabaseError(
                        DB_SHARED_THREAD % (
                            self.alias, self._thread_ident, _get_ident()),
                    )
            BaseDatabaseWrapper._

            BaseDatabaseWrapper.validate_thread_sharing = \
                _validate_thread_sharing
        patch_thread_ident.called = True
    except ImportError:
        pass
patch_thread_ident()
class CeleryCommand(BaseCommand):
    options = BaseCommand.option_list
    skip_opts = ['--app', '--loader', '--config']
    keep_base_opts = False
    def get_version(self):
        return 'celery {c.__version__}\ndjango-celery {d.__version__}'.format(
            c=celery, d=djcelery,
        )
    def execute(self, *args, **options):
        broker = options.get('broker')
        if broker:
            self.set_broker(broker)
        super(CeleryCommand, self).execute(*args, **options)
    def set_broker(self, broker):
        os.environ['CELERY_BROKER_URL'] = broker
    def run_from_argv(self, argv):
        self.handle_default_options(argv[2:])
        return super(CeleryCommand, self).run_from_argv(argv)
    def handle_default_options(self, argv):
        acc = []
        broker = 
class HTTPMVCMapper(object):
  compReg = outlet('ComponentRegistry')
  httpRequestMapper = outlet('HTTPRequestMapper')
  app       = outlet('Application')
  scheduler = outlet('Scheduler')
  
  def assembled(self):
    self.httpRequestMapper.registerLocationHandler(self)
    
    self.controller_names = []
    self.map = routes.Mapper(controller_scan=self.controller_names)
    self.map.minimization=True
    
    mod_names = ['Rambler', self.app.name] + [ext.name for ext in self.app.config.extensions]
    for mod_name in mod_names:
      mod_full_name = mod_name + ".web_controllers"
      for cls in load_classes(mod_full_name, component('WebController')):
        if hasattr(cls, "provides"):
          name = cls.provides
        else:
          name = cls.__name__
        self.compReg.addComponent(name, cls)
        controller_name = name.split('Controller',1)[0].lower()
        self.controller_names.append(controller_name)
       
      try:
        routes_mod_name = mod_full_name + '.

        routes_mod = sys.modules[routes_mod_name]
        routes_mod.add_routes(self.map)
      except(ImportError):
        pass
    
  def dispatch(self, request):
    match = self.map.match(environ=request.environ)
    
    if match:
      controller_name = self.camelHump(match['controller']) + "Controller"
      action = match['action']
      
      try:
        cls = self.compReg.lookup(controller_name)
      except KeyError:
        return None
      controller = cls(request)
      controller.routing = match
      
      if hasattr(controller, action):
        controller.app = self.app
        controller.action = action    
        return controller.process()
    
  def handleHTTPRequest(self, request, startResponse):
    return None
    
    path = request[PATH_INFO_KEY]
    routed = True
    controller, action = "DefaultController", "index"
   
    m = self.controllerActionExp.match(path)
    if(m):
      parts = m.groupdict()
      controller = parts['controller'] or controll
def _CheckChange(input_api, output_api):
  results = []
  results += input_api.canned_checks.CheckDoNotSubmit(input_api, output_api)
  results += input_api.canned_checks.CheckChangeHasNoTabs(input_api, output_api)
  results += input_api.canned_checks.CheckLongLines(input_api, output_api, 80)
  lint_results = _Lint(input_api, output_api)
  results += lint_results
  if lint_results:
    print 'Not running unit tests, please fix lint errors first.'
  else:
    results += _UnitTests(input_api, output_api)
  return results
def _GetWptTestCommand(input_api, output_api):
  agent_dir = input_api.PresubmitLocalPath()
  if input_api.platform == 'win32':
    return ('cmd', '/c', input_api.os_path.join(agent_dir, 'wpttest.bat'))
  else:
    return (input_api.os_path.join(agent_dir, 'wpttest.sh'),)
def _RunWptTest(input_api, output_api, name, *flags):
  wpttest_command = _GetWptTestCommand(input_api, output_api) + flags
  command = input_api.Command(
    name=name,
    cmd=wpttest_command,
    kwar
'''
**/Xfero/ Module:**
+-----------------------------------+------------------------------------------+
| Type                              | Brief Description                        |
+===================================+==========================================+
| Func: create_XFERO_DB.create_db   | Database creation function               |
+-----------------------------------+------------------------------------------+
| Func: manage_control              | Control table CRUD functions             |
+-----------------------------------+------------------------------------------+
| Func: manage_cots_pattern         | COTS Pattern table CRUD functions        |
+-----------------------------------+------------------------------------------+
| Func: manage_function             | Function table CRUD functions            |
+-----------------------------------+------------------------------------------+
| Func: manage_partner              | Partner table CRUD functions             |
+---

| Func: manage_priority             | Priority table CRUD functions            |
+-----------------------------------+------------------------------------------+
| Func: manage_route                | Route table CRUD functions               |
+-----------------------------------+------------------------------------------+
| Func: manage_schedule             | Scheduler table CRUD functions           |
+-----------------------------------+------------------------------------------+
| Func: manage_workflow             | Workflow table CRUD functions            |
+-----------------------------------+------------------------------------------+
| Func: manage_xfer                 | Xfer table CRUD functions                |
+-----------------------------------+------------------------------------------+
+------------+-------------+---------------------------------------------------+
| Date       | Author      | Change Details                                    |
+============+=============
class TestCase(TestCase):
    def setUp(self):
        self.configuration = Configuration()
        class Example(Resource):
            configuration = self.configuration
            name = 'example'
            version = 1
        self.resource_1 = Example
        class Example(Example):
            name = 'example'
            version = 2
        self.resource_2 = Example
        class ExampleController(Controller):
            resource = Example
            version = (1, 0)
        self.controller_1_0 = ExampleController
        class ExampleController(ExampleController):
            resource = Example
            version = (1, 1)
        self.controller_1_1 = ExampleController
        class ExampleController(ExampleController):
            resource = Example
            version = (2, 0)
        self.controller_2_0 = ExampleController
        class ExampleController(ExampleController):
            resource = Example
            version = (2, 1)
        self.controller_2_1 = Example

        self.Example = Example
        self.ExampleController = ExampleController
class TestMount(TestCase):
    def test_null_mount(self):
        m = mount(None)
        m.construct(None)
        for attr in ('resource', 'controller', 'min_version', 'max_version'):
            self.assertIs(getattr(m, attr, None), None)
    def test_mount_with_controller(self):
        m = mount(self.Example, self.ExampleController)
        m.construct(None)
        self.assertIs(m.resource, self.Example)
        self.assertIs(m.controller, self.ExampleController)
        self.assertEqual(m.min_version, (1, 0))
        self.assertEqual(m.max_version, (2, 1))
        self.assertEqual(m.versions, [(1, 0), (1, 1), (2, 0), (2, 1)])
    def test_mount_with_min_version(self):
        m = mount(self.Example, self.ExampleController, min_version=(1, 1))
        m.construct(None)
        self.assertEqual(m.min_version, (1, 1))
        self.assertEqual(m.max_version, (2, 1))
        self.assertEqual(m.versions
def check_dispatch(ep, *args, **kwds):
    return ep.name == 't2'
class TestDispatch(utils.TestCase):
    def check_dispatch(ep, *args, **kwds):
        return ep.name == 't2'
    def test_dispatch(self):
        def invoke(ep, *args, **kwds):
            return (ep.name, args, kwds)
        em = dispatch.DispatchExtensionManager('stevedore.test.extension',
                                               lambda *args, **kwds: True,
                                               invoke_on_load=True,
                                               invoke_args=('a',),
                                               invoke_kwds={'b': 'B'},
                                               )
        self.assertEqual(len(em.extensions), 2)
        self.assertEqual(set(em.names()), set(['t1', 't2']))
        results = em.map(check_dispatch,
                         invoke,
                         'first',
                         named='named value',
                         )
        expected = [

        self.assertEqual(results, expected)
    def test_dispatch_map_method(self):
        em = dispatch.DispatchExtensionManager('stevedore.test.extension',
                                               lambda *args, **kwds: True,
                                               invoke_on_load=True,
                                               invoke_args=('a',),
                                               invoke_kwds={'b': 'B'},
                                               )
        results = em.map_method(check_dispatch, 'get_args_and_data', 'first')
        self.assertEqual(results, [(('a',), {'b': 'B'}, 'first')])
    def test_name_dispatch(self):
        def invoke(ep, *args, **kwds):
            return (ep.name, args, kwds)
        em = dispatch.NameDispatchExtensionManager('stevedore.test.extension',
                                                   lambda *args, **kwds: True,
                                                   invoke_on_load=True,
                     

                                                   invoke_kwds={'b': 'B'},
                                                   )
        self.assertEqual(len(em.extensions), 2)
        self.assertEqual(set(em.names()), set(['t1', 't2']))
        results = em.map(['t2'], invoke, 'first', named='named value',)
        expected = [('t2', ('first',), {'named': 'named value'})]
        self.assertEqual(results, expected)
    def test_name_dispatch_ignore_missing(self):
        def invoke(ep, *args, **kwds):
            return (ep.name, args, kwds)
        em = dispatch.NameDispatchExtensionManager(
            'stevedore.test.extension',
            lambda *args, **kwds: True,
            invoke_on_load=True,
            invoke_args=('a',),
            invoke_kwds={'b': 'B'},
        )
        results = em.map(['t3', 't1'], invoke, 'first', named='named value',)
        expected = [('t1', ('first',), {'named': 'named value'})]
        self.assertEqual(results, expected)
    def test_name_di
urlpatterns = [
	url(r'^main/$', views.main,
                    name = 'events_manage_main'),
    url(r'^results/(?P<user_id>\d+)',
        views.edit_or_create_result,
                    name = 'events_manage_edit_or_create_result'),
    url(r'^results/$', views.show_results,
                    name = 'events_manage_show_results'),
    url(r'^choose/(?P<role>\w+)/$', views.choose_users,
                    name = 'events_manage_choose_users'),
    url(r'^invite/(?P<uid>\d+)/(?P<role>\w+)/$', views.invite,
                    name = 'events_manage_invite'),
    url(r'^exclude/(?P<uid>\d+)/(?P<role>\w+)/$', views.exclude,
                    name = 'events_manage_exclude'),
    url(r'^requests', views.show_requests,
                    name = 'events_manage_show_requests'),
    url(r'^accept/(?P<request_id>\d+)/$', views.accept_request,
                    name = 'events_manage_accept_request'),
    url(r'^place_request', views.place_request, 
                    name = 'events_manag
SConscript('extlibs/gtest/SConscript')
Import('env')
if env.get('RELEASE'):
	env.AppendUnique(CCFLAGS = ['-Os'])
	env.AppendUnique(CPPDEFINES = ['NDEBUG'])
else:
	env.AppendUnique(CCFLAGS = ['-g'])
if env.get('LOGGING'):
	env.AppendUnique(CPPDEFINES = ['TB_LOG'])
lib_env = env.Clone()
SConscript(env.get('SRC_DIR') + '/service/third_party_libs.scons', 'lib_env')
src_dir = lib_env.get('SRC_DIR')
broker_test_env = lib_env.Clone()
target_os = env.get('TARGET_OS')
broker_test_env.AppendUnique(CPPPATH = ['../include'])
broker_test_env.AppendUnique(CPPPATH = ['../../../include'])
broker_test_env.AppendUnique(CPPPATH = ['../../common/primitiveResource/include'])
broker_test_env.AppendUnique(CPPPATH = ['../../common/expiryTimer/include'])
broker_test_env.AppendUnique(CPPPATH = ['../../common/expiryTimer/src'])
broker_test_env.AppendUnique(CPPPATH = ['../../common/utils/include'])
broker_test_env.PrependUnique(CPPPATH = [env.get('SRC_DIR')+'/extlibs/hippomocks-master'])
broker_test_env.AppendUni

broker_test_env.PrependUnique(LIBS = ['coap'])
broker_test_env.AppendUnique(LIBS = ['connectivity_abstraction'])
broker_test_env.AppendUnique(LIBS = ['oc_logger'])
broker_test_env.AppendUnique(LIBS = ['octbstack'])
broker_test_env.AppendUnique(LIBS = ['oc'])
broker_test_env.AppendUnique(LIBS = ['rcs_client'])
broker_test_env.AppendUnique(LIBS = ['rcs_common'])
broker_test_env.AppendUnique(LIBS = ['gtest'])
broker_test_env.AppendUnique(LIBS = ['gtest_main'])
if target_os not in ['windows', 'winrt']:
    broker_test_env.AppendUnique(CXXFLAGS = ['-O2', '-g', '-Wall', '-fmessage-length=0', '-std=c++0x'])
if target_os == 'linux':
    broker_test_env.AppendUnique(LIBS = ['pthread'])
broker_test_src = env.Glob('./*.cpp')
broker_test = broker_test_env.Program('broker_test', broker_test_src)
Alias("broker_test", broker_test)
env.AppendTarget('broker_test')
if env.get('TEST') == '1':
        target_os = env.get('TARGET_OS')
        if target_os == 'linux':
                run_test(broker_test_e
urlpatterns = patterns('ts_repr.views',
                        url(r'^$', IndexView.as_view(), name='ts_repr.index'),
                        url(r'^(?P<scenario_id>\d+)/$', login_required(determine_page), name='ts_repr.determine_view'),
                        url(r'^scenario/browse2/$', login_required(BrowseScenarioView.as_view()), name='ts_repr.browse_scenario2'),
                        url(r'^scenario/browse/$', login_required(ScenarioBrowseView.as_view()), name='ts_repr.browse_scenario'),
                        url(r'^new/$', login_required(NewScenarioView.as_view()), name='ts_repr.new_scenario'),
                        url(r'^weather/(?P<scenario_id>\d+)/$', login_required(WeatherView.as_view()), name='ts_repr.weather'),
                        url(r'^weather/data/(?P<option_id>\d+)/$', get_weather_data, name='ts_repr.get_weather_data'),
                        url(r'^weather/save_data/$', save_weather_data, name='ts_repr.save_weather_data'),
                        url(r'^de

                        url(r'^demographics/data/(?P<option_id>\d+)/$', get_demographics_data, name='ts_repr.get_demographics_data'),
                        url(r'^demographics/save_data/$', save_demographics_data, name='ts_repr.save_demographics_data'),
                        url(r'^species/(?P<scenario_id>\d+)/$', login_required(SpeciesView.as_view()), name='ts_repr.species'),
                        url(r'^species/data/(?P<option_id>\d+)/$', get_species_data_ajax, name='ts_repr.get_species_data'),
                        url(r'^species/save_data/$', save_species_data, name='ts_repr.save_species_data'),
                        url(r'^parasite/(?P<scenario_id>\d+)/$', login_required(ParasiteView.as_view()), name='ts_repr.parasite'),
                        url(r'^parasite/save_data/$', save_parasite_data, name='ts_repr.save_parasite_data'),
                        url(r'^details/(?P<scenario_id>\d+)/$', login_required(DetailsView.as_view()), name='ts_repr.details'),
               

                        url(r'^manage/weather/$', ManageWeatherView.as_view(), name='ts_repr.manage_weather'),
                        url(r'^manage/demographics/$', ManageDemographicsView.as_view(), name='ts_repr.manage_demographics'),
                        url(r'^manage/species/$', ManageSpeciesView.as_view(), name='ts_repr.manage_species'),
                        url(r'^manage/species_parameter/$', ManageSpeciesParameterView.as_view(), name='ts_repr.manage_species_parameter'),
                        url(r'^manage/emod_snippet/$', ManageEMODSnippetView.as_view(), name='ts_repr.manage_emod_snippet'),
                        url(r'^manage/om_snippet/$', ManageOMSnippetView.as_view(), name='ts_repr.manage_om_snippet'),
                        url(r'^scenario/delete/(?P<scenario_id>\d+)/$', delete_scenario, name='ts_repr.delete_scenario'),
                        url(r'^emod_snippet/data/(?P<option_id>\d+)/$', get_emod_snippet_ajax, name='ts_repr.emod_snippet_data'),
               
def get_faked_rangevote(_id='1', votes=None):
    if votes is None:
        votes = [{'opinions': {'a': 1, 'b': -1}, 'elector': 'G'}, {'opinions': {'a': -1, 'b': 2}, 'elector': 'V'}]
    return {'id': _id, 'votes': votes, 'randomized_choices': ['a', 'b'], 'question': 'Q?', 'choices': ['a', 'b']}
class HandlersTestCase(unittest.TestCase):
    def setUp(self):
        self.mock_repository = repository.MockRepository()
    def test_create_rangevote_handler_save_rangevote_created(self):
        create_rangevote_handler = handlers.CreateRangeVoteHandler(self.mock_repository)
        create_rangevote_handler.handle(commands.CreateRangeVoteCommand(1, 'Q?', ['a', 'b']))
        self.assertEqual(1, self.mock_repository.db[1].uuid)
        self.assertEqual('Q?', self.mock_repository.db[1].question)
        self.assertEqual(['a', 'b'], self.mock_repository.db[1].choices)
    def test_update_rangevote_handler_call_update_method(self):
        update_rangevote_handler = handlers.UpdateRangeVoteHand

        update_rangevote_handler.handle(
            commands.UpdateRangeVoteCommand(1, 'Q?', ['a', 'b'], votes=[{'elector': 'e', 'opinions': {'a': 0, 'b': 0}}]))
        self.assertEqual(1, self.mock_repository.db[1].uuid)
        self.assertEqual('Q?', self.mock_repository.db[1].question)
        self.assertEqual(['a', 'b'], self.mock_repository.db[1].choices)
        self.assertEqual('e', self.mock_repository.db[1].votes[0].elector)
        self.assertEqual({'a': 0, 'b': 0}, self.mock_repository.db[1].votes[0].opinions)
    def test_create_vote_handler_save_vote_created(self):
        self.mock_repository.db['1'] = get_faked_rangevote(votes=[])
        create_vote_handler = handlers.CreateVoteHandler(self.mock_repository)
        create_vote_handler.handle(commands.CreateVoteCommand('1', 'GV', {'a': 1, 'b': -2}))
        self.assertEqual('GV', self.mock_repository.db['1'].votes[0].elector)
        self.assertDictEqual({'a': 1, 'b': -2}, self.mock_repository.db['1'].votes[0].opinion

class QueryHandlersTestCase(unittest.TestCase):
    def setUp(self):
        self.mock_repository = repository.MockRepository()
    def test_get_rangevote_handler(self):
        self.mock_repository.db['1'] = get_faked_rangevote()
        get_rangevote_handler = handlers.GetRangeVoteHandler(self.mock_repository)
        rangevote = get_rangevote_handler.handle(queries.GetRangeVoteQuery('1'))
        self.assertEqual(self.mock_repository.db['1']['id'], rangevote['id'])
        self.assertEqual(self.mock_repository.db['1']['question'], rangevote['question'])
        self.assertListEqual(self.mock_repository.db['1']['choices'], rangevote['choices'])
    def test_get_rangevote_results_handler(self):
        self.mock_repository.db['1'] = get_faked_rangevote()
        get_rangevote_results_handler = handlers.GetRangeVoteResultsHandler(self.mock_repository)
        results = get_rangevote_results_handler.handle(queries.GetRangeVoteResultsQuery('1'))
        expected_results = {
            
class RETURN_CODE:
    ApiSuccess = 512
    ApiFailed 								= 513
    ApiAccessDenied 						= 514
    ApiDmaChannelUnavailable 				= 515
    ApiDmaChannelInvalid 					= 516
    ApiDmaChannelTypeError 					= 517
    ApiDmaInProgress 						= 518
    ApiDmaDone 								= 519
    ApiDmaPaused 							= 520
    ApiDmaNotPaused 						= 521
    ApiDmaCommandInvalid 					= 522
    ApiDmaManReady 							= 523
    ApiDmaManNotReady 						= 524
    ApiDmaInvalidChannelPriority 			= 525
    ApiDmaManCorrupted 						= 526
    ApiDmaInvalidElementIndex 				= 527
    ApiDmaNoMoreElements 					= 528
    ApiDmaSglInvalid 						= 529
    ApiDmaSglQueueFull 						= 530
    ApiNullParam 							= 531
    ApiInvalidBusIndex 						= 532
    ApiUnsupportedFunction 					= 533
    ApiInvalidPciSpace 						= 534
    ApiInvalidIopSpace 						= 535
    ApiInvalidSize 							= 536
    ApiInvalidAddress 						= 537
    ApiInvalidAccessType 					= 538
    ApiInvalidIndex 						= 539
    ApiMuNotReady 							= 540
  

    ApiMuFifoFull 							= 542
    ApiInvalidRegister 						= 543
    ApiDoorbellClearFailed 					= 544
    ApiInvalidUserPin 						= 545
    ApiInvalidUserState 					= 546
    ApiEepromNotPresent 					= 547
    ApiEepromTypeNotSupported 				= 548
    ApiEepromBlank 							= 549
    ApiConfigAccessFailed 					= 550
    ApiInvalidDeviceInfo 					= 551
    ApiNoActiveDriver 						= 552
    ApiInsufficientResources 				= 553
    ApiObjectAlreadyAllocated 				= 554
    ApiAlreadyInitialized 					= 555
    ApiNotInitialized 						= 556
    ApiBadConfigRegEndianMode 				= 557
    ApiInvalidPowerState 					= 558
    ApiPowerDown 							= 559
    ApiFlybyNotSupported 					= 560
    ApiNotSupportThisChannel 				= 561
    ApiNoAction 							= 562
    ApiHSNotSupported 						= 563
    ApiVPDNotSupported 						= 564
    ApiVpdNotEnabled 						= 565
    ApiNoMoreCap 							= 566
    ApiInvalidOffset 						= 567
    ApiBadPinDirection 						= 568
    ApiPciTimeout 							= 569
    ApiDmaChannelClos
"""
Migration script to add the repository_dependency and repository_repository_dependency_association tables.
"""
now = datetime.datetime.utcnow
log = logging.getLogger( __name__ )
log.setLevel( logging.DEBUG )
handler = logging.StreamHandler( sys.stdout )
format = "%(name)s %(levelname)s %(asctime)s %(message)s"
formatter = logging.Formatter( format )
handler.setFormatter( formatter )
log.addHandler( handler )
metadata = MetaData()
RepositoryDependency_table = Table( "repository_dependency", metadata,
    Column( "id", Integer, primary_key=True ),
    Column( "create_time", DateTime, default=now ),
    Column( "update_time", DateTime, default=now, onupdate=now ),
    Column( "tool_shed_repository_id", Integer, ForeignKey( "tool_shed_repository.id" ), index=True, nullable=False ) )
RepositoryRepositoryDependencyAssociation_table = Table( "repository_repository_dependency_association", metadata,
    Column( "id", Integer, primary_key=True ),
    Column( "create_time", DateTime, default

    Column( "update_time", DateTime, default=now, onupdate=now ),
    Column( "tool_shed_repository_id", Integer, ForeignKey( "tool_shed_repository.id" ), index=True ),
    Column( "repository_dependency_id", Integer, ForeignKey( "repository_dependency.id" ), index=True ) )
def upgrade(migrate_engine):
    print __doc__
    metadata.bind = migrate_engine
    metadata.reflect()
    try:
        RepositoryDependency_table.create()
    except Exception, e:
        log.debug( "Creating repository_dependency table failed: %s" % str( e ) )
    try:
        RepositoryRepositoryDependencyAssociation_table.create()
    except Exception, e:
        log.debug( "Creating repository_repository_dependency_association table failed: %s" % str( e ) )
def downgrade(migrate_engine):
    metadata.bind = migrate_engine
    metadata.reflect()
    try:
        RepositoryRepositoryDependencyAssociation_table.drop()
    except Exception, e:
        log.debug( "Dropping repository_repository_dependency_associa
debug = False
class FreeVarVisitor(Visitor):
    _reservedNames = ['input', 'type_error']
    heapSet = set()
    def getHeapSet(self):
        return list(self.heapSet)
    def resetHeapSet(self):
        self.heapSet.clear()
    def visitModule(self, n, args=None):
        loosies = self.dispatch(n.node)
        locVars = UniquifyVisitor().findLocals(n)
        letGoSet = loosies - set(locVars)
        self.heapSet |= letGoSet
        return letGoSet
    def visitStmt(self, n, args=None):
        loosies = set()
        for stmt in n.nodes:
            loosies |= self.dispatch(stmt)
        return loosies
    def visitLambda(self, n, args=None):
        loosies = self.dispatch(n.code)
        locVars = UniquifyVisitor().findLocals(n)
        if debug:
            print str(n.argnames) + ": " + str(
                loosies - set(locVars) - set(n.argnames))
        letGoSet = loosies - set(locVars) - set(n.argnames)
        self.heapSet |= letGoSet
        return letGoSet
    def visit

        if n.name == 'True' or n.name == 'False':
            return set([])
        return set([n.name])
    def visitPrintnl(self, n, args=None):
        return self.dispatch(n.nodes[0])
    def visitConst(self, n, args=None):
        return set([])
    def visitAssign(self, n, args=None):
        if isinstance(n.nodes[0], Subscript):
            return self.dispatch(n.expr) | self.dispatch(n.nodes[0])
        return self.dispatch(n.expr)
    def visitAssName(self, n, args=None):
        return set([])
    def visitCallFunc(self, n, args=None):
        if isinstance(n.node, Name) and (n.node.name in reservedFuncs):
            return set([])
        args = set([])
        for element in n.args:
            args |= self.dispatch(element)
        names = self.dispatch(n.node)
        return args | names
    def visitAdd(self, n, args=None):
        return self.dispatch(n.left) | self.dispatch(n.right)
    def visitIntAdd(self, n, args=None):
        return self.dispatch(n.left) | self

    def visitBigAdd(self, n, args=None):
        return self.dispatch(n.left) | self.dispatch(n.right)
    def visitUnarySub(self, n, args=None):
        return self.dispatch(n.expr)
    def visitOr(self, n, args=None):
        return self.visitList(n)
    def visitAnd(self, n, args=None):
        return self.visitList(n)
    def visitNot(self, n, args=None):
        return self.dispatch(n.expr)
    def visitCompare(self, n, args=None):
        ret = set([])
        ret |= self.dispatch(n.expr)
        ret |= self.dispatch(n.ops[0][1])
        return ret
    def visitIntCompare(self, n, args=None):
        ret = set([])
        ret |= self.dispatch(n.expr)
        ret |= self.dispatch(n.ops[0][1])
        return ret
    def visitBigCompare(self, n, args=None):
        ret = set([])
        ret |= self.dispatch(n.expr)
        ret |= self.dispatch(n.ops[0][1])
        return ret
    def visitIsCompare(self, n, args=None):
        ret = set([])
        ret |= self.dispatch(n.expr)
     
def home(request):
    form = PieceForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def GlazeView(request):
    form = GlazeLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def DocumentationView(request):
    form = DocumentationForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def ConditionChoiceView(request):
    form =

    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def ExhibitionView(request):
    form = ExhibitionForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def HeathLineLookupView(request):
    form = HeathLineLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def LogoView(request):
    form = LogoForm(request.POST or None)
    if form.is_valid():
        

        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def MakerLookupView(request):
    form = MakerLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def MaterialLookupView(request):
    form = MaterialLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                                locals(),
                                context_instance=RequestContext(request))
def MethodLookupView(request):
    form = MethodLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.
log = logging.getLogger("cliApi.__init__")
def users(*args):
    ManageUsers.users().call(*args)
def keys(*args):
    ManageUsers.keys().call(*args)
def addUser(*args):
    ManageUsers.addUser().call(*args)
    
def addKey(*args):
    ManageUsers.addKey().call(*args)
def modUser(*args):
    ManageUsers.modUser().call(*args)
def delUser(*args):
    ManageUsers.delUser().call(*args)
    
def delKey(*args):
    ManageUsers.delKey().call(*args)
    
def passwd(*args):
    ManageUsers.passwd().call(*args)
def whoami(*args):
    ManageUsers.whoami().call(*args)
    
def jobs(*args):
    ManageJobs.CliJobs().call(*args)
def stopJob(*args):
    ManageJobs.stopJob().call(*args)
    
def addDummyJob(*args):
    ManageJobs.addDummyJob().call(*args)
    
def hosts(*args):
    ManageHosts.hosts().call(*args)
    
def addHost(*args):
    ManageHosts.addHost().call(*args)
    
def modHost(*args):
    ManageHosts.modHost().call(*args)
    
def delHost(*args):
    ManageHosts.delHost().call(*args)
    

def checkHost(*args):
    ManageHosts.checkHost().call(*args)
def nets(*args):
    ManageNets.nets().call(*args)
def addNet(*args):
    ManageNets.addNet().call(*args)
def delNet(*args):
    ManageNets.delNet().call(*args)
    
def startNet(*args):
    ManageNets.startNet().call(*args)
def stopNet(*args):
    ManageNets.stopNet().call(*args)
    
def refreshNet(*args):
    ManageNets.refreshNet().call(*args)
    
def vms(*args):
    ManageVms.vms().call(*args)
def addVm(*args):
    ManageVms.addVm().call(*args)
def delVm(*args):
    ManageVms.delVm().call(*args)
    
def startVm(*args):
    ManageVms.startVm().call(*args)
def stopVm(*args):
    ManageVms.stopVm().call(*args)
    
def refreshVm(*args):
    ManageVms.refreshVm().call(*args)
    
def vmAddInterface(*args):
    ManageVms.vmAddInterface().call(*args)
    
def vmDelInterface(*args):
    ManageVms.vmDelInterface().call(*args)
def prepareVm(*args):
    ManageVms.prepareVm().call(*args)
    
def deployVm(*args):
    ManageVms.

    
def resetVm(*args):
    ManageVms.resetVm().call(*args)
def totalResetVm(*args):
    ManageVms.totalResetVm().call(*args)
    
def apps(*args):
    ManageApps.apps().call(*args)
    
def addApp(*args):
    ManageApps.addApp().call(*args)
    
def delApp(*args):
    ManageApps.delApp().call(*args)
    
def addAppUser(*args):
    ManageApps.addAppUser().call(*args)
    
def delAppUser(*args):
    ManageApps.delAppUser().call(*args)
    
def addAppVm(*args):
    ManageApps.addAppVm().call(*args)
    
def delAppVm(*args):
    ManageApps.delAppVm().call(*args)
    
def resetApp(*args):
    ManageApps.resetApp().call(*args)
def compileApp(*args):
    ManageApps.compileApp().call(*args)
    
def startApp(*args):
    ManageApps.startApp().call(*args)
    
def stopApp(*args):
    ManageApps.stopApp().call(*args)
def interruptApp(*args):
    ManageApps.interruptApp().call(*args)
    
def refreshGitApp(*args):
    ManageApps.refreshGitApp().call(*args)
    
def refreshAndResetApp(*args):
  
"""Tests for `maasserver.websockets.handlers.packagerepository`"""
__all__ = []
    dehydrate_datetime,
    HandlerPermissionError,
    PackageRepositoryHandler,
class TestPackageRepositoryHandler(MAASServerTestCase):
    def setUp(self):
        super().setUp()
        self.patch(
            forms_packagerepository_module,
            'validate_dhcp_config').return_value = []
    def dehydrate(self, package_repository):
        return {
            'id': package_repository.id,
            'name': package_repository.name,
            'url': package_repository.url,
            'distributions': package_repository.distributions,
            'disabled_pockets': package_repository.disabled_pockets,
            'disabled_components': package_repository.disabled_components,
            'components': package_repository.components,
            'arches': package_repository.arches,
            'key': package_repository.key,
            'default': package_repository.default,
            'enabled'

            'updated': dehydrate_datetime(package_repository.updated),
            'created': dehydrate_datetime(package_repository.created),
        }
    def test_list(self):
        PackageRepository.objects.all().delete()
        user = factory.make_User()
        handler = PackageRepositoryHandler(user, {})
        expected_package_repositories = [
            self.dehydrate(factory.make_PackageRepository())
            for _ in range(3)
        ]
        self.assertItemsEqual(expected_package_repositories, handler.list({}))
    def test_create_is_admin_only(self):
        user = factory.make_User()
        handler = PackageRepositoryHandler(user, {})
        self.assertRaises(
            HandlerPermissionError,
            handler.create, {})
    def test_create(self):
        user = factory.make_admin()
        handler = PackageRepositoryHandler(user, {})
        package_repository_name = factory.make_name('package_repository_name')
        handler.create({
            'name':

            'url': factory.make_url(scheme='http'),
        })
        self.assertIsNotNone(
            PackageRepository.objects.get(name=package_repository_name))
    def test_update_is_admin_only(self):
        user = factory.make_User()
        handler = PackageRepositoryHandler(user, {})
        self.assertRaises(
            HandlerPermissionError,
            handler.update, {})
    def test_update(self):
        user = factory.make_admin()
        handler = PackageRepositoryHandler(user, {})
        package_repository = factory.make_PackageRepository()
        url = factory.make_url(scheme='http')
        handler.update({
            'id': package_repository.id,
            'url': url
        })
        package_repository = reload_object(package_repository)
        self.assertEquals(url, package_repository.url)
    def test_delete_is_admin_only(self):
        user = factory.make_User()
        handler = PackageRepositoryHandler(user, {})
        self.assertRaises(
           
__doc__ = """
Front-End Interface for ZNNv4
Jingpeng Wu <jingpeng.wu@gmail.com>,
Nicholas Turner <nturner@cs.princeton.edu>, 2015
"""
def record_config_file(params=None, config_filename=None, net_save_filename=None,
    timestamp=None, train=True):
    '''
    Copies the config file used for the current run of ZNN under the same
    prefix as the network save prefix
    Format: {net_save_prefix}_{train/forward}_{timestamp}.cfg
    e.g. net_train_20151007_17:48:55.cfg
    '''
    utils.assert_arglist(params,
        [config_filename, net_save_filename]
        )
    if params is not None:
        _config_filename = params['fconfig']
        if train:
            _net_save_filename = params['train_net']
        else:
            _net_save_filename = params['']
    if config_filename is not None:
        _config_filename = config_filename
    if net_save_filename is not None:
        _net_save_filename = net_save_filename
    save_prefix = os.path.splitext( _net_save_filename )[0]
    con

    assert(config_file_exists)
    save_prefix_valid = len(save_prefix) > 0
    assert(save_prefix_valid)
    if timestamp is None:
        timestamp = utils.timestamp()
    mode = "train" if train else "forward"
    directory_name = os.path.dirname( save_prefix )
    if not os.path.exists(directory_name):
        os.mkdir(directory_name)
    save_filename = "{}_{}_{}.cfg".format(save_prefix, mode, timestamp)
    shutil.copy( _config_filename, save_filename)
def make_logfile_name(params=None, net_save_filename=None, timestamp = None, train=True):
    '''
    Returns the name of the logfile for the current training/forward pass run
    '''
    utils.assert_arglist(params,
        [net_save_filename])
    if params is not None:
        if train:
            _net_save_filename = params['train_net']
        else:
            _net_save_filename = params['output_prefix']
    if net_save_filename is not None:
        _net_save_filename = net_save_filename
    save_prefix = os.path.splitext( 
def getName():
    return "html"
def output(state,information):
    categories = information.listCategories()
    selections = state.selected
    toSave     = ""
    toSave    += """
<html>
    <head>
    </head>
    <body>
\n
"""
    firstOne = True
    for category in categories:
        found = 0
        for selection in selections:
            if information.getCategory(selection) == category:
                if state.comments[selection] :
                    found += 1
                    if found == 1:
                        if not firstOne:
                            toSave += "</ul>\n"
                        toSave += "<h2>" + category + "</h2>\n<ul>\n"
                        firstOne = False
                    toSave += "\n<li>\n<h3>"+ selection+"</h3><br/>\n"
                    commentLines = state.comments[selection].split("\n")
                    for line in commentLines :
                        toSave += line+"<br/>\n"
                    toSave += "</li>\n"
    to
"""
Created on Mon Jan 02 20:18:09 2017
@author: Noppharut
"""
if __name__ == '__main__':
    threads = []
    dictAllActivePortInTDA = {}
    lock = RWLock()
    try:
        f = open("TDAConfig.txt")
        controller = f.readline()
        controller = controller.split("=")
        controller = controller[1].strip()
        controllerIP = f.readline()
        controllerIP =  controllerIP.split("=")
        controllerIP = controllerIP[1].strip()
        controllerPort = f.readline()
        controllerPort = controllerPort.split("=")
        controllerPort = controllerPort[1].strip()
        
        mininetOption = f.readline()
        mininetOption = mininetOption.split("=")
        mininetOption = mininetOption[1].strip()
        communityString = f.readline()
        communityString = communityString.split("=")
        communityString = communityString[1].strip()
        
        print("Controller ip : " + controllerIP)
        print("Controller port : " + controllerPort)
       

        print("Community String : " + communityString)
        
        for switchIP in f:
            try:
                print(switchIP.replace("\n",""))
                if controller.lower() == "pox":
                    thread = switchPOX.Switch( controllerIP , int(controllerPort) , 8192 , switchIP.replace("\n","") , dictAllActivePortInTDA , lock , int(mininetOption) , communityString )
                else:
                    thread = switchRyu.Switch( controllerIP , int(controllerPort) , 8192 , switchIP.replace("\n","") , dictAllActivePortInTDA , lock , int(mininetOption) , communityString )
                thread.start()
                threads.append(thread)
            except Exception as err:
                print( "Handling run-time error : " + str(err) )
        for t in threads:
            t.join()
        
    except Exception as err:
        print( "Handling run-time error : " + str(err) )
    f.close()  
"""
    threads = []
    thread1 = switch.Switch( '192.168.90.
admin.autodiscover()
urlpatterns = patterns('',
    url(r'^grappelli/', include('grappelli.urls')),
    url(r'^admin/', include(admin.site.urls)),
    url(r'^favicon.ico/$', RedirectView.as_view(url='/static/images/favicon.png')),
    url(r'^accounts/login/$', 'engine.account.userlogin', name='userlogin'),
    url(r'^accounts/logout/$', 'django.contrib.auth.views.logout', {
        'next_page': '/accounts/login/'}, name="userlogout"),
    url(r'^accounts/changepassword/$', 'engine.account.changepassword', name='changepassword'),
    url(r'^$', 'engine.views.index'),
    url(r'^manage/class/$', 'engine.class.index', name='manageclass'),
    url(r'^manage/addclass/$', 'engine.class.addclass', name='addclass'),
    url(r'^manage/editclass/$', 'engine.class.editclass', name='editclass'),
    url(r'^manage/deleteclass/$', 'engine.class.deleteclass', name='deleteclass'),
    url(r'^ajax/get_classes_list/$', 'engine.class.get_classes_list', name='get_classes_list'),
    url(r'^manage/student/

    url(r'^manage/addstudent/$', 'engine.student.addstudent', name='addstudent'),
    url(r'^manage/editstudent/$', 'engine.student.editstudent', name='editstudent'),
    url(r'^manage/deletestudent/$', 'engine.student.deletestudent', name='deletestudent'),
    url(r'^manage/initstudent/$', 'engine.student.initstudent', name='initstudent'),
    url(r'^studentprofile/$', 'engine.student.studentprofile', name='studentprofile'),
    url(r'^ajax/get_students_list/$', 'engine.student.get_students_list', name='get_students_list'),
    url(r'^ajax/select_classes/$', 'engine.class.select_classes', name='select_classes'),
    url(r'^manage/assessment/$', 'engine.assessment.index', name='manageassessment'),
    url(r'^manage/addassessment/$', 'engine.assessment.addassessment', name='addassessment'),
    url(r'^manage/editassessment/$', 'engine.assessment.editassessment', name='editassessment'),
    url(r'^manage/deleteassessment/$', 'engine.assessment.deleteassessment', name='deleteassessment')

    url(r'view/assessment/$', 'engine.assessment.viewassessment', name='viewassessment'),
    url(r'^ajax/get_assessments_list/$', 'engine.assessment.get_assessments_list', name='get_assessments_list'),
    url(r'^ajax/view_assessments_list/$', 'engine.assessment.view_assessments_list', name='view_assessments_list'),
    url(r'^manage/goassessment/$', 'engine.assessment.goassessment', name='goassessment'),
    url(r'^ajax/go_assessments_list/$', 'engine.assessment.go_assessments_list', name='go_assessments_list'),
    url(r'^ajax/go_assessments/$', 'engine.assessment.go_assessments', name='go_assessments'),
    url(r'^manage/grades/$', 'engine.grade.index', name='managegrades'),
    url(r'manage/classgrades/$', 'engine.grade.classgrades', name='classgrades'),
    url('^ajax/studentgrades/$', 'engine.grade.studentgrades', name='studentgrades'),
    url(r'^ajax/ajaxclassgrades/$', 'engine.grade.ajaxclassgrades', name='ajaxclassgrades'),
    url(r'^manage/behavior/$', 'engine.activity.be
"""
    Sahana Eden Stats Controller
"""
module = request.controller
resourcename = request.function
if not settings.has_module(module):
    raise HTTP(404, body="Module disabled: %s" % module)
def parameter():
    """ REST Controller """
    return s3_rest_controller()
def data():
    """ REST Controller """
    return s3_rest_controller()
def aggregate():
    """ REST Controller """
    def prep(r):
        if r.method == "clear":
            if not s3_has_role(ADMIN):
                auth.permission.fail()
            s3db.stats_rebuild_aggregates()
            redirect(URL(c="stats",
                         f="aggregate",
                         args="",
                         ))
        return True
    s3.prep = prep
    output = s3_rest_controller()
    return output
def group():
    """ REST Controller """
    return s3_rest_controller()
def demographic():
    """ REST Controller """
    return s3_rest_controller()
def demographic_data():
    """ REST Controller """
    retu
class Blueprint(object):
    def __init__(self, model, fields=None, pre_save=None, post_save=None, seed=None):
        self.factory = factory
        self._model = model
        self._fields = fields or {}
        self.seed = seed
        self.pre_save = pre_save
        self.post_save = post_save
        self.pk = -1
        super(Blueprint, self).__init__()
    def fields(self, **kwargs):
        self._fields = kwargs
        return self
    def make_one(self, fields=None, pre_save=None, post_save=None, seed=None, iteration=None):
        _fields = self._fields.copy()
        if fields:
            _fields.update(fields)
        if seed is None:
            seed = self.seed
        if pre_save is None:
            pre_save = self.pre_save
        if post_save is None:
            post_save = self.post_save
        return self.factory.make_one(self._model, _fields, pre_save, post_save, seed, iteration)
    def make(self, fields=None, pre_save=None, post_save=None, seed=None, quantity=

        _fields = self._fields.copy()
        if fields:
            _fields.update(fields)
        if seed is None:
            seed = self.seed
        if pre_save is None:
            pre_save = self.pre_save
        if post_save is None:
            post_save = self.post_save
        return self.factory.make(self._model, _fields, pre_save, post_save, seed, quantity)
    def build(self, fields=None, pre_save=None, seed=None, quantity=None, make_fks=False):
        _fields = self._fields.copy()
        if fields:
            _fields.update(fields)
        if seed is None:
            seed = self.seed
        if pre_save is None:
            pre_save = self.pre_save
        return self.factory.build(self._model, _fields, pre_save, seed, quantity, make_fks)
    def m(self, pre_save=None, post_save=None, seed=None, quantity=None):
        make = partial(self.make, pre_save=pre_save, post_save=post_save, seed=seed, quantity=quantity)
        def fn(**kwargs):
            return make(fie
urlpatterns = patterns('collaborador.views',
    url(r'^stat/$', 'estat', name='manage_estat'),
    url(r'^addqr/clinex$', 'addQRClinex', name='manage_clinex_addqr'),
    
    url(r'^addqr/mosqueter$', 'addQRMosqueter', name='manage_mosqueter_addqr'),
    url(r'^premis/addPremi$', 'addPremi', name='manage_premis_addpremi'),            
    url(r'^premis/editPremi/(?P<pk>\d*)$', 'editPremi', name='manage_premis_editpremi'),            
    url(r'^listtalonari/(?P<talonari_pk>\d*)$', 'listTalonari', name='manage_clinex_listqrs'),    
    url(r'^listmosqueter/(?P<mosqueter_pk>\d*)$', 'listMosqueter', name='manage_mosqueter_listqr'),    
    url(r'^listtalonaris$', 'listTalonaris', name='manage_clinex_listtalonaris'),    
    url(r'^listmosqueters$', 'listMosqueters', name='manage_mosqueter_list'),
    url(r'^recollidesPendents/$', 'recollidesDePremisList', name='manage_recollidesdepremi_list'),
    url(r'^listpremis$', 'listPremis', name='manage_premis_listpremis'),    
    url(r'^factura
datatypes_repository_name = 'emboss_datatypes_0020'
datatypes_repository_description = "Galaxy applicable data formats used by Emboss tools."
datatypes_repository_long_description = "Galaxy applicable data formats used by Emboss tools.  This repository contains no tools."
emboss_repository_name = 'emboss_0020'
emboss_repository_description = 'Galaxy wrappers for Emboss version 5.0.0 tools for test 0020'
emboss_repository_long_description = 'Galaxy wrappers for Emboss version 5.0.0 tools for test 0020'
class TestBasicRepositoryDependencies( ShedTwillTestCase ):
    '''Testing emboss 5 with repository dependencies.'''
    def test_0000_initiate_users( self ):
        """Create necessary user accounts and login as an admin user."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s f

        test_user_1_private_role = test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = test_db_util.get_private_role( admin_user )
  
    def test_0005_create_category( self ):
        """Create a category for this test suite"""
        self.create_category( name='Test 0020 Basic Repository Dependencies', description='Testing basic repository dependency features.' )
    def test_0010_create_emboss_datatypes_repository_and_upload_tarball( self ):
        '''Create and populate the emboss_datatypes repository.'''
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        category = test_db_util.get_category_by_name( 'Test 00

        repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                             description=datatypes_repository_description, 
                                             long_description=datatypes_repository_long_description, 
                                             owner=common.test_user_1_name,
                                             category_id=self.security.encode_id( category.id ), 
                                             strings_displayed=[] )
        self.upload_file( repository, 
                          filename='emboss/datatypes/datatypes_conf.xml', 
                          filepath=None,
                          valid_tools_only=True,
                          uncompress_file=False,
                          remove_repo_files_not_in_tar=False,
                          commit_message='Uploaded datatypes_conf.xml.',
                          strings_displayed=[], 
                          strings_not_dis
mod = 'pikachewie.broker'
class _BrokerTestCase(_BaseTestCase):
    __contexts__ = (
        ('_flush_outbound', patch(
            'pika.adapters.base_connection.BaseConnection._flush_outbound')),
        ('tornado_adapter_connect', patch(
            mod + '.TornadoConnection._adapter_connect')),
        ('blocking_adapter_connect', patch(
            mod + '.BlockingConnection._adapter_connect')),
    )
    nodes = {
        'rabbit1': {
            'host': 'rabbit1.example.com',
            'port': 5673,
        },
        'rabbit2': {
            'port': 5674,
        },
        'rabbit3': {
            'host': 'rabbit3.example.com',
        },
        'localhost': {
            'host': '127.0.0.1',
        },
    }
    connect_options = {
        'credentials': PlainCredentials(username=sentinel.username,
                                        password=sentinel.password),
        'virtual_host': '/pikachewie',
        'heartbeat_interval': 60,
    }
class WhenCreatingBrokerWitho

    def execute(self):
        self.broker = Broker()
    def should_use_default_nodes(self):
        self.assertEqual(dict(self.broker._nodes), Broker.DEFAULT_NODES)
    def should_use_default_connect_options(self):
        self.assertEqual(self.broker._connect_options,
                         Broker.DEFAULT_CONNECT_OPTIONS)
class WhenCreatingBrokerWithNodes(_BrokerTestCase):
    def execute(self):
        self.broker = Broker(self.nodes)
    def should_set_nodes(self):
        self.assertEqual(dict(self.broker._nodes), self.nodes)
class WhenCreatingBrokerWithConnectOptions(_BrokerTestCase):
    def execute(self):
        self.broker = Broker(None, self.connect_options)
    def should_set_connect_options(self):
        self.assertEqual(self.broker._connect_options, self.connect_options)
class WhenCreatingBrokerWithCredentialsDict(_BrokerTestCase):
    connect_options = {
        'credentials': {
            'username': sentinel.username,
            'password': sentinel.password,
  

        'virtual_host': '/pikachewie',
        'heartbeat_interval': 60,
    }
    def execute(self):
        self.broker = Broker(None, self.connect_options)
    def should_create_plain_credentials(self):
        self.assertIsInstance(self.broker._connect_options['credentials'],
                              PlainCredentials)
    def should_set_username(self):
        self.assertEqual(self.broker._connect_options['credentials'].username,
                         sentinel.username)
    def should_set_password(self):
        self.assertEqual(self.broker._connect_options['credentials'].username,
                         sentinel.username)
class _BaseConnectionTestCase(_BrokerTestCase):
    nodes = {'localhost': {'host': '127.0.0.1', 'port': 5673}}
    connection_options = {
        'credentials': {'username': sentinel.username,
                        'password': sentinel.password},
        'virtual_host': '/pikachewie',
        'heartbeat_interval': 60,
    }
    def should_connect_to_
logger = get_task_logger(__name__)
@shared_task
def task_ava_evaluate_controller_run(controller_id):
    logger.debug('Task triggered'
                 ' - evaluate::task_ava_evaluate_controller_run')
    try:
        controller = EvaluateController.objects.get(id=controller_id)
    except EvaluateController.DoesNotExist:
        logger.debug('Task error'
                     ' - evaluate::task_ava_evaluate_controller_run'
                     ' - EvaluateController.DoesNotExist')
        return
    controller.run_evaluate()
@shared_task
def task_ava_evaluate_controller_expire(controller_id):
    logger.debug('Task triggered'
                 ' - evaluate::task_ava_evaluate_controller_expire')
    try:
        controller = EvaluateController.objects.get(id=controller_id)
    except EvaluateController.DoesNotExist:
        logger.debug('Task error'
                     ' - evaluate::task_ava_evaluate_controller_expire'
                     ' - EvaluateController.DoesNotExist')
        r
repository = Blueprint('repository', __name__)
@repository.route('/add', methods=['GET', 'POST'])
@require_sign_in(need_github=True)
def add_repository():
    token = session['github_access_token']
    oauth_session = auth_github.get_session(token=token)
    with db_session_scope() as db_session:
        user = get_user_in_session(db_session)
        organization = None
        if 'organization' in request.args:
            organization = request.args['organization']
            organizations = oauth_session.get('user/orgs').json()
            if len(organizations) == 0:
                return redirect(url_for('repository.add_repository'))
            if (organization == '' or
               organization not in (org['login'] for org in organizations)):
                return render_template('organization_select.html',
                                       items=organizations,
                                       user=user)
        if organization:
            api_path = 'orgs/%s/rep

        else:
            api_path = 'user/repos?type=owner'
        repositories = oauth_session.get(api_path).json()
        if request.method == 'POST':
            repository = repositories[int(request.form['repository']) - 1]
            db_session.add(Repository(
                github_id=repository['id'],
                name=repository['name'],
                full_name=repository['full_name'],
                description=repository['description'],
                is_private=repository['private'],
                url=repository['html_url'],
                owner_user=user
            ))
            return redirect('dashboard')
        return render_template('repository_add.html',
                               items=repositories,
                               organization=organization,
                               user=user)
@repository.route('/<repository_id>')
@require_sign_in()
def show_repository(repository_id):
    with db_session_scope() as db_session:
        user = 

        repository = db_session.query(Repository) \
                               .filter(Repository.id == repository_id) \
                               .first()
        token = repository.owner_user.github_access_token
        oauth_session = auth_github.get_session(token=token)
        api_path = 'repositories/%s/issues?state=%s&labels=%s'
        state = 'open'
        if 'state' in request.args:
            state_argument = request.args['state']
            if state_argument == 'closed' or state_argument == 'all':
                state = state_argument
        labels = ''
        if 'labels' in request.args:
            labels = request.args['labels']
        api_path = api_path % (repository.github_id, state, labels)
        issues = oauth_session.get(api_path).json()
        return render_template('repository.html',
                               repository=repository,
                               issues=issues,
                               state=state,
                  
tecnologia = Categoria(nombre="Tecnologia").save()
tv = Categoria(nombre="TV", padre=tecnologia).save()
LCD = Categoria(nombre="Celulares", padre=tecnologia).save()
LED = Categoria(nombre="Camaras", padre=tecnologia).save()
computadoras = Categoria(nombre="computadoras", padre=tecnologia).save()
notebooks = Categoria(nombre="notebooks", padre=computadoras).save()
ultrabooks = Categoria(nombre="ultrabooks", padre=computadoras).save()
netbooks = Categoria(nombre="netbooks", padre=computadoras).save()
impresoras = Categoria(nombre="impresoras", padre=tecnologia).save()
multifuncionales = Categoria(
    nombre="multifuncionales", padre=impresoras).save()
laser = Categoria(nombre="laser", padre=impresoras).save()
Producto(
    sku="13130202",
    nombre='Recco LCD 32" HD RLCD-32B330',
    marca="Recco",
    precio="699",
    categoria=LCD,
    detalles={
        "Pantalla": "LCD",
        "Modelo": "RLCD-32B330",
        "Tam": '32"',
        "Resolucion": "1368 x 768"
    }
).save()
Produc
urlpatterns = patterns('',
    url(r'^login/$', 'django.contrib.auth.views.login', {'template_name': 'login.html'}, name="login"),
    url(r'^logout/$', 'django.contrib.auth.views.logout_then_login', name="logout"),
    url(r'^$', home.IndexView.as_view(), name='home'),
    url(r'^debug_threads/$', home.DebugView.as_view(), name='debug'),
    url(r'^queue/log/(?P<pk>\w+)/$', queue.DownloadLog.as_view(), name='queue.log'),
    url(r'^queue/log/(?P<pk>\w+)/clear$', queue.downloadlog_clear, name='queue.log.clear'),
    url(r'^queue/manualfix/(?P<pk>\w+)/success/$', queue.DownloadsManuallyFixItemSuccess.as_view(), name="queue.manualfixitem.success"),
    url(r'^queue/manualfix/(?P<pk>\w+)/$', queue.DownloadsManuallyFixItem.as_view(), name='queue.manualfixitem'),
    url(r'^queue/(?P<type>\w+)/$', queue.QueueManage.as_view(), name='queue.index'),
    url(r'^find/$', find.find, name='find'),
    url(r'^manage/tvshows/$', manage.tvshows, name='manage.tvshows.find'),
    url(r'^manage/tvshows/
def zero(app="eclaim"):
	local("python manage.py migrate %s zero --settings=settings.development" % app )
def run():
	local("python manage.py runserver 0.0.0.0:80 --settings=settings.development")
def clear(app="eclaim"):
	local("rm -r %s/migrations" % app)
def shell():
	local("python manage.py shell --settings=settings.development")
def collectstatic():
	local("python manage.py collectstatic --noinput --settings=settings.production")
def gunicorn():
	local("gunicorn wsgi:application -b 0.0.0.0:3000 --settings=settings.production")
def clear_migrations():
	local("cd authentication")
	local("rm -rf migrations")
def syncdb():
	local("python manage.py syncdb --settings=settings.development")
def migrate_initial(app="apps.main"):
	local("python manage.py schemamigration %s --initial --settings=settings.development && python manage.py migrate %s --settings=settings.development" % (app,app))
def migration_update(app="apps.main"):
	local("python manage.py schemamigration %s --auto --update --
repository = load_repository("repository/")
if len(sys.argv) == 4:
	releaseKeyFile = sys.argv[1]
	f = open(releaseKeyFile)
	releasePassword = f.readline()
	timestampKeyFile = sys.argv[2]
	f = open(timestampKeyFile)
	timestampPassword = f.readline()
	targetsKeyFile = sys.argv[3]
	f = open(targetsKeyFile)
	targetsPassword = f.readline()
	repository.targets.load_signing_key(private_targets_key)
	repository.release.load_signing_key(private_release_key)
	repository.timestamp.load_signing_key(private_timestamp_key)
	for target in repository.targets.target_files:
		repository.targets.remove_target("repository/targets/"+target)
	release_targets = repository.get_filepaths_in_directory("repository/targets/update/",recursive_walk=True, followlinks=True)
	repository.targets.add_targets(release_targets)
	beta_targets = repository.get_filepaths_in_directory("repository/targets/pub/mozilla.org/firefox/releases/",recursive_walk=True, followlinks=True)
	repository.targets.add_targets(beta_targets)
	rep
__author__ = 'funhead'
class NeoRepositoryTest(unittest.TestCase):
    def test_GetNextId(self):
        repository = NeoRepository(1, "SOURCE", "sources")
        nextId = repository.GetNextId()
        print(nextId)
        self.assertTrue(nextId > 0)
        self.assertIsInstance(nextId, int)
    def test_GetByTitle(self):
        repository = NeoRepository(1, "SOURCE", "sources")
        node = repository.GetEntityFromTitle("inde")
        self.assertIsNotNone(node)
    def test_CreateNew(self):
        repository = NeoRepository(1, "SOURCE", "sources")
        newSource = {"id": -1, "title": 'Independent', "readership": 3207, "pagerate": 20}
        newNeoSource = repository.CreateEntity(newSource)
        self.assertEqual(newNeoSource["title"], "Independent")
    def test_Update(self):
        repository = NeoRepository(1, "SOURCE", "sources")
        entity = repository.GetEntity("1")
        oldReadership = entity["readership"]
        newReadership = int(oldReadership) * 2
   
_CONTROLLER = None
def get_controller():
    return _CONTROLLER
def set_controller(controller):
    global _CONTROLLER
    _CONTROLLER = controller
def disconnect_from_circus(endpoint):
    controller = get_controller()
    if controller is not None:
        controller.disconnect(endpoint)
        return True
    return False
@gen.coroutine
def connect_to_circus(loop, endpoint, ssh_server=None):
    if get_controller() is None:
        controller = Controller(loop, ssh_server=ssh_server)
        set_controller(controller)
    else:
        controller = get_controller()
    yield gen.Task(controller.connect, endpoint)
class Session(object):
    def __init__(self):
        self.messages = []
        self.endpoints = set()
        self.stats_endpoints = set()
    @property
    def connected(self):
        return bool(self.endpoints)
class SessionManager(object):
    sessions = {}
    @classmethod
    def get(cls, session_id):
        return cls.sessions.get(session_id, None)
    @classmet
class LevelController(Controller):
    """ Controller for the level """
    
    def __init__(self):
        """ Initialize the Level Controller """
        self.level = Level()
        Controller.__init__(self, LevelView(self.level))
        self.gameLoopActionIndex = 0
            
    def performGameCycle(self):
        """ Perform a Game Cycle Event """
        gameLoopActions = [self.doPlayerActions, self.drawPlayerCard, self.drawPlayerCard, self.infectACity, self.infectACity]
        gameLoopActions[self.gameLoopActionIndex]()
        self.gameLoopActionIndex += 1
        self.gameLoopActionIndex %= len(gameLoopActions)
        
    def handleInput(self):
        """ Do Nothing """
                
    def doPlayerActions(self):
        """ Perform Player Actions """
        player = self.level.players[0]
        
        controller = PlayerActionController(self.level, player)
        controller.run()
        
        if controller.quitting:
            self.stopRunning()
       
app_name = 'banking_system'
urlpatterns = [
    url(r'^$', views.login, name='login'),
    url(r'^create_user/$', views.create_user, name='create_user'),
    url(r'^create_account/$', views.create_account, name='create_account'),
    url(r'^user_portal/$', views.user_portal, name='user_portal'),
    url(r'^adminPortal/$', views.adminPortal, name='adminPortal'),
    url(r'^adminPortal/manageCustomers/$', views.manageCustomers, name='manageCustomers'),
    url(r'^adminPortal/manageCustomers/editCustomer$', views.editCustomer, name='editCustomer'),
    url(r'^adminPortal/manageCustomers/addCustomer$', views.addCustomer, name='addCustomer'),
    url(r'^adminPortal/manageAccounts/$', views.manageAccounts, name='manageAccounts'),
    url(r'^adminPortal/manageAccounts/addAccount$', views.addAccount, name='addAccount'),
    url(r'^adminPortal/manageAccounts/editAccount$', views.editAccount, name='editAccount'),
    url(r'^adminPortal/manageAccountTypes/$', views.manageAccountTypes, name='manag
def runcmd(cmd):
  try:
    print "Executing %s" % ' '.join(cmd)
    output = subprocess.check_output(cmd)
    print output
    return output
  except:
    print "Failed"
    return None
VBoxManage = '/usr/bin/VBoxManage'
vboxConfBios = './vboxConfBiosWinXP.py'
for machine in sys.argv[1:]:
  hdpath = os.path.join('/','data','VirtualBox VMs',machine,machine+'.vdi')
  runcmd([VBoxManage,'createhd','--filename',hdpath,'--size',str(80*1024)])
  runcmd([VBoxManage,'createvm','--name',machine,'--ostype','WindowsXP','--register'])
  runcmd([VBoxManage,'storagectl',machine,'--name','PIIX4','--add','ide','--controller','PIIX4'])
  runcmd([VBoxManage,'storageattach', machine,'--storagectl','PIIX4','--port','0','--device','0','--type','dvddrive','--medium','emptydrive'])
  runcmd([VBoxManage,'storageattach', machine,'--storagectl','PIIX4','--port','0','--device','1','--type','hdd','--medium',hdpath])
  runcmd([VBoxManage,'hostonlyif','create'])
  runcmd([VBoxManage,'hostonlyif','ipconfig','vboxne
"""
module handing the event pages
Created: Aug 28, 2013
"""
__author__ = 'Weber Jean-Paul'
__email__ = 'jean-paul.weber@govcert.etat.lu'
__copyright__ = 'Copyright 2013, GOVCERT Luxembourg'
__license__ = 'GPL v3+'
class AttributeController(BaseController):
  """event controller handling all actions in the event section"""
  def __init__(self, config, session=None):
    BaseController.__init__(self, config, session)
    self.attribute_broker = self.broker_factory(AttributeBroker)
  def get_attribute_by_id(self, identifier):
    try:
      return self.attribute_broker.get_by_id(identifier)
    except NothingFoundException as error:
      raise ControllerNothingFoundException(error)
    except BrokerException as error:
      raise ControllerException(error)
  def get_attribute_by_uuid(self, uuid):
    try:
      return self.attribute_broker.get_by_uuid(uuid)
    except NothingFoundException as error:
      raise ControllerNothingFoundException(error)
    except BrokerException as error:


  def update_attribute(self, attribute, user, commit=True):
    try:
      user = self.user_broker.get_by_id(user.identifier)
      self.set_extended_logging(attribute, user, user.group, False)
      self.attribute_broker.update(attribute)
    except BrokerException as error:
      raise ControllerException(error)
  def remove_attribute(self, attribute, user, commit=True):
    try:
      self.attribute_broker.remove_by_id(attribute.identifier)
    except BrokerException as error:
      raise ControllerException(error)
  def insert_attributes(self, attributes, user, commit=True, owner=True):
    self.logger.debug('User {0} inserts a new attribute'.format(user.username))
    try:
      for attribute in attributes:
        self.set_extended_logging(attribute, user, user.group, True)
        for child in attribute.children:
          self.set_extended_logging(child, user, user.group, True)
      user = self.user_broker.get_by_id(user.identifier)
      for attribute in attributes:
        
def initialize_exporter( ):
	if bpy.ops.object.mode_set.poll():
		bpy.ops.object.mode_set(mode='OBJECT')
class TamyExportSettings( Structure ):
	_fields_ = [("saveAnimations", c_bool),
				("saveMaterials", c_bool),
				("saveMeshes", c_bool),
				("savePrefabs", c_bool),
				("saveObjects", c_bool) ]
	def __init__( self, saveAnimations, saveMaterials, saveMeshes, savePrefabs, saveObjects ):
		self.saveAnimations = saveAnimations
		self.saveMaterials = saveMaterials
		self.saveMeshes = saveMeshes
		self.savePrefabs = savePrefabs
		self.saveObjects = saveObjects
def export_scene(operator, context, filesystemRoot="", filepath="", bUseSelection=True, selectedArmature="", saveAnimations=True, saveMaterials=True, saveMeshes=True, savePrefabs=True, saveObjects=True ):
	time1 = time.clock()
	initialize_exporter()
	exportDir, sceneName = os.path.split( filepath )
	tamyScene = tamy_scene.TamyScene( sceneName )
	tamyScene.compile_scene( context, bUseSelection, selectedArmature )
	exportSettings 
datatypes_repository_name = 'emboss_datatypes_0110'
datatypes_repository_description = "Galaxy applicable data formats used by Emboss tools."
datatypes_repository_long_description = "Galaxy applicable data formats used by Emboss tools.  This repository contains no tools."
emboss_repository_name = 'emboss_0110'
emboss_repository_description = 'Galaxy wrappers for Emboss version 5.0.0 tools'
emboss_repository_long_description = 'Galaxy wrappers for Emboss version 5.0.0 tools'
category_name = 'Test 0110 Invalid Repository Dependencies'
category_desc = 'Test 0110 Invalid Repository Dependencies'
class TestBasicRepositoryDependencies( ShedTwillTestCase ):
    '''Testing emboss 5 with repository dependencies.'''
    def test_0000_initiate_users( self ):
        """Create necessary user accounts and login as an admin user."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = test_db_util.get_user( common.test_use

        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = test_db_util.get_private_role( admin_user )
  
    def test_0005_create_category( self ):
        """Create a category for this test suite"""
        self.create_category( name=category_name, description=category_desc )
  
    def test_0010_create_emboss_datatypes_repository_and_upload_tarball( self ):
        '''Create and populate the emboss_datatypes repository.'''
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_nam

        category = test_db_util.get_category_by_name( category_name )
        repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                             description=datatypes_repository_description, 
                                             long_description=datatypes_repository_long_description, 
                                             owner=common.test_user_1_name,
                                             category_id=self.security.encode_id( category.id ), 
                                             strings_displayed=[] )
        self.upload_file( repository, 
                          filename='emboss/datatypes/datatypes_conf.xml',
                          filepath=None,
                          valid_tools_only=True,
                          uncompress_file=True,
                          remove_repo_files_not_in_tar=False, 
                          commit_message='Uploaded datatypes_conf.xml.',
                     
__author__ = 'qianfunian'
timeFile = open('time.log', 'a+')
start = int(time.time())
mobileDbConnection = MySQLdb.connect(user="anjuke_triger", passwd="anjuke_triger", host='10.20.3.80', db="mobile_db")
mobileCursor = mobileDbConnection.cursor()
globalBrokerIds = {}
pageCount = 10
def generate_data(brokerIds):
    for brokerId in brokerIds:
        if (globalBrokerIds.has_key(brokerId[0])):
            continue
        globalBrokerIds[brokerId[0]] = ''
        sql = "select *,count(*) as count from (select distinct `broker_id`,`community_id`,DATE_FORMAT(sign_time,'%m%d') " \
              "as sign_time from broker_community_sign_201410  where broker_id = " + str(brokerId[0]) + \
              " union all select distinct `broker_id`,`community_id`,DATE_FORMAT(sign_time,'%m%d') as sign_time " \
              "from broker_community_sign_201411  where broker_id = " + str(brokerId[0]) + \
              " ) temp group by sign_time,broker_id order by sign_time asc"
        mobileCursor.execut

        sign_data = mobileCursor.fetchall()
        anjukeDbConnection = MySQLdb.connect(user="anjuke_triger", passwd="anjuke_triger", host='10.20.3.80',
                                             db="anjuke_db")
        sql = 'select ajk_brokerextend.BrokerId,ajk_brokerextend.TrueName,ajk_brokerextend.UserMobile,' \
              'ajk_brokerextend.BelongCom,ajk_citytype.CityName from ajk_brokerextend ' \
              'left join ajk_citytype on ajk_brokerextend.CityId=ajk_citytype.CityId where BrokerId= ' + str(
            brokerId[0])
        anjukeCursor = anjukeDbConnection.cursor()
        anjukeCursor.execute(sql)
        brokerInfo = anjukeCursor.fetchall()
        line_text = ''
        for info in brokerInfo[0]:
            line_text += str(info) + ','
        for info in sign_data:
            line_text += str(info[2]) + "(" + str(info[3]) + "),"
        file_object.write(line_text + '\n')
pass
file_object = open('sign.csv', 'a+')
for db in ['broker_community_sign_201410'
def main(request):
    """context processor for LFC.
    """
    current_language = translation.get_language()
    default_language = settings.LANGUAGE_CODE
    
    is_default_language = default_language == current_language
    if current_language == "0" or is_default_language:
        link_language = ""
    else:
        link_language = current_language
    
    return {
        "PORTAL" : lfc.utils.get_portal(),
        "LFC_MULTILANGUAGE" : settings.LFC_MULTILANGUAGE,
        "LFC_MANAGE_WORKFLOWS" : settings.LFC_MANAGE_WORKFLOWS,
        "LFC_MANAGE_APPLICATIONS" : settings.LFC_MANAGE_APPLICATIONS,
        "LFC_MANAGE_COMMENTS" : settings.LFC_MANAGE_COMMENTS,
        "LFC_MANAGE_USERS" : settings.LFC_MANAGE_USERS,
        "LFC_MANAGE_PERMISSIONS" : settings.LFC_MANAGE_PERMISSIONS,
        "LFC_MANAGE_SEO" : settings.LFC_MANAGE_SEO,
        "LANGUAGES_DICT" : LANGUAGES_DICT,
        "DEFAULT_LANGUAGE" : default_language,
        "CURRENT_LANGUAGE" : current_language,
        "IS_DE
""" The Node class """
class Node(Server):
    """ A simple example server """
    namespace = "zerotask.node"
    def __init__(self, **kwargs):
        self.node_id = kwargs.get("node_id", None)
        self.running_tasks = 0
        self.workers = []
        Server.__init__(self)
    def setup(self):
        """ Sets up the handlers """
        self.broker_req_socket = None
        self.broker_sub_socket = None
        self._push_file = tempfile.NamedTemporaryFile(prefix="zerotaskq-")
        self._pull_file = tempfile.NamedTemporaryFile(prefix="zerotaskr-")
        self.push_socket = self.context.socket(zmq.PUSH)
        self.push_socket.bind("ipc://%s" % self._push_file.name)
        self.pull_socket = self.context.socket(zmq.PULL)
        self.pull_socket.bind("ipc://%s" % self._pull_file.name)
        self.add_callback(self.pull_socket, self.worker_task_result)
        self.add_handler(self.task_ready)
        self.add_handler(self.request_status)
    def teardown(self):
        

        logging.info("Closing temporary files")
        self._push_file.close()
        self._pull_file.close()
    def start(self):
        """ Checks if broker is setup, then starts the loop """
        if not self.broker_req_socket or not self.broker_sub_socket:
            self.add_broker("tcp://127.0.0.1:5555", "tcp://127.0.0.1:5556")
        logging.info("Starting up %s workers...", self.worker_count)
        for i in range(self.worker_count):
            push_file = self._push_file.name
            pull_file = self._pull_file.name
            def worker_func():
                worker = Worker(queue=push_file, result=pull_file,
                                name="worker-%d" % i)
                worker.start()
            process = Process(target=worker_func)
            self.workers.append(process)
            process.start()
        Server.start(self)
    def add_broker(self, broker_req_uri, broker_sub_uri):
        """ Sets the (only) broker """
        self.broker_req_socke

        self.broker_sub_socket = self.context.socket(zmq.SUB)
        self.broker_req_socket.connect(broker_req_uri)
        self.broker_sub_socket.connect(broker_sub_uri)
        self.broker_sub_socket.setsockopt(zmq.SUBSCRIBE, "")
        connect_method = "zerotask.broker.node_connect"
        connect_request = jsonrpc.request(connect_method)
        self.broker_req_socket.send_json(connect_request)
        connect_result = self.broker_req_socket.recv_json()
        if connect_result.has_key("error"):
            connect_error = connect_result["error"]
            raise JSONRPCError(connect_error["code"],
                               connect_error.get("message"))
        node_id = connect_result.get("result")
        if not node_id:
            raise JSONRPCError(jsonrpc.INVALID_NODE_ID)
        self.node_id = node_id
        logging.info("New node id: %s", node_id)
        self.add_callback(self.broker_sub_socket, self.subscribe)
    def subscribe(self, message):
        """ Spec
urlpatterns = patterns('',
    url(r'^acidentes_rodovias/$', 'app.controller.index_controller.index'),
    url(r'^acidentes_rodovias/regiao$', 'app.controller.consultabasica_regiao_controller.consulta_por_regiao'),
    url(r'^acidentes_rodovias/periodo$', 'app.controller.consultabasica_periodo_controller.consulta_por_periodo'),
    url(r'^acidentes_rodovias/municipios-regiao$', 'app.controller.consultabasica_regiao_controller.consulta_municipios_na_regiao'),
    url(r'^acidentes_rodovias/consulta/municipio$', 'app.controller.consultabasica_regiao_controller.consulta_ocorrencias_por_municipio'),
    url(r'^acidentes_rodovias/consulta/periodo$', 'app.controller.consultabasica_periodo_controller.consulta_ocorrencias_por_periodo'),
    url(r'^acidentes_rodovias/estatisticas/tipos-acidentes$', 'app.controller.estatisticas_tipos_controller.tipos_acidentes'),
    url(r'^acidentes_rodovias/estatisticas/causas-acidentes$', 'app.controller.estatisticas_causas_controller.causas_acidentes'),
    u
class UpdateDepthThread(threading.Thread):
    """
    simple class for updating the highest bid and lowest
    ask rates of each broker
    """
    def __init__(self, broker, pair, backtest_data=None, tick_i=0):
        self.broker = broker
        self.pair = pair
        self.backtest_data = backtest_data
        self.tick_i = tick_i
        threading.Thread.__init__(self)
    def run(self):
        if self.broker.xchg.get_validated_pair(self.pair) is not None:
            if self.backtest_data is not None:
                self.broker.update_depth(self.pair, self.backtest_data, self.tick_i)
            else:
                self.broker.update_depth(self.pair)
class UpdateBalanceThread(threading.Thread):
    """
    simple thread class for updating balances across
    all accounts. Originally this was a part of UpdateDepthThread
    but some exchanges serve up entire wallet and this may result in
    HTTP 429 error if too many requests are made!
    """
    def __init__(self, broker)

        self.broker = broker
        threading.Thread.__init__(self)
    def run(self):
        self.broker.update_all_balances()
class Bot(object):
    def __init__(self, config, brokers):
        """
        config = configuration file
        brokers = array of broker objects
        """
        super(Bot, self).__init__()
        self.config = config
        self.brokers = brokers
        self.error = False
        self.log = Logger()
        self.backtest_data = None
        self.max_ticks = 0
        self.data_path = abspath(config.TICK_DIR)
        self.trading_enabled = True
        self.tick_i = 0
        start = time.time()
        last_tick = start - sleep
        while not self.error:
            delta = time.time() - last_tick
            if (delta < sleep):
                time.sleep(sleep-delta)
            self.tick()
            last_tick = time.time()
        print('Initial Position:')
        initial_position = get_assets(self.brokers)
        print(initial_position

        self.backtest_data = pickle.load(open(backtest_file, "rb" ))
        self.max_ticks = len(self.backtest_data['ticks'])
        self.tick_i = 0
        while self.tick_i < self.max_ticks:
            self.tick()
            self.tick_i += 1
        print('Final Position:')
        final_position = get_assets(self.brokers)
        print('Total Profits:')
        for k,v in final_position.items():
            if k in initial_position:
                print('%s : %f' % (k,v-initial_position[k]))
            else:
                print('%s : %f' % (k,v))
        '''
        runs the bot in realtime for 60 seconds, waits 1 second between each execution, and
        write the tick data for playback in realtime. Increase the frequency if you
        are interested in larger-scale price movements rather than high-frequency trading.
        maxdepth is number of orders saved in each market. Idea being that we are unlikely
        to be interested in the order prices of anything beyond t
def home_page(request):
    return render(request, 'home.html')
def PieceView(request):
    form = PieceModelForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def GlazeView(request):
    form = GlazeLookupModelForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def DocumentationView(request):
    form = DocumentationForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=Re

def ConditionView(request):
    form = ConditionForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def ExhibitionLookupView(request):
    form = ExhibitionLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def HeathLineLookupView(request):
    form = HeathLineLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def LogoView(request):

    form = LogoForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def MakerLookupView(request):
    form = MakerLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def MaterialLookupView(request):
    form = MaterialLookupForm(request.POST or None)
    if form.is_valid():
        save_it = form.save(commit=False)
        save_it.save()
    return render_to_response("kk.html",
                              locals(),
                              context_instance=RequestContext(request))
def MethodLookupView(request):
    form = MethodLookupForm(request.
sys_graphicsController = GraphicsController()
sys_gameController = GameController()
sys_inputController = Input()
def drawRectangle(x, y, width, height):
	global sys_graphicsController
	sys_graphicsController.drawRectangle(x, y, width, height)
def drawCircle(x, y, radius):
	global sys_graphicsController
	sys_graphicsController.drawCircle(x, y, radius)
def drawLine(x1, y1, x2, y2):
	global sys_graphicsController
	sys_graphicsController.drawLine(x1, y1, x2, y2)
def drawPoint(x, y):
	global sys_graphicsController
	sys_graphicsController.drawPoint(x, y)
def drawString(x, y, string):
	global sys_graphicsController
	sys_graphicsController.drawString(x, y, string)
def useColour(r, g, b, a):
	global sys_graphicsController
	sys_graphicsController.useColour(r, g, b, a)
def clearScreen():
	global sys_graphicsController
	sys_gameController.clearScreen()
def newFrame():
	global sys_graphicsController
	sys_gameController.newFrame()
def isMouseDown():
	global sys_inputController
	return sys_inputCont
store = storage.load()
logger = logging.getLogger(__name__)
RE_USER_AGENT = re.compile('([^\s/]+)/([^\s/]+)')
@app.route('/v1/repositories/<path:repository>/properties', methods=['PUT'])
@toolkit.parse_repository_name
@toolkit.requires_auth
def set_properties(namespace, repo):
    logger.debug("[set_access] namespace={0}; repository={1}".format(namespace,
                 repo))
    data = None
    try:
        data = json.loads(flask.request.data)
    except json.JSONDecodeError:
        pass
    if not data or not isinstance(data, dict):
        return toolkit.api_error('Invalid data')
    private_flag_path = store.private_flag_path(namespace, repo)
    if data['access'] == 'private' and not store.is_private(namespace, repo):
        store.put_content(private_flag_path, '')
    elif data['access'] == 'public' and store.is_private(namespace, repo):
        store.remove(private_flag_path)
    return toolkit.response()
@app.route('/v1/repositories/<path:repository>/properties', methods=

@toolkit.parse_repository_name
@toolkit.requires_auth
def get_properties(namespace, repo):
    logger.debug("[get_access] namespace={0}; repository={1}".format(namespace,
                 repo))
    is_private = store.is_private(namespace, repo)
    return toolkit.response({
        'access': 'private' if is_private else 'public'
    })
def get_tags(namespace, repository):
    tag_path = store.tag_path(namespace, repository)
    for fname in store.list_directory(tag_path):
        full_tag_name = fname.split('/').pop()
        if not full_tag_name.startswith('tag_'):
            continue
        tag_name = full_tag_name[4:]
        tag_content = store.get_content(fname)
        yield (tag_name, tag_content)
@app.route('/v1/repositories/<path:repository>/tags', methods=['GET'])
@toolkit.parse_repository_name
@toolkit.requires_auth
@mirroring.source_lookup_tag
def _get_tags(namespace, repository):
    logger.debug("[get_tags] namespace={0}; repository={1}".format(namespace,
            

    try:
        data = dict((tag_name, tag_content)
                    for tag_name, tag_content
                    in get_tags(namespace=namespace, repository=repository))
    except OSError:
        return toolkit.api_error('Repository not found', 404)
    return toolkit.response(data)
@app.route('/v1/repositories/<path:repository>/tags/<tag>', methods=['GET'])
@toolkit.parse_repository_name
@toolkit.requires_auth
@mirroring.source_lookup_tag
def get_tag(namespace, repository, tag):
    logger.debug("[get_tag] namespace={0}; repository={1}; tag={2}".format(
                 namespace, repository, tag))
    data = None
    tag_path = store.tag_path(namespace, repository, tag)
    try:
        data = store.get_content(tag_path)
    except IOError:
        return toolkit.api_error('Tag not found', 404)
    return toolkit.response(data)
@app.route('/v1/repositories/<path:repository>/json', methods=['GET'])
@toolkit.parse_repository_name
@toolkit.requires_auth
@mirroring.source_lookup
HOST = 'm2.exosite.com'
PORT = 80
def main():
  
  device = ProvisionDevice(HOST, PORT, VENDOR_NAME, DEVICE_MODEL, CONTENT_ID)
  
  manager = ProvisionManager(HOST, PORT, VENDOR_TOKEN, DEVICE_MODEL, CLONE_RID, CONTENT_ID)
  
  manager.provisionManageModelPOST()
  
  print manager.provisionManageModelGET()
  
  manager.provisionManageModelModelPUT('&options=nohistorical')
  
  print manager.provisionManageModelModelGET()
  manager.provisionManageContentModelPOST()
  
  print manager.provisionManageContentModelGET()
  
  manager.provisionManageContentModelIDPOST()
  
  print manager.provisionManageContentModelIDGET()
  
  print manager.provisionManageContentModelIDGET('download=true')
  
  manager.provisionManageModelModelInfoPOST('add=true&sn=' + FIRST_SERIAL_NUM)
  manager.provisionManageModelModelInfoPOST('add=true&sn=' + SECOND_SERIAL_NUM)
  
  print manager.provisionManageModelModelInfoGET()
  
  manager.provisionManageModelModelSNPOST(FIRST_SERIAL_NUM, 'enable=true&owner=' + DEVICE

  
  manager.provisionManageModelModelSNPOST(SECOND_SERIAL_NUM, 'enable=true&oldsn=' + FIRST_SERIAL_NUM)
  
  print manager.provisionManageModelModelSNGET(SECOND_SERIAL_NUM)
  device.ip();
  
  device.provisionActivatePOST(SECOND_SERIAL_NUM);
  
  manager.provisionManageModelModelSNPOST(SECOND_SERIAL_NUM, 'enable=true')
  
  device.provisionActivatePOST(SECOND_SERIAL_NUM);
  
  print manager.provisionManageModelModelSNGET(SECOND_SERIAL_NUM, 'show=log')
  
  print device.provisionDownloadGET('&info=true')
  
  print device.provisionDownloadGET()
  
  manager.provisionManageModelModelSNPOST(SECOND_SERIAL_NUM, 'disable=true')
  
  print manager.provisionManageModelModelSNGET(SECOND_SERIAL_NUM)
  
  manager.provisionManageModelModelSNDELETE(FIRST_SERIAL_NUM)
  manager.provisionManageModelModelSNDELETE(SECOND_SERIAL_NUM)
  
  manager.provisionManageContentModelIDDELETE()
  print manager.provisionManageContentModelGET()
  
  manager.provisionManageModelModelDELETE()
  print manager.provisio
    NotFoundError,
    NotAuthorizedError,
    PermissionDeniedError,
    ValidationError,
    InvalidServiceError,
    ServerError,
api_v1 = Blueprint('api', __name__, url_prefix='/api/v1')
api = Api(api_v1, version='1.0', title='Organizer Server APIs',
          description='Open Event Organizer APIs')
api.add_namespace(event_api)
api.add_namespace(session_api)
api.add_namespace(track_api)
api.add_namespace(speaker_api)
api.add_namespace(sponsor_api)
api.add_namespace(microlocation_api)
api.add_namespace(login_api)
api.add_namespace(exports_api)
api.add_namespace(users_api)
api.add_namespace(extras_api)
api.add_namespace(notifications_api)
api.add_namespace(error_models)
api.add_namespace(error_models)
api.add_namespace(attendees_api)
api.add_namespace(tickets_apt)
@api.documentation
def custom_ui():
    return render_template(
        'swagger/swagger-ui.html',
        title=api.title,
        specs_url=api.specs_url,
        user=current_user)
@api.errorhandler(NotFoundError)
@api.
'''OFolder, a folder with explicit control over the order of elements.'''
try:
except ImportError:
class OFolder(OrderedFolder):
  '''OFolder behaves like 'OrderedFolder' but provides an additional 'manage_reorder' which allows to directly specify the element order.'''
  meta_type= 'OFolder'
  security= ClassSecurityInfo()
  security.declareProtected(manage_properties,
                            'manage_reorder',
                            )
  def manage_reorder(self, order, REQUEST=None, cmp= lambda x,y: cmp(x.order,y.order)):
    '''reorder the folders children according to *order*.'''
    order.sort(cmp)
    d= _dictify(self._objects); l= []
    for x in order: l.append(d[x.id])
    self._objects= tuple(l)
    if REQUEST is not None:
      return self.manage_main(self,REQUEST,
                              manage_tabs_message='reordered')
  manage_main= DTMLFile('dtml/main', globals())
InitializeClass(OFolder)
manage_addOFolderForm= DTMLFile('dtml/ofolderAdd',globals())
def manage
"""Base implementation classes.
The public-facing ``Events`` serves as the base class for an event interface;
its public attributes represent different kinds of events.   These attributes
are mirrored onto a ``_Dispatch`` class, which serves as a container for
collections of listener functions.   These collections are represented both
at the class level of a particular ``_Dispatch`` class as well as within
instances of ``_Dispatch``.
"""
    _EmptyListener, _DispatchDescriptor
_registrars = util.defaultdict(list)
def _is_event_name(name):
    return not name.startswith('_') and name != 'dispatch'
class _UnpickleDispatch(object):
    """Serializable callable that re-generates an instance of
    :class:`_Dispatch` given a particular :class:`.Events` subclass.
    """
    def __call__(self, _parent_cls):
        for cls in _parent_cls.__mro__:
            if 'dispatch' in cls.__dict__:
                return cls.__dict__['dispatch'].dispatch_cls(_parent_cls)
        else:
            rais

class _Dispatch(object):
    """Mirror the event listening definitions of an Events class with
    listener collections.
    Classes which define a "dispatch" member will return a
    non-instantiated :class:`._Dispatch` subclass when the member
    is accessed at the class level.  When the "dispatch" member is
    accessed at the instance level of its owner, an instance
    of the :class:`._Dispatch` class is returned.
    A :class:`._Dispatch` class is generated for each :class:`.Events`
    class defined, by the :func:`._create_dispatcher_class` function.
    The original :class:`.Events` classes remain untouched.
    This decouples the construction of :class:`.Events` subclasses from
    the implementation used by the event internals, and allows
    inspecting tools like Sphinx to work in an unsurprising
    way against the public API.
    """
    _events = None
    """reference the :class:`.Events` class which this
        :class:`._Dispatch` is created for."""
    def __init__(s

        self._parent_cls = _parent_cls
    @util.classproperty
    def _listen(cls):
        return cls._events._listen
    def _join(self, other):
        """Create a 'join' of this :class:`._Dispatch` and another.
        This new dispatcher will dispatch events to both
        :class:`._Dispatch` objects.
        """
        if '_joined_dispatch_cls' not in self.__class__.__dict__:
            cls = type(
                "Joined%s" % self.__class__.__name__,
                (_JoinedDispatcher, self.__class__), {}
            )
            for ls in _event_descriptors(self):
                setattr(cls, ls.name, _JoinedDispatchDescriptor(ls.name))
            self.__class__._joined_dispatch_cls = cls
        return self._joined_dispatch_cls(self, other)
    def __reduce__(self):
        return _UnpickleDispatch(), (self._parent_cls, )
    def _update(self, other, only_propagate=True):
        """Populate from the listeners in another :class:`_Dispatch`
            object."""
       
CONTENT_MANAGE_OPTIONS = (
 {'action': 'manage_change_history_page', 'label': 'History'},
 {'action': 'view', 'label': 'View'},
 {'action': 'manage_interfaces', 'label': 'Interfaces'},
class BaseContentMixin(CatalogMultiplex,
                       BaseObject,
                       PortalContent,
                       Historical):
    """A not-so-basic CMF Content implementation that doesn't
    include Dublin Core Metadata"""
    implements(IBaseContent, IReferenceable)
    security = ClassSecurityInfo()
    manage_options = CONTENT_MANAGE_OPTIONS
    isPrincipiaFolderish = 0
    isAnObjectManager = 0
    __dav_marshall__ = True
    security.declarePrivate('manage_afterAdd')
    def manage_afterAdd(self, item, container):
        BaseObject.manage_afterAdd(self, item, container)
    security.declarePrivate('manage_afterClone')
    def manage_afterClone(self, item):
        BaseObject.manage_afterClone(self, item)
    security.declarePrivate('manage_beforeDelete')
    def manage_befo

        BaseObject.manage_beforeDelete(self, item, container)
        self._v_cp_refs = None
    def _notifyOfCopyTo(self, container, op=0):
        """OFS.CopySupport notify
        """
        BaseObject._notifyOfCopyTo(self, container, op=op)
        if op == 1:
            self._v_cp_refs = 1
    security.declareProtected(permissions.ModifyPortalContent, 'PUT')
    PUT = WebDAVSupport.PUT
    security.declareProtected(permissions.View, 'manage_FTPget')
    manage_FTPget = WebDAVSupport.manage_FTPget
    security.declarePrivate('manage_afterPUT')
    manage_afterPUT = WebDAVSupport.manage_afterPUT
InitializeClass(BaseContentMixin)
class BaseContent(BaseContentMixin,
                  ExtensibleMetadata,
                  PropertyManager):
    """A not-so-basic CMF Content implementation with Dublin Core
    Metadata included"""
    implements(IBaseContent, IReferenceable, IExtensibleMetadata)
    schema = BaseContentMixin.schema + ExtensibleMetadata.schema
    def __init__(self, oi
register = template.Library()
def memoize(function):
    memo = {}
    def decorated_function(*args):
        result = memo.get(args, None)
        if result is None:
            result = function(*args)
            memo[args] = result
        return result
    return decorated_function
@memoize
def get_url(repository_name, path):
    repository = django_memorious.get_repository(repository_name)
    if getattr(settings, "MEMORIOUS_DEBUG", False):
        revision = None
    else:
        revision = repository.current_revision
    url = urlresolvers.reverse(
        'memorious', 
        kwargs={"repository": repository_name,
                "revision": revision,
                "name": path})
    return url
class MemoriousNode(template.Node):
    def __init__(self, repository, path):
        self.repository = repository
        self.path = path
    def render(self, context):
        return get_url(self.repository, self.path)
@register.tag(name="memorious")
def parse_memorious(parser, t
"""Majordomo Protocol Worker API, Python version
Author: Min RK <benjaminrk@gmail.com>
Based on Java example by Arkadiusz Orzechowski
"""
class MajorDomoWorker(object):
    """Majordomo Protocol Worker API, Python version
    """
    broker = None
    ctx = None
    service = None
    reply_to = None
    def __init__(self, broker, service, verbose=False):
        self.broker = broker
        self.service = service
        self.verbose = verbose
        self.ctx = zmq.Context()
        self.poller = zmq.Poller()
        logging.basicConfig(format="%(asctime)s %(message)s", datefmt="%Y-%m-%d %H:%M:%S",
                level=logging.INFO)
        self.reconnect_to_broker()
    def reconnect_to_broker(self):
        """Connect or reconnect to broker"""
        if self.worker:
            self.poller.unregister(self.worker)
            self.worker.close()
        self.worker = self.ctx.socket(zmq.DEALER)
        self.worker.linger = 0
        self.worker.connect(self.broker)
        self.po

        if self.verbose:
            logging.info("I: connecting to broker at %s...", self.broker)
        self.send_to_broker(MDP.W_READY, self.service, [])
        self.liveness = self.HEARTBEAT_LIVENESS
        self.heartbeat_at = time.time() + 1e-3 * self.heartbeat
    def send_to_broker(self, command, option=None, msg=None):
        """Send message to broker.
        If no msg is provided, creates one internally
        """
        if msg is None:
            msg = []
        elif not isinstance(msg, list):
            msg = [msg]
        if option:
            msg = [option] + msg
        msg = ['', MDP.W_WORKER, command] + msg
        if self.verbose:
            logging.info("I: sending %s to broker", command)
            dump(msg)
        self.worker.send_multipart(msg)
    def recv(self, reply=None):
        """Send reply, if any, to broker and wait for next request."""
        assert reply is not None or not self.expect_reply
        if reply is not None:
            assert

            reply = [self.reply_to, ''] + reply
            self.send_to_broker(MDP.W_REPLY, msg=reply)
        self.expect_reply = True
        while True:
            try:
                items = self.poller.poll(self.timeout)
            except KeyboardInterrupt:
            if items:
                msg = self.worker.recv_multipart()
                if self.verbose:
                    logging.info("I: received message from broker: ")
                    dump(msg)
                self.liveness = self.HEARTBEAT_LIVENESS
                assert len(msg) >= 3
                empty = msg.pop(0)
                assert empty == ''
                header = msg.pop(0)
                assert header == MDP.W_WORKER
                command = msg.pop(0)
                if command == MDP.W_REQUEST:
                    self.reply_to = msg.pop(0)
                    assert msg.pop(0) == ''
                elif command == MDP.W_HEARTBEAT:
                    pass
                elif command == MD
class Command(BaseCommand):
    option_list = BaseCommand.option_list + (
        make_option("-c", "--cron", dest="exec_cron",
                    help="Execution stops if all tasks are worked off.", action="store_true"),
        make_option("-d", "--daemon", dest="exec_daemon",
                    help="Daemon mode.", action="store_true"),
        make_option("-w", "--worker", dest="worker",
                    help="Number of processes to start.", default=1, type="int"),
    )
    help = "Starts the worker process."
    def handle(self, *args, **options):
        if options.get('exec_cron'):
            self.run_as_script(**options)
        else:
            self.run_as_daemon(**options)
    def get_broker(self):
        try:
            broker = get_broker()
            return broker
        except BrokerConnectionError, e:
            self.stderr.write("Connection to broker failed: %s" % e)
        except KeyboardInterrupt:
            self.stdout.write("Stopped.")
    def run_as_
midi_note_definitions = {
    
    1  : ['DeviceController', 'select_current_then_select_next_hash_device', [0]],
    2  : ['DeviceController', 'set_chain_selector', [0]],
    3  : ['DeviceController', 'set_chain_selector', [1]],
    4  : ['DeviceController', 'set_chain_selector', [2]],
    5  : ['DeviceController', 'set_chain_selector', [3]],
    6  : ['TrackController', 'get_focus', [0]],
    
    7  : ['DeviceController', 'set_chain_selector', [4]],
    8  : ['DeviceController', 'set_chain_selector', [5]],
    9  : ['DeviceController', 'set_chain_selector', [6]],
    10 : ['DeviceController', 'set_chain_selector', [7]],
    12 : ['DeviceController', 'navigate_device_focus', [0, PREV]],
    13 : ['DeviceController', 'navigate_device_focus', [0, NEXT]],
    
    14 : ['DeviceController', 'toggle_device', [CURRENT, CURRENT]],
    15 : ['LooperController', 'clipLooper', [0]],    
    16 : ['TrackController', 'arm', [0]],
    
    26 : ['TrackController', 'arm', [1]],
    36 : ['TrackCon

    46 : ['TrackController', 'arm', [3]],
    56 : ['TrackController', 'arm', [4]],
    66 : ['TrackController', 'arm', [5]],
    72 : ['LooperController', 'activate_looper', [0]],     
    74 : ['LooperController', 'activate_looper', [1]], 
    77 : ['LooperController', 'switch_view', [0]],
    79 : ['LooperController', 'switch_view', [1]],
    22 : ['DeviceController', 'navigate_device_focus', [1, PREV]],
    32 : ['DeviceController', 'navigate_device_focus', [2, PREV]],
    42 : ['DeviceController', 'navigate_device_focus', [3, PREV]],
    52 : ['DeviceController', 'navigate_device_focus', [4, PREV]],
    62 : ['DeviceController', 'navigate_device_focus', [5, PREV]],
    23 : ['DeviceController', 'navigate_device_focus', [1, NEXT]],
    33 : ['DeviceController', 'navigate_device_focus', [2, NEXT]],
    43 : ['DeviceController', 'navigate_device_focus', [3, NEXT]],
    53 : ['DeviceController', 'navigate_device_focus', [4, NEXT]],
    63 : ['DeviceController', 'navigate_device_focus

    24 : ['DeviceController', 'toggle_device', [CURRENT, CURRENT]],
    34 : ['DeviceController', 'toggle_device', [CURRENT, CURRENT]],
    44 : ['DeviceController', 'toggle_device', [CURRENT, CURRENT]],
    54 : ['DeviceController', 'toggle_device', [CURRENT, CURRENT]],
    64 : ['DeviceController', 'toggle_device', [CURRENT, CURRENT]],
    25 : ['LooperController', 'clipLooper', [0]],
    35 : ['LooperController', 'clipLooper', [1]],
    45 : ['LooperController', 'clipLooper', [2]],
    55 : ['LooperController', 'clipLooper', [3]],
    65 : ['LooperController', 'clipLooper', [4]],
    
    92 : ['RedFrameController', 'play_clip', [0]],
    93 : ['RedFrameController', 'play_clip', [1]],
    94 : ['RedFrameController', 'play_clip', [2]],
    95 : ['RedFrameController', 'play_clip', [3]],
    97 : ['RedFrameController', 'play_clip', [4]],
    98 : ['RedFrameController', 'play_clip', [5]],
    99 : ['RedFrameController', 'play_clip', [6]],
    
    20 : ['TrackController', 'stop_or_rest
__all__ = ["SDL_GameController", "SDL_CONTROLLER_BINDTYPE_NONE",
           "SDL_CONTROLLER_BINDTYPE_BUTTON", "SDL_CONTROLLER_BINDTYPE_AXIS",
           "SDL_CONTROLLER_BINDTYPE_HAT", "SDL_GameControllerBindType",
           "SDL_GameControllerButtonBind", "SDL_GameControllerAddMapping",
           "SDL_GameControllerMappingForGUID", "SDL_GameControllerMapping",
           "SDL_IsGameController", "SDL_GameControllerNameForIndex",
           "SDL_GameControllerOpen", "SDL_GameControllerName",
           "SDL_GameControllerGetAttached", "SDL_GameControllerGetJoystick",
           "SDL_GameControllerEventState", "SDL_GameControllerUpdate",
           "SDL_CONTROLLER_AXIS_INVALID", "SDL_CONTROLLER_AXIS_LEFTX",
           "SDL_CONTROLLER_AXIS_LEFTY", "SDL_CONTROLLER_AXIS_RIGHTX",
           "SDL_CONTROLLER_AXIS_RIGHTY", "SDL_CONTROLLER_AXIS_TRIGGERLEFT",
           "SDL_CONTROLLER_AXIS_TRIGGERRIGHT", "SDL_CONTROLLER_AXIS_MAX",
           "SDL_GameControllerAxis", "SDL_GameControllerGetAxisF

           "SDL_GameControllerGetStringForAxis",
           "SDL_GameControllerGetBindForAxis", "SDL_GameControllerGetAxis",
           "SDL_CONTROLLER_BUTTON_INVALID", "SDL_CONTROLLER_BUTTON_A",
           "SDL_CONTROLLER_BUTTON_B", "SDL_CONTROLLER_BUTTON_X",
           "SDL_CONTROLLER_BUTTON_Y", "SDL_CONTROLLER_BUTTON_BACK",
           "SDL_CONTROLLER_BUTTON_GUIDE", "SDL_CONTROLLER_BUTTON_START",
           "SDL_CONTROLLER_BUTTON_LEFTSTICK", "SDL_CONTROLLER_BUTTON_RIGHTSTICK",
           "SDL_CONTROLLER_BUTTON_LEFTSHOULDER",
           "SDL_CONTROLLER_BUTTON_RIGHTSHOULDER",
           "SDL_CONTROLLER_BUTTON_DPAD_UP", "SDL_CONTROLLER_BUTTON_DPAD_DOWN",
           "SDL_CONTROLLER_BUTTON_DPAD_LEFT", "SDL_CONTROLLER_BUTTON_DPAD_RIGHT",
           "SDL_CONTROLLER_BUTTON_MAX", "SDL_GameControllerButton",
           "SDL_GameControllerGetButtonFromString",
           "SDL_GameControllerGetStringForButton",
           "SDL_GameControllerGetBindForButton", "SDL_GameControllerGetButton",
    

           "SDL_GameControllerAddMappingsFromRW"
           ]
class SDL_GameController(Structure):
    pass
SDL_CONTROLLER_BINDTYPE_NONE = 0
SDL_CONTROLLER_BINDTYPE_BUTTON = 1
SDL_CONTROLLER_BINDTYPE_AXIS = 2
SDL_CONTROLLER_BINDTYPE_HAT = 3
SDL_GameControllerBindType = c_int
class _gchat(Structure):
    _fields_ = [("hat", c_int), ("hat_mask", c_int)]
class _gcvalue(Union):
    _fields_ = [("button", c_int), ("axis", c_int), ("hat", _gchat)]
class SDL_GameControllerButtonBind(Structure):
    _fields_ = [("bindType", SDL_GameControllerBindType), ("value", _gcvalue)]
SDL_GameControllerAddMapping = _bind("SDL_GameControllerAddMapping", [c_char_p], c_int)
SDL_GameControllerMappingForGUID = _bind("SDL_GameControllerMappingForGUID", [SDL_JoystickGUID], c_char_p)
SDL_GameControllerMapping = _bind("SDL_GameControllerMapping", [POINTER(SDL_GameController)], c_char_p)
SDL_IsGameController = _bind("SDL_IsGameController", [c_int], SDL_bool)
SDL_GameControllerNameForIndex = _bind("SDL_GameControll
samples = [
	["Dispatch", ["Plane", "Emirates 209"], "please", ["Command", ["Taxi", "taxi to", ["Place", "runway 2"]]]],
	["Dispatch", ["Plane", "Swissair 11"], "you're cleared for", ["Command", ["Takeoff", "takeoff"]]],
	["Dispatch", ["Plane", "American 33"], ["Command", ["Takeoff", "take off on", ["Place", "runway 1"]]]],
	["Dispatch", ["Plane", "American 42"], ["Command", ["Taxi", "go to", ["Place", "gate C13"]]]],
	["Dispatch", ["Plane", "United 78"], "please", ["Command", ["AscendTo", "climb to", ["Altitude", "30,000 feet"]]]],
	["Dispatch", ["Plane", "Delta 92"], ["Query", ["AltitudeQuery", "what's your altitude ?"]]],
	["Dispatch", ["Plane", "American 32"], "you're cleared for", ["Command", ["Landing", "landing on", ["Place", "runway 1"]]]],
	["Dispatch", ["Plane", "American 104"], ["Command", ["AscendTo", "go to", ["Altitude", "5,000 feet"]]]],
	["Dispatch", ["Plane", "BA 300"], ["Command", ["HoldingPattern", "enter a holding pattern at", ["Altitude", "7,000 feet"]]]],
	["Dispa
"""
(Description)
Created on Jan 28, 2014
"""
__author__ = 'Weber Jean-Paul'
__email__ = 'jean-paul.weber@govcert.etat.lu'
__copyright__ = 'Copyright 2013, GOVCERT Luxembourg'
__license__ = 'GPL v3+'
class DefinitionBrokerBase(BrokerBase):
  """This is the interface between python an the database"""
  def __init__(self, session):
    BrokerBase.__init__(self, session)
  def get_defintion_by_chksum(self, chksum):
    """
    Returns the attribute definition object with the given name
    Note: raises a NothingFoundException
    :param identifier: the id of the requested user object
    :type identifier: integer
    :returns: Object
    """
    try:
      definition = self.session.query(self.get_broker_class()).filter(getattr(self.get_broker_class(), 'chksum') == chksum).one()
      return definition
    except sqlalchemy.orm.exc.NoResultFound:
      raise NothingFoundException(u'No {0} not found for CHKSUM {1}'.format(self.get_broker_class().__class__.__name__,
                         

    except sqlalchemy.exc.SQLAlchemyError as error:
      self.session.rollback()
      raise BrokerException(error)
  def get_defintion_by_chksums(self, chksums):
    """
    Returns the attribute definition object with the given name
    Note: raises a NothingFoundException or a TooManyResultsFound Exception
    :param identifier: the id of the requested user object
    :type identifier: integer
    :returns: Object
    """
    try:
      definitions = self.session.query(self.get_broker_class()).filter(getattr(self.get_broker_class(), 'chksum').in_(chksums)).all()
      if definitions:
        return definitions
      else:
        return list()
    except sqlalchemy.orm.exc.NoResultFound:
      raise NothingFoundException(u'No {0} not found for CHKSUMS {1}'.format(self.get_broker_class().__class__.__name__,
                                                                             chksums))
    except sqlalchemy.exc.SQLAlchemyError as error:
      self.session.rollback()
      ra
class ConfigurationRepositoryBase(ItemBase):
    '''
    classdocs
    '''
    def __init__(self, repositoryProperty=list(), artifactPath=list(), repositoryType=None, artifact=list(), repositoryPath=None, readOnly=False, syncIntervalSeconds=None, artifactType=None):
        ItemBase.__init__(self)
        self._attrSpecs = getattr(self, '_attrSpecs', {})
        self._attrSpecs.update({'repositoryProperty': {'maxOccurs': 'unbounded', 'type': 'Property', 'name': 'repositoryProperty', 'minOccurs': '0', 'native': False}, 'artifactPath': {'maxOccurs': 'unbounded', 'type': 'string', 'name': 'artifactPath', 'minOccurs': '0', 'native': True}, 'repositoryType': {'type': 'string', 'name': 'repositoryType', 'minOccurs': '0', 'native': True}, 'artifact': {'maxOccurs': 'unbounded', 'type': 'Link', 'name': 'artifact', 'minOccurs': '0', 'native': False}, 'repositoryPath': {'type': 'string', 'name': 'repositoryPath', 'minOccurs': '0', 'native': True}, 'readOnly': {'type': 'boolean', 'name': 'readOnly
class PrintVisitor2(PrintVisitor):
    def visitShiftLeftInstr(self, n):
        if len(n.rhs) > 1:
            return "%s = %s << %s" % (self.dispatch(n.lhs),
                                      self.dispatch(n.rhs[0]),
                                      self.dispatch(n.rhs[1]))
        else:
            return "%s <<= %s" % (self.dispatch(n.lhs),
                                  self.dispatch(n.rhs[0]))
    def visitShiftRightInstr(self, n):
        if len(n.rhs) > 1:
            return "%s = %s >> %s" % (self.dispatch(n.lhs),
                                      self.dispatch(n.rhs[0]),
                                      self.dispatch(n.rhs[1]))
        else:
            return "%s >>= %s" % (self.dispatch(n.lhs),
                                  self.dispatch(n.rhs[0]))
    def visitIntOrInstr(self, n):
        if len(n.rhs) > 1:
            return "%s = %s | %s" % (self.dispatch(n.lhs),
                                     self.dispatch(n.rhs[0]),
                      

        else:
            return "%s |= %s" % (self.dispatch(n.lhs),
                                 self.dispatch(n.rhs[0]))
    def visitIntAndInstr(self, n):
        if len(n.rhs) > 1:
            return "%s = %s & %s" % (self.dispatch(n.lhs),
                                     self.dispatch(n.rhs[0]),
                                     self.dispatch(n.rhs[1]))
        else:
            return "%s &= %s" % (self.dispatch(n.lhs),
                                 self.dispatch(n.rhs[0]))
    def visitIntNotInstr(self, n):
        x = self.dispatch(n.lhs)
        return '%s = ~%s' % (x,x)
    
    def visitCMPLInstr(self, n):
        return "%s == %s?" % (self.dispatch(n.rhs[0]), self.dispatch(n.rhs[1]))
    def visitSetIfEqInstr(self, n):
        return "sete %s" % self.dispatch(n.lhs)
    def visitSetIfNotEqInstr(self, n):
        return "setne %s" % self.dispatch(n.lhs)
    def visitIntMoveZeroExtendInstr(self, n):
        return "movbzl %s, %s" % (','.join([self.dispatch(c) f
CURRENT_DIR = os.path.abspath(os.path.dirname(__file__))
CONFIG_FILE = CURRENT_DIR + "".join('/conf/config.ini')
LIBS_DIR = CURRENT_DIR + "".join('/../')
if LIBS_DIR not in sys.path:
    sys.path[0:0] = [LIBS_DIR]
class TestDispatch:
    def test_ojigi(self):
        payload = {}
        dispatch = Dispatch('ojigi', payload, CONFIG_FILE)
        assert dispatch.repository == ''
        assert dispatch.branch == ''
    def test_github(self):
        payload = {
            "ref": "refs/heads/testing",
            "repository": {
                "name": "foo"
            }
        }
        dispatch = Dispatch('github', payload, CONFIG_FILE)
        assert dispatch.repository == 'foo'
        assert dispatch.branch == 'testing'
    def test_bitbucket(self):
        payload = {
            "commits": [{"branch": "testing"}],
            "repository": {
                "name": "foo"
            }
        }
        dispatch = Dispatch('bitbucket', payload, CONFIG_FILE)
        assert dispat

        assert dispatch.branch == 'testing'
    def test_config_file_repo(self):
        payload = {
            "commits": [{"branch": "testing"}],
            "repository": {
                "name": "foo"
            }
        }
        dispatch = Dispatch('bitbucket', payload, CONFIG_FILE)
        assert dispatch.config_file_repo == './foo/config.ini'
    def test_dispatch_path(self):
        payload = {
            "commits": [{"branch": "testing"}],
            "repository": {
                "name": "foo"
            }
        }
        dispatch = Dispatch('bitbucket', payload, CONFIG_FILE)
        assert dispatch.dispatch_path == './'
    def test_script_name(self):
        payload = {
            "commits": [{"branch": "testing"}],
            "repository": {
                "name": "foo"
            }
        }
        dispatch = Dispatch('bitbucket', payload, CONFIG_FILE)
        assert dispatch.script_name == 'testing.sh'
    def test_mails(self):
        payload = {
      
""" base class for all bots. """
cpy = copy.deepcopy
def predispatch(bot, event):
    if event.status == "done":
        logging.debug("dispatch - event is done .. ignoring")
        return
    if event.isremote():
        logging.done("dispatch - event is remote .. not dispatching")
        return
    return True
def dispatch(bot, event):
    """ dispatch an event. """
    logging.info("dispatch - doing event %s" % event.dump())
    if event.userhost in bot.ignore: logging.warn("%s - ignore on %s" % (bot.name, event.userhost)) ; return
    if event.nodispatch:
        logging.debug("dispatch - nodispatch option is set - ignoring %s" % event.userhost)
        return
    bot.status = "dispatch"
    event.bind(bot)
    bot.curevent = event
    go = False
    execstr = event.iscmnd()
    logging.debug("dispatch - execstr is %s" % execstr)
    try:
        if execstr:
            event.iscommand = True
            event.dontclose = True
            e = cpy(event)
            e.usercmnd = e

            e.txt = execstr
            e.showexception = True
            if not e.options: e.makeoptions()
            e.bind(bot)
            if e.usercmnd in event.chan.data.silentcommands: e.silent = True
            result = bot.plugs.dispatch(bot, e)
        else:
            logging.debug("dispatch - no go for %s (cc is %s)" % (event.auth or event.userhost, execstr))
            result =  None
    except NoSuchUser, ex: logging.error("no such user: %s" % str(ex)) ; result = None
    except NoSuchCommand: logging.info("no such command: %s" % event.usercmnd) ; result = None
    return result
last_callbacks.add('PRIVMSG', dispatch, predispatch)
last_callbacks.add('MESSAGE', dispatch, predispatch)
last_callbacks.add('BLIP_SUBMITTED', dispatch, predispatch)
last_callbacks.add('WEB', dispatch, predispatch)
last_callbacks.add('CONSOLE', dispatch, predispatch)
last_callbacks.add('DCC', dispatch, predispatch)
last_callbacks.add('DISPATCH', dispatch, predispatch)
last_callbacks.add('CMN
"""packet.py: Raw packet object."""
log = logging.getLogger(__name__)
__author__ = "Raido Pahtma"
__license__ = "MIT"
class Packet(object):
    def __init__(self, dispatch=0):
        self._dispatch = dispatch
        self._payload = ""
        self.callback = None
    @property
    def dispatch(self):
        return self._dispatch
    @dispatch.setter
    def dispatch(self, dispatch):
        self._dispatch = dispatch
    @property
    def payload(self):
        return self._payload
    @payload.setter
    def payload(self, payload):
        self._payload = payload
    def serialize(self):
        return struct.pack("! B", self._dispatch) + self._payload
    def __str__(self):
        return "[{0._dispatch:02X}]{1:s}".format(self, self._payload.encode("hex").upper())
    @staticmethod
    def deserialize(data):
        if len(data) == 0:
            raise ValueError("At least 1 byte is required to deserialize a Packet!")
        p = Packet(dispatch=ord(data[0]))
        p.payload = da
norm = numpy.linalg.norm
dot = numpy.dot
array = numpy.array
class save_class:
    pass
save = save_class()
save.n = 10
save.p_degree = 3
save.n_samples = 10000
def mi_itt(length, degree):
    prod = itt.product(range(degree+1), repeat=length)
    return ( i for i in prod if sum(i) <= degree )
def mi_pow(x, i):
    y = 1.0
    for j in range(len(x)):
        y *= x[j]**i[j]
    return y
def mpoly_eval(coeff, x, degree):
    return sum( coeff[j]*mi_pow(x, i) for j,i in enumerate(mi_itt(len(x), degree)) )
def xsample(N, mean, sig):
    xsamps = numpy.zeros((N, len(mean)) )
    for j in range(len(mean)):
        xsamps[:,j] = numpy.random.normal(mean[j], sig[j], N)
    return xsamps
print "drawig coefficients..."
save.coefficients = numpy.array( \
    [random.normalvariate(0,1) for j in mi_itt(save.n, save.p_degree)] )
print "drawing x samples:", save.n_samples
save.means = array([random.normalvariate(0,1) for j in range(save.n) ])
save.sigs = 0.5*abs(save.means)
save.xsamples = xsample(s
@csrf_exempt
def create_site(request):
	site_id = request.POST['unifi_site_id']
	site_name = request.POST['unifi_site_name']
	controller = UnifiController.objects.get(pk = request.POST['unifi_controller'])
	controller = controller.controller()
	return HttpResponse(controller.add_site(site_id, site_name))
@csrf_exempt
def set_general_settings(request):
	site_id = request.POST['unifi_site_id']
	controller = UnifiController.objects.get(pk = request.POST['unifi_controller'])
	controller = controller.controller(site_id)
	controller.set_site_auto_upgrade(True)
	controller.set_site_timezone('Europe/Amsterdam')
	return HttpResponse(True)
@csrf_exempt
def set_guest_portal(request):
	site_id = request.POST['unifi_site_id']
	controller = UnifiController.objects.get(pk = request.POST['unifi_controller'])
	controller = controller.controller(site_id)
	return HttpResponse(controller.set_site_guest_access())
@csrf_exempt
def add_wlans(request):
	site_id = request.POST['unifi_site_id']
	ssid = request.
class BaseStationController(PyQt4.QtCore.QObject):
    __INSTANCE = None
    def __init__(self):
        super(BaseStationController, self).__init__()
        self.__LOGGER = LogController.getInstance()
        self.__rocketController = RocketController.getInstance()
        self.__baseStationModel = BaseStation()
        self.__RFD900SerialController = SerialController()
        self.__XBeeSerialController = SerialController()
        self.__globalSatSerialController = SerialController()
        self.__RFD900 = RFD900Strategy(self.__rocketController, self.__RFD900SerialController.serialConnection)
        self.__XBee = XbeeStrategy(self.__rocketController, self.__XBeeSerialController.serialConnection)
        self.setupSerialDevices()
        self.__gpsDevice = GlobalSat(self.__globalSatSerialController)
        self.__RFD900.rocketDiscovered.connect(self.__on_rocketDiscovery)
        self.__gpsDevice.coordsReceived.connect(self.__on_coordsReceived)
    def setupSerialDevices(self):
 

        self.__RFD900SerialController.updateSerialConnectionPort('/dev/ttyS1')
        self.__RFD900SerialController.updateSerialConnectionBaudrate(57600)
        self.__XBeeSerialController.updateSerialConnectionDeviceName("XBEE")
        self.__XBeeSerialController.updateSerialConnectionPort("/dev/ttyS0")
        self.__XBeeSerialController.updateSerialConnectionBaudrate(9600)
        self.__globalSatSerialController.updateSerialConnectionDeviceName("GlobalSat GPS")
        self.__globalSatSerialController.updateSerialConnectionPort("/dev/ttyS1")
        self.__globalSatSerialController.updateSerialConnectionBaudrate(4800)
    def connectSerialDevices(self):
        try:
            self.__RFD900.connect()
            self.__XBee.connect()
            self.__gpsDevice.connect()
        except SerialDeviceException.UnableToConnectException as e:
            self.__LOGGER.error(e.message)
            raise
    @property
    def baseStation(self):
        return self.__baseStationModel

    @baseStation.setter
    def baseStation(self, baseStationModel):
        self.__baseStationModel = baseStationModel
    @property
    def rocketController(self):
        return self.__rocketController
    @rocketController.setter
    def rocketController(self, rocketController):
        self.__rocketController = rocketController
    @property
    def RFD900SerialController(self):
        return self.__RFD900SerialController
    @property
    def XBeeSerialController(self):
        return self.__XBeeSerialController
    @property
    def GlobalSatSerialController(self):
        return self.__globalSatSerialController
    @GlobalSatSerialController.setter
    def GlobalSatSerialController(self, serialController):
        self.__globalSatSerialController = serialController
    @property
    def RFD900(self):
        return self.__RFD900
    @RFD900.setter
    def RFD900(self, rfdCommStrategy):
        self.__RFD900 = rfdCommStrategy
    @property
    def XBee(self):
        return se
assorted = {'incubi': {'ws': 5, 'bs': 5, 'strength': 4, 'toughness': 3,
            'wounds': 1,
            'initiative': 5, 'attacks': 2, 'save': 3, 'ap': 3, 'cost': 22},
 'banshee': {'ws': 4, 'bs': 4, 'strength': 3, 'toughness': 3, 'wounds': 1,
             'initiative': 4, 'attacks': 2, 'save': 4, 'ap': 3, 'cost': 14,
             'special_rules': 'banshee_mask'},
 'scorpion': {'ws': 4, 'bs': 4, 'strength': 4, 'toughness': 3, 'wounds': 1,
              'initiative': 5, 'attacks': 2, 'save': 3, 'ap': 7, 'cost': 17,
              'special_rules': 'mandiblaster'},
 'wraithblade': {'ws': 4, 'bs': 4, 'strength': 6, 'toughness': 6, 'wounds': 1,
                 'initiative': 4, 'attacks': 2, 'save': 3, 'ap': 3, 'cost': 32},
 'wraithaxe': {'ws': 4, 'bs': 4, 'strength': 7, 'toughness': 6, 'wounds': 1,
               'initiative': 4, 'attacks': 1, 'save': 3, 'ap': 2, 'cost': 32},
 'wraithlord': {'ws': 4, 'bs': 4, 'strength': 9, 'toughness': 8, 'wounds': 4,
                'initiative': 4, '

                'special_rules': 'hammer_of_wrath'},
 'direavenger': {'ws': 4, 'bs': 4, 'strength': 3, 'toughness': 3, 'wounds': 1,
                 'initiative': 4, 'attacks': 1, 'save': 4, 'ap': 7, 'cost': 13},
 'warpspider': {'ws': 4, 'bs': 4, 'strength': 3, 'toughness': 3, 'wounds': 1,
                'initiative': 4, 'attacks': 1, 'save': 3, 'ap': 7, 'cost': 16},
 'wraithguard': {'ws': 4, 'bs': 4, 'strength': 5, 'toughness': 6, 'wounds': 1,
                 'initiative': 4, 'attacks': 1, 'save': 3, 'ap': 7, 'cost': 32},
 'wraithflamer': {'ws': 4, 'bs': 4, 'strength': 5, 'toughness': 6, 'wounds': 1,
                  'initiative': 4, 'attacks': 1, 'save': 3, 'ap': 7,
                  'cost': 32},
 'wych': {'ws': 4, 'bs': 4, 'strength': 3, 'toughness': 3, 'wounds': 1,
          'initiative': 5, 'attacks': 2, 'save': 6, 'ap': 7, 'invun_save': 4,
          'cost': 10},
 'kabalite': {'ws': 4, 'bs': 4, 'strength': 3, 'toughness': 3, 'wounds': 1,
              'initiative': 4, 'attacks

 'wraithknight': {'ws': 4, 'bs': 4, 'strength': 10, 'toughness': 8, 'wounds': 6,
                  'initiative': 4, 'attacks': 4, 'save': 3, 'ap': 3,
                  'cost': 250},
 'archon': {'ws': 7, 'bs': 7, 'strength': 3, 'toughness': 3, 'wounds': 3,
            'initiative': 7, 'attacks': 4, 'save': 5, 'ap': 2, 'invun_save': 2,
            'cost': 120},
 'marine': {'ws': 4, 'bs': 4, 'strength': 4, 'toughness': 4, 'wounds': 1,
            'initiative': 4, 'attacks': 1, 'save': 3, 'ap': 7, 'cost': 16},
 'assaultmarine': {'ws': 4, 'bs': 4, 'strength': 4, 'toughness': 4, 'wounds': 1,
                   'initiative': 4, 'attacks': 2, 'save': 3, 'ap': 7,
                   'cost': 22},
 'terminator': {'ws': 4, 'bs': 4, 'strength': 8, 'toughness': 4, 'wounds': 1,
                'initiative': 1, 'attacks': 2, 'save': 2, 'ap': 2,
                'invun_save': 5, 'cost': 25},
 'terminatorlc': {'ws': 4, 'bs': 4, 'strength': 4, 'toughness': 4, 'wounds': 1,
                  'initiative': 4
def assert_hooks(hooks):
    assert sample_models.GLOBAL_HOOK_HISTORY == hooks
    sample_models.GLOBAL_HOOK_HISTORY = []
def test_document_hook_save(WithHooks):
    assert_hooks([])
    assert WithHooks.count() == 0
    assert_hooks([])
    WithHooks.insert_one({"a": 1})
    a1 = WithHooks.find_one()
    assert_hooks([["after_save", 1]])
    a1["b"] = 2
    a1.save()
    assert_hooks([["before_save", 1], ["after_save", 1]])
    a1 = WithHooks.find_one()
    a1["a"] = 2
    a1.save()
    assert_hooks([["before_save", 1], ["after_save", 2]])
    try:
        a1.save_partial({"a": 3, "raise_before_save": True})
    except:
        assert_hooks([])
        assert a1["a"] == 2
    else:
        assert False
    try:
        a1.unset_fields(["a", "raise_before_save"])
    except:
        assert_hooks([])
        assert a1.get("a") == 2
    else:
        assert False
    WithHooks.update({}, {"$set": {"a": 3}})
    assert_hooks([["before_save", 2], ["after_save", 3]])
    WithHooks.find_one_

    assert_hooks([["before_save", 3], ["after_save", 3]])
    WithHooks.find_one_and_update({}, {"$set": {"a": 5}}, return_document="before")
    assert_hooks([["before_save", 4], ["after_save", 4]])
    WithHooks.find_one_and_update({}, {"$set": {"a": 6}}, return_document="after")
    assert_hooks([["before_save", 5], ["after_save", 6]])
    WithHooks.update_one({}, {"$set": {"a": 7}})
    assert_hooks([["before_save", 6], ["after_save", 7]])
    WithHooks.update_many({}, {"$set": {"a": 8}})
    assert_hooks([["before_save", 7], ["after_save", 8]])
    WithHooks.replace_one({}, {"a": 9})
    assert_hooks([["before_save", 8], ["after_save", 9]])
    WithHooks.update({}, {"$set": {"incr_before_save": True, "a": 10}})
    assert_hooks([["before_save", 9], ["after_save", 11]])
def test_document_hook_delete(WithHooks):
    assert_hooks([])
    assert WithHooks.count() == 0
    assert_hooks([])
    WithHooks.insert_one({"a": 1})
    assert_hooks([["after_save", 1]])
    WithHooks.find_one(
"""
Defines simple limitations on project dispatch without considering unit
commitment. This module is mutually exclusive with the project.commit
module which constrains dispatch to unit committment decisions.
SYNOPSIS
>>> model = define_AbstractModel(
...     'timescales', 'financials', 'load_zones', 'fuels',
...     'gen_tech', 'project.build', 'project.dispatch', 'project.no_commit')
>>> instance = model.load_inputs(inputs_dir='test_dat')
"""
def define_components(mod):
    """
    Adds components to a Pyomo abstract model object to constrain
    dispatch decisions subject to available capacity, renewable resource
    availability, and baseload restrictions. Unless otherwise stated,
    all power capacity is specified in units of MW and all sets and
    parameters are mandatory. This module estimates project dispatch
    limits and fuel consumption without consideration of unit
    commitment. This can be a useful approximation if fuel startup
    requirements are a small portion of

    that the aggregate fuel consumption with respect to energy
    production can be approximated as a line with a 0 intercept. This
    estimation method has been known to result in excessive cycling of
    Combined Cycle Gas Turbines in the SWITCH-WECC model.
    DispatchUpperLimit[(proj, t) in PROJ_DISPATCH_POINTS] is an
    expression that defines the upper bounds of dispatch subject to
    installed capacity, average expected outage rates, and renewable
    resource availability.
    DispatchLowerLimit[(proj, t) in PROJ_DISPATCH_POINTS] in an
    expression that defines the lower bounds of dispatch, which is 0
    except for baseload plants where is it the upper limit.
    Enforce_Dispatch_Lower_Limit[(proj, t) in PROJ_DISPATCH_POINTS] and
    Enforce_Dispatch_Upper_Limit[(proj, t) in PROJ_DISPATCH_POINTS] are
    constraints that limit DispatchProj to the upper and lower bounds
    defined above.
        DispatchLowerLimit <= DispatchProj <= DispatchUpperLimit
    ProjFuelUseRat

    calculates fuel consumption for the variable ProjFuelUseRate as
    DispatchProj * proj_full_load_heat_rate. The units become:
    MW * (MMBtu / MWh) = MMBTU / h
    """
    def DispatchUpperLimit_expr(m, proj, t):
        if proj in m.VARIABLE_PROJECTS:
            return (m.ProjCapacityTP[proj, t] * m.proj_availability[proj] *
                    m.prj_max_capacity_factor[proj, t])
        else:
            return m.ProjCapacityTP[proj, t] * m.proj_availability[proj]
    mod.DispatchUpperLimit = Expression(
        mod.PROJ_DISPATCH_POINTS,
        initialize=DispatchUpperLimit_expr)
    def DispatchLowerLimit_expr(m, proj, t):
        if proj in m.BASELOAD_PROJECTS:
            return DispatchUpperLimit_expr(m, proj, t)
        else:
            return 0
    mod.DispatchLowerLimit = Expression(
        mod.PROJ_DISPATCH_POINTS,
        initialize=DispatchLowerLimit_expr)
    mod.Enforce_Dispatch_Lower_Limit = Constraint(
        mod.PROJ_DISPATCH_POINTS,
        rule=lambda m, 
sys.path.insert(0, os.path.join(os.environ["GC_HOME"],
				"contrib", "MITRE", "templates"))
def Welcome(env, dict):
    try:
	file = dict[":audiofile"]
    except KeyError:
	sys.stderr.write("No filename provided\n")
	return dict
    try:
	broker_method = dict[":broker_method"]
    except KeyError:
	broker_method = None
    fp = open(file, "r")
    a = Galaxy.BinaryObject(Galaxy.GAL_BINARY)
    fp.seek(0, 2)
    l = fp.tell()
    fp.seek(0, 0)
    a.fromfile(fp, l)
    fp.close()
    f = Galaxy.Frame("main", Galaxy.GAL_CLAUSE)
    if broker_method in [None, "original_env", "original_comm"]:
	b = GalaxyIO.BrokerDataOut(env.conn, 10)
	b.PopulateFrame(f, ":binary_host", ":binary_port")
	b.Write(a)
	b.DataDone()
    elif broker_method in ["proxy_obj", "proxy_stream", "proxy_original"]:
	p = GalaxyIO.BrokerProxyOut(env, 10, type = Galaxy.GAL_BINARY)
	p.Write(a)
	p.DataDone()
	f[":binary_proxy"] = p
    env.WriteFrame(f)
    return None
def Notify(env, dict):
    print "Audio send: %s" % di
__author__ = 'Zhao Guoyan'
class userConfig:
    UserName = "_NULL_"
    hadLogin = False
    WORD = "_NULL_"
class tcpManage:
    @staticmethod
    def connectServer(ipAddr='127.0.0.1', port=60000):
        tcpManage.conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        tcpManage.conn.connect((ipAddr, port))
    @staticmethod
    def wordQuery(word, username='_NULL_'):
        tcpManage.connectServer()
        WORD=word
        answer = tcpManage.conn.recv(2048)
        rst = {}
        if not 'NoSuchWord' in answer:
                expPart, rest = web.split(';likenumber:')
                likenum, liked = rest.split(';liked:')
                key = expPart.split(':')[0]
                rst[key.encode('ascii', 'ignore')] = (expPart[len(key):], int(likenum), 'true' in liked)
        tcpManage.conn.close()
        return rst
    @staticmethod
    def login(name, passwd):
        tcpManage.connectServer()
        tcpManage.conn.send('Login ' + name + ' ' + passwd + '\n')
     

        tcpManage.conn.close()
        return 'Success' in ans
    @staticmethod
    def logout(name):
        tcpManage.connectServer()
        tcpManage.conn.send('Logout ' + name + '\n')
        userConfig.UserName = "_NULL_"
        userConfig.hadLogin = False
        ans = tcpManage.conn.recv(2048)
        tcpManage.conn.close()
        return 'Logout' in ans
    @staticmethod
    def register(name, passwd):
        tcpManage.connectServer()
        tcpManage.conn.send('Register ' + name + ' ' + passwd + '\n')
        ans = tcpManage.conn.recv(2048)
        tcpManage.conn.close()
        return 'Success' in ans
    @staticmethod
    def clickLike(word, src, name):
        tcpManage.connectServer()
        tcpManage.conn.send('Like ' + name + ' ' + word + ' ' + src + '\n')
        ans = tcpManage.conn.recv(2048)
        tcpManage.conn.close()
        return 'Success' in ans
    @staticmethod
    def share(me, dest, word, src, exp):
        pass
    @staticmethod
    def likeList(n

        tcpManage.connectServer()
        tcpManage.conn.send('Word ' + name + '\n')
        rst = ()
        likelist = tcpManage.conn.recv(2048).split(' ')[1:]
        for item in likelist:
            rst.append(item.split(':'))
        tcpManage.conn.close()
        return rst
    @staticmethod
    def onlineList():
        tcpManage.conn.send('User\n')
        rst = ()
        rst.append(online.split(' '))
        rst.append(offline.split(' '))
        return rst
    @staticmethod
    def goodbye():
        tcpManage.conn.send('Bye!\n')
        tcpManage.conn.close()
def user_login(request):
    request.encoding = 'utf-8'
    username = request.POST['username'].encode('utf-8')
    password = request.POST['password'].encode('utf-8')
    print username
    print password
    if tcpManage.login(username, password):
        login_error = False
        userConfig.UserName = username
        userConfig.hadLogin = True
        tempLogin = userConfig.hadLogin
        tempUsername = userC
try:
    file_not_found_exception_class = FileNotFoundError
except NameError:
    file_not_found_exception_class = IOError
utils.app_runner_setup_multiple(__name__, [
    (kitchen_sink_app.app, 8060),
    (retry_app.app, 8063),
])
save_dir = os.environ.get('WEBRACER_TEST_TMP') or os.path.join(os.path.dirname(__file__), 'tmp')
nonexistent_save_dir = '/tmp/nonexistent.dee11123e367b4a7506f856cc55898fabd4caeff'
def list_save_dir():
    entries = os.listdir(save_dir)
    entries = [entry for entry in entries if entry[0] != '.']
    return entries
@nose.plugins.attrib.attr('client')
@webracer.config(host='localhost', port=8060)
class ResponseSavingTest(webracer.WebTestCase):
    def setUp(self, *args, **kwargs):
        super(ResponseSavingTest, self).setUp(*args, **kwargs)
        
        if not os.path.exists(save_dir):
            os.mkdir(save_dir)
        else:
            for entry in list_save_dir():
                os.unlink(os.path.join(save_dir, entry))
    
    @webracer.config(s

    def test_save_successful(self):
        self.assertEqual(0, len(list_save_dir()))
        
        self.get('/ok')
        self.assert_status(200)
        self.assertEqual('ok', self.response.body)
        
        entries = list_save_dir()
        self.assertEqual(4, len(entries))
        assert 'last.html' in entries, 'last.html not in entries: %s' % repr(entries)
        entries.remove('last.html')
        entries.sort()
        assert entries[0].endswith('.request.headers')
        assert entries[1].endswith('.response.body.html')
        assert entries[2].endswith('.response.headers')
    
    @webracer.config(save_responses=True, save_dir=save_dir)
    def test_save_text_plain(self):
        self.assertEqual(0, len(list_save_dir()))
        
        self.get('/ok_plain')
        self.assert_status(200)
        self.assertEqual('ok', self.response.body)
        
        entries = list_save_dir()
        self.assertEqual(4, len(entries))
        assert 'last.txt' in entries, '

        entries.remove('last.txt')
        entries.sort()
        assert entries[0].endswith('.request.headers')
        assert entries[1].endswith('.response.body.txt')
        assert entries[2].endswith('.response.headers')
    
    @webracer.config(save_responses=True, save_dir=save_dir)
    def test_save_encoded(self):
        self.assertEqual(0, len(list_save_dir()))
        
        self.get('/utf16_body')
        self.assert_status(200)
        self.assertEqual('hello world', self.response.body)
        
        entries = list_save_dir()
        self.assertEqual(4, len(entries))
        assert 'last.txt' in entries, 'last.txt not in entries: %s' % repr(entries)
        entries.remove('last.txt')
        entries.sort()
        assert entries[0].endswith('.request.headers')
        assert entries[1].endswith('.response.body.txt')
        with open(os.path.join(save_dir, entries[1]), 'rb') as f:
            contents = f.read()
            self.assertEqual(utils.u('hello world').en
class SaveManager(DirectObject):
    
    def __init__(self,world):
        self.worldObj = world
        self.saveFileName = "Orellia.save"
        self.isOpen = True
        
    def closeFile(self,saveFile):
        saveFile.close()
        self.isOpen = False
        
    def loadWorld(self):
        try:
            saveFile = open(self.saveFileName,'rb')
        except:
            saveFile = open(self.saveFileName,'wb')
        try:
            playerPosBin = saveFile.read(12)
            playerX,playerY,playerZ = struct.unpack("fff",playerPosBin)
            playerSpawnBin = saveFile.read(12)
            playerSpawnX,playerSpawnY,playerSpawnZ = struct.unpack("fff",playerPosBin)
            print playerX,playerY,playerZ
            self.worldObj.hero.setPos(playerX,playerY,playerZ)
            self.worldObj.spawnPoint = (playerSpawnX,playerSpawnY,playerSpawnZ)
            
            disabledObjectsNum = saveFile.read(4)
            disableRange = struct.unpack('i',disabledObje

            print disableRange[0]
            for ii in range(disableRange[0]):
                print ii
                disabledObject = saveFile.read()
                self.worldObj.objects[disabledObject].removeNode()
        except:
            print "EOF"
        self.closeFile(saveFile)
        
    def saveWorld(self):
        saveFile = open(self.saveFileName,'wb')
        playerX = struct.pack("f",self.worldObj.hero.getX())
        playerY = struct.pack("f",self.worldObj.hero.getY())
        playerZ = struct.pack("f",self.worldObj.hero.getZ())
        
        playerSpawnX = struct.pack("f",self.worldObj.spawnPoint[0])
        playerSpawnY = struct.pack("f",self.worldObj.spawnPoint[1])
        playerSpawnZ = struct.pack("f",self.worldObj.spawnPoint[2])
        
        saveFile.write(playerX)
        saveFile.write(playerY)
        saveFile.write(playerZ)
        saveFile.write(playerSpawnX)
        saveFile.write(playerSpawnY)
        saveFile.write(playerSpawnZ)
        
  
logger = Logger(level=logging.INFO)
class SyncControllerImages(OpenStackSyncStep):
    provides=[ControllerImages]
    observes = ControllerImages
    requested_interval=0
    def fetch_pending(self, deleted):
        if (deleted):
            return []
        return ControllerImages.objects.filter(Q(enacted__lt=F('updated')) | Q(enacted=None))
    def sync_record(self, controller_image):
        logger.info("Working on image %s on controller %s" % (controller_image.image.name, controller_image.controller))
        image_fields = {'endpoint':controller_image.controller.auth_url,
                        'admin_user':controller_image.controller.admin_user,
                        'admin_password':controller_image.controller.admin_password,
                        'name':controller_image.image.name,
                        'filepath':controller_image.image.path,
                        }
        res = run_template('sync_controller_images.yaml', image_fields, path='controller_images', exp
__revision__ = "__FILE__ __REVISION__ __DATE__ __DEVELOPER__"
test = TestSCons.TestSCons()
test.subdir('repository', ['repository', 'subdir'], 'work')
repository_aaa_in = test.workpath('repository', 'aaa.in')
repository_aaa_mid = test.workpath('repository', 'aaa.mid')
repository_aaa_out = test.workpath('repository', 'aaa.out')
repository_bbb_in = test.workpath('repository', 'bbb.in')
repository_bbb_mid = test.workpath('repository', 'bbb.mid')
repository_bbb_out = test.workpath('repository', 'bbb.out')
repository_subdir_ccc_in = test.workpath('repository', 'subdir', 'ccc.in')
repository_subdir_ccc_mid = test.workpath('repository', 'subdir', 'ccc.mid')
repository_subdir_ccc_out = test.workpath('repository', 'subdir', 'ccc.out')
repository_subdir_ddd_in = test.workpath('repository', 'subdir', 'ddd.in')
repository_subdir_ddd_mid = test.workpath('repository', 'subdir', 'ddd.mid')
repository_subdir_ddd_out = test.workpath('repository', 'subdir', 'ddd.out')
work_aaa_in = test.workpath('work',

work_aaa_mid = test.workpath('work', 'aaa.mid')
work_aaa_out = test.workpath('work', 'aaa.out')
work_bbb_in = test.workpath('work', 'bbb.in')
work_bbb_mid = test.workpath('work', 'bbb.mid')
work_bbb_out = test.workpath('work', 'bbb.out')
work_subdir_ccc_in = test.workpath('work', 'subdir', 'ccc.in')
work_subdir_ccc_mid = test.workpath('work', 'subdir', 'ccc.mid')
work_subdir_ccc_out = test.workpath('work', 'subdir', 'ccc.out')
work_subdir_ddd_in = test.workpath('work', 'subdir', 'ddd.in')
work_subdir_ddd_mid = test.workpath('work', 'subdir', 'ddd.mid')
work_subdir_ddd_out = test.workpath('work', 'subdir', 'ddd.out')
opts = "-Y " + test.workpath('repository')
test.write(['repository', 'SConstruct'], r"""
def copy(env, source, target):
    source = str(source[0])
    target = str(target[0])
    print 'copy() < %s > %s' % (source, target)
    open(target, "wb").write(open(source, "rb").read())
Build = Builder(action=copy)
env = Environment(BUILDERS={'Build':Build})
env.Build('aaa.mid', '

env.Build('aaa.out', 'aaa.mid')
env.Build('bbb.mid', 'bbb.in')
env.Build('bbb.out', 'bbb.mid')
SConscript('subdir/SConscript', "env")
""")
test.write(['repository', 'subdir', 'SConscript'], r"""
Import("env")
env.Build('ccc.mid', 'ccc.in')
env.Build('ccc.out', 'ccc.mid')
env.Build('ddd.mid', 'ddd.in')
env.Build('ddd.out', 'ddd.mid')
""")
test.write(repository_aaa_in, "repository/aaa.in\n")
test.write(repository_bbb_in, "repository/bbb.in\n")
test.write(repository_subdir_ccc_in, "repository/subdir/ccc.in\n")
test.write(repository_subdir_ddd_in, "repository/subdir/ddd.in\n")
test.writable('repository', 0)
test.run(chdir = 'work', options = opts, arguments = '.')
test.fail_test(test.read(work_aaa_mid) != "repository/aaa.in\n")
test.fail_test(test.read(work_aaa_out) != "repository/aaa.in\n")
test.fail_test(test.read(work_bbb_mid) != "repository/bbb.in\n")
test.fail_test(test.read(work_bbb_out) != "repository/bbb.in\n")
test.fail_test(test.read(work_subdir_ccc_mid) != "repository/subdir/cc
""" storyxml.py
Contains a "broker" class that makes it easy to access data in the story XML files uploaded by the Flash applet;
this class is separated from views_flash.py to improve readability of the code and to avoid introducing "non-django view"
functions/classes into that module (separation of concerns, thus). 
"""
class Broker(object):
    """ (Very) simple read-only xml broker, allowing quick 'n easy access to the DOM structure """
    
    def __init__(self, xmlNode):
        """ Constructor; don't use this. Use the static getInstance() method to create a new broker
        """
        self._xmlNode = xmlNode
    
    def node(self):
        """ Returns the underlying DOM node of this broker instance """
        return self._xmlNode
    
    def text(self):
        """ Returns any text contained in the direct children of this node """
        rc = ''
        for node in self._xmlNode.childNodes:
            if node.nodeType == node.TEXT_NODE:
                rc = rc + node.dat

        return rc
    
    def __getattr__(self, name):
        tagList = self._xmlNode.getElementsByTagName(name)
        if len(tagList) > 0:
            tag = tagList[0]
            if tag.nodeType == tag.ELEMENT_NODE:
                return Broker(tagList[0])
            else:
                return tag.dat
        else:
            raise AttributeError, "object has no attribute '%s'" % name
class StoryXml(object):
    """ Represents a story XML document uploaded by the OurStories Flash applet """
    def __init__(self, xmlDoc):
        """ Constructor
        @param xmlDoc: The XML document of the story
        @type xmlDoc: xml.dom.minidom.Document
        """
        self._xmlBroker = Broker(xmlDoc)
        self._categories = None
        self.title = self._xmlBroker.title.text()
        self.summary = self._xmlBroker.summary.text()
        self.language = self._xmlBroker.language.text()
        self.city = self._xmlBroker.city.text()
        self.country = self._xmlBroker.coun

        self.duration = int(self._xmlBroker.recording.duration.text())
        
        self.imageFilename = self._xmlBroker.image.text()
        self.audioFilename = RED5_UPLOAD_PATH + self._xmlBroker.recording.file.text()
        
        self.contributorName = self._xmlBroker.name.text()
        self.contributorEmail = self._xmlBroker.email.text()
        self.contributorAge = int(self._xmlBroker.age.text())
  
    @property
    def categories(self):
        """ A list of category names that the story is tagged with (list of strings) """
        if self._categories == None:
            self._categories = []
            categoriesElement = self._xmlBroker.categories.node()
            for node in categoriesElement.childNodes:
                if (node.nodeType != node.TEXT_NODE):
                    if (node.tagName != 'othercategory'):
                        if (node.firstChild.data.lower() == 'true'):
                            self._categories.append(node.tagName)
              
search = django.dispatch.Signal(providing_args=[
    "request", "q", "location", "distance", "latitude", "longitude",
    "accounts", "tags", "events_only"]
account_created = django.dispatch.Signal(providing_args=["request", "data"])
account_updated = django.dispatch.Signal(providing_args=["request", "data"])
user_created = django.dispatch.Signal(providing_args=["request", "data"])
user_updated = django.dispatch.Signal(providing_args=["request", "data"])
invite_created = django.dispatch.Signal(providing_args=["request", "data"])
invite_accepted = django.dispatch.Signal(providing_args=["request", "data"])
invite_resent = django.dispatch.Signal(providing_args=["request", "data"])
resource_created = django.dispatch.Signal(providing_args=["request", "data"])
resource_updated = django.dispatch.Signal(providing_args=["request", "data"])
reindex_resource = django.dispatch.Signal(providing_args=["instance"])
curation_created = django.dispatch.Signal(providing_args=["request", "data"])
curation
admin.autodiscover()
urlpatterns = patterns('',
                       url(r'^$', 'linted.views.index', name='home'),
                       url(r'^repository/$', views.repository_list, name='repository_list'),
                       url(r'^repository/create/$', views.create_repository, name='create_repository'),
                       url(r'^repository/(?P<uuid>[a-zA-Z0-9\-]+)/$', views.view_repoository, name='view_repository'),
                       url(r'^repository/(?P<repo_uuid>[a-zA-Z0-9\-]+)/add_scanner/$', views.add_scanner,
                           name='add_scanner'),
                       url(r'^repository/(?P<uuid>[a-zA-Z0-9\-]+)/scan$', views.run_scan, name='scan_repository'),
                       url(r'^repository/(?P<uuid>[a-zA-Z0-9\-]+)/settings/(?P<scanner_name>[a-zA-Z]+)$',
                           views.scanner_settings,
                           name='scanner_settings'),
                       url(r'^scan/(?P<uuid>[a-zA-Z0-9\-]+)/$', views.view_scan,
      
def copy_repo_attributes_to_relation(apps, schema_editor):
    """
    Copy data in Project.repository_* attributes to Repository
    instances.
    """
    Project = apps.get_model('base', 'Project')
    Repository = apps.get_model('base', 'Repository')
    for project in Project.objects.all():
        repo = Repository(
            project=project,
            type=project.repository_type,
            url=project.repository_url,
        )
        repo.save()
def copy_relation_to_repo_attributes(apps, schema_editor):
    """
    Copy data in Repository instances to Project.repository_*
    attributes.
    """
    Project = apps.get_model('base', 'Project')
    for project in Project.objects.all():
        repo = project.repository_set.first()
        if repo is not None:
            project.repository_type = repo.type
            project.repository_url = repo.url
            project.save()
class Migration(migrations.Migration):
    dependencies = [
        ('base', '0025_add_repositor
"""
.. moduleauthor:: Gabriel Martin Becedillas Ruiz <gabriel.becedillas@gmail.com>
"""
LiveBroker = livebroker.LiveBroker
class BacktestingBroker(backtesting.Broker):
    MIN_TRADE_USD = 5
    """A Bitstamp backtesting broker.
    :param cash: The initial amount of cash.
    :type cash: int/float.
    :param barFeed: The bar feed that will provide the bars.
    :type barFeed: :class:`pyalgotrade.barfeed.BarFeed`
    :param fee: The fee percentage for each order. Defaults to 0.25%.
    :type fee: float.
    .. note::
        * Only limit orders are supported.
        * Orders are automatically set as **goodTillCanceled=True** and  **allOrNone=False**.
        * BUY_TO_COVER orders are mapped to BUY orders.
        * SELL_SHORT orders are mapped to SELL orders.
    """
    def __init__(self, cash, barFeed, fee=0.0025):
        commission = backtesting.TradePercentage(fee)
        super(BacktestingBroker, self).__init__(cash, barFeed, commission)
    def getInstrumentTraits(self, instrum

        return common.BTCTraits()
    def submitOrder(self, order):
        if order.isInitial():
            order.setAllOrNone(False)
            order.setGoodTillCanceled(True)
        return super(BacktestingBroker, self).submitOrder(order)
    def createMarketOrder(self, action, instrument, quantity, onClose=False):
        raise Exception("Market orders are not supported")
    def createLimitOrder(self, action, instrument, limitPrice, quantity):
        if instrument != common.btc_symbol:
            raise Exception("Only BTC instrument is supported")
        if action == broker.Order.Action.BUY_TO_COVER:
            action = broker.Order.Action.BUY
        elif action == broker.Order.Action.SELL_SHORT:
            action = broker.Order.Action.SELL
        if limitPrice * quantity < BacktestingBroker.MIN_TRADE_USD:
            raise Exception("Trade must be >= %s" % (BacktestingBroker.MIN_TRADE_USD))
        if action == broker.Order.Action.BUY:
            fee = self.getCommiss

            cashRequired = limitPrice * quantity + fee
            if cashRequired > self.getCash(False):
                raise Exception("Not enough cash")
        elif action == broker.Order.Action.SELL:
            if quantity > self.getShares(common.btc_symbol):
                raise Exception("Not enough %s" % (common.btc_symbol))
        else:
            raise Exception("Only BUY/SELL orders are supported")
        return super(BacktestingBroker, self).createLimitOrder(action, instrument, limitPrice, quantity)
    def createStopOrder(self, action, instrument, stopPrice, quantity):
        raise Exception("Stop orders are not supported")
    def createStopLimitOrder(self, action, instrument, stopPrice, limitPrice, quantity):
        raise Exception("Stop limit orders are not supported")
class PaperTradingBroker(BacktestingBroker):
    """A Bitstamp paper trading broker.
    :param cash: The initial amount of cash.
    :type cash: int/float.
    :param barFeed: The bar feed that 
column_repository_name = 'column_maker_1087'
column_repository_description = "Add column"
column_repository_long_description = "Compute an expression on every row"
convert_repository_name = 'convert_chars_1087'
convert_repository_description = "Convert delimiters"
convert_repository_long_description = "Convert delimiters to tab"
category_name = 'Test 1087 Advanced Circular Dependencies'
category_description = 'Test circular dependency features'
class TestRepositoryDependencies( ShedTwillTestCase ):
    '''Test installing a repository, then updating it to include repository dependencies.'''
    def test_0000_create_or_login_admin_user( self ):
        """Create necessary user accounts and login as an admin user."""
        self.galaxy_logout()
        self.galaxy_login( email=common.admin_email, username=common.admin_username )
        galaxy_admin_user = test_db_util.get_galaxy_user( common.admin_email )
        assert galaxy_admin_user is not None, 'Problem retrieving user with email 

        galaxy_admin_user_private_role = test_db_util.get_galaxy_private_role( galaxy_admin_user )
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % test_user_1_email
        test_user_1_private_role = test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % admin_email
        admin_user_private_role = test_db_util.get_private_role( admin_user )
    def test_0005_create_and_populate_column_repository( self ):
        """Create a category for this test suite and add repositories to it."""
        category = se

        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        repository = self.get_or_create_repository( name=column_repository_name, 
                                                    description=column_repository_description, 
                                                    long_description=column_repository_long_description, 
                                                    owner=common.test_user_1_name,
                                                    category_id=self.security.encode_id( category.id ), 
                                                    strings_displayed=[] )
        if self.repository_is_new( repository ):
            self.upload_file( repository, 
                              'column_maker/column_maker.tar', 
                              strings_displayed=[], 
                              commit_message='Uploaded column_maker.tar.' )
    def test_0010_create_and_populate_convert_repository( 
urlpatterns = patterns('',
    url(r'^db/api/clear', 'API.admin.clear'),
    url(r'^db/api/user/create/$', 'API.Handlers.hUser.createUser'),
    url(r'^db/api/user/details/$', 'API.Handlers.hUser.detailsUser'),
    url(r'^db/api/user/follow/$', 'API.Handlers.hUser.followUser'),
    url(r'^db/api/user/listFollowers/$', 'API.Handlers.hUser.listFollowers'),
    url(r'^db/api/user/listFollowing/$', 'API.Handlers.hUser.listFollowing'),
    url(r'^db/api/user/listPosts/$', 'API.Handlers.hUser.listPost'),
    url(r'^db/api/user/unfollow/$', 'API.Handlers.hUser.unfollowUser'),
    url(r'^db/api/user/updateProfile/$', 'API.Handlers.hUser.updateProfile'),
    url(r'^db/api/forum/create/$', 'API.Handlers.hForum.createForum'),
    url(r'^db/api/forum/details/$', 'API.Handlers.hForum.detailsForum'),
    url(r'^db/api/forum/listPosts/$', 'API.Handlers.hForum.listPostsForum'),
    url(r'^db/api/forum/listThreads/$', 'API.Handlers.hForum.listThreadsForum'),
    url(r'^db/api/forum/listUsers/$', 'API.H

    url(r'^db/api/thread/close/$', 'API.Handlers.hThread.closeThread'),
    url(r'^db/api/thread/create/$', 'API.Handlers.hThread.createThread'),
    url(r'^db/api/thread/details/$', 'API.Handlers.hThread.detailsThread'),
    url(r'^db/api/thread/list/$', 'API.Handlers.hThread.listThread'),
    url(r'^db/api/thread/listPosts/$', 'API.Handlers.hThread.listPostsThread'),
    url(r'^db/api/thread/open/$', 'API.Handlers.hThread.openThread'),
    url(r'^db/api/thread/remove/$', 'API.Handlers.hThread.removeThread'),
    url(r'^db/api/thread/restore/$', 'API.Handlers.hThread.restoreThread'),
    url(r'^db/api/thread/subscribe/$', 'API.Handlers.hThread.subscribeThread'),
    url(r'^db/api/thread/unsubscribe/$', 'API.Handlers.hThread.unsubscribeThread'),
    url(r'^db/api/thread/update/$', 'API.Handlers.hThread.updateThread'),
    url(r'^db/api/thread/vote/$', 'API.Handlers.hThread.voteThread'),
    url(r'^db/api/post/create/$', 'API.Handlers.hPost.createPost'),
    url(r'^db/api/post/details/
class brocade_openflow(object):
    """Auto generated class.
    """
    def __init__(self, **kwargs):
        self._callback = kwargs.pop('callback')
            
    def openflow_controller_controller_name(self, **kwargs):
        """Auto Generated Code
        """
        config = ET.Element("config")
        openflow_controller = ET.SubElement(config, "openflow-controller", xmlns="urn:brocade.com:mgmt:brocade-openflow")
        controller_name = ET.SubElement(openflow_controller, "controller-name")
        controller_name.text = kwargs.pop('controller_name')
        callback = kwargs.pop('callback', self._callback)
        return callback(config)
        
    def openflow_controller_connection_address_controller_address(self, **kwargs):
        """Auto Generated Code
        """
        config = ET.Element("config")
        openflow_controller = ET.SubElement(config, "openflow-controller", xmlns="urn:brocade.com:mgmt:brocade-openflow")
        controller_name_key = ET.SubElement(op

        controller_name_key.text = kwargs.pop('controller_name')
        connection_address = ET.SubElement(openflow_controller, "connection-address")
        controller_address = ET.SubElement(connection_address, "controller-address")
        controller_address.text = kwargs.pop('controller_address')
        callback = kwargs.pop('callback', self._callback)
        return callback(config)
        
    def openflow_controller_connection_address_connection_method(self, **kwargs):
        """Auto Generated Code
        """
        config = ET.Element("config")
        openflow_controller = ET.SubElement(config, "openflow-controller", xmlns="urn:brocade.com:mgmt:brocade-openflow")
        controller_name_key = ET.SubElement(openflow_controller, "controller-name")
        controller_name_key.text = kwargs.pop('controller_name')
        connection_address = ET.SubElement(openflow_controller, "connection-address")
        connection_method = ET.SubElement(connection_address, "connection-met

        connection_method.text = kwargs.pop('connection_method')
        callback = kwargs.pop('callback', self._callback)
        return callback(config)
        
    def openflow_controller_connection_address_connection_port(self, **kwargs):
        """Auto Generated Code
        """
        config = ET.Element("config")
        openflow_controller = ET.SubElement(config, "openflow-controller", xmlns="urn:brocade.com:mgmt:brocade-openflow")
        controller_name_key = ET.SubElement(openflow_controller, "controller-name")
        controller_name_key.text = kwargs.pop('controller_name')
        connection_address = ET.SubElement(openflow_controller, "connection-address")
        connection_port = ET.SubElement(connection_address, "connection-port")
        connection_port.text = kwargs.pop('connection_port')
        callback = kwargs.pop('callback', self._callback)
        return callback(config)
        
    def openflow_controller_connection_address_active_controller_vrf(self, **k
datatypes_repository_name = 'emboss_datatypes_0110'
datatypes_repository_description = "Galaxy applicable data formats used by Emboss tools."
datatypes_repository_long_description = "Galaxy applicable data formats used by Emboss tools.  This repository contains no tools."
emboss_repository_name = 'emboss_0110'
emboss_repository_description = 'Galaxy wrappers for Emboss version 5.0.0 tools'
emboss_repository_long_description = 'Galaxy wrappers for Emboss version 5.0.0 tools'
category_name = 'Test 0110 Invalid Repository Dependencies'
category_desc = 'Test 0110 Invalid Repository Dependencies'
class TestBasicRepositoryDependencies( ShedTwillTestCase ):
    '''Testing emboss 5 with repository dependencies.'''
    def test_0000_initiate_users( self ):
        """Create necessary user accounts and login as an admin user."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.tes

        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = self.test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
  
    def test_0005_create_category( self ):
        """Create a category for this test suite"""
        self.create_category( name=category_name, description=category_desc )
  
    def test_0010_create_emboss_datatypes_repository_and_upload_tarball( self ):
        '''Create and populate the emboss_datatypes repository.'''
        self.logout()
        self.login( email=common.test_user_1_email, username=common.

        category = self.test_db_util.get_category_by_name( category_name )
        repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                             description=datatypes_repository_description, 
                                             long_description=datatypes_repository_long_description, 
                                             owner=common.test_user_1_name,
                                             category_id=self.security.encode_id( category.id ), 
                                             strings_displayed=[] )
        self.upload_file( repository, 
                          filename='emboss/datatypes/datatypes_conf.xml',
                          filepath=None,
                          valid_tools_only=True,
                          uncompress_file=True,
                          remove_repo_files_not_in_tar=False, 
                          commit_message='Uploaded datatypes_conf.xml.',
                
log = logging.getLogger( __name__ )
category_name = 'Test 1430 Repair installed repository'
category_description = 'Test script 1430 for repairing an installed repository.'
filter_repository_name = 'filter_1430'
column_repository_name = 'column_1430'
filter_repository_description = "Galaxy's filter tool for test 1430"
column_repository_description = 'Add a value as a new column'
filter_repository_long_description = '%s: %s' % ( filter_repository_name, filter_repository_description )
column_repository_long_description = '%s: %s' % ( column_repository_name, column_repository_description )
'''
In the Tool Shed:
1) Create and populate the filter_1430 repository
2) Create and populate the column_1430 repository
3) Upload a repository_dependencies.xml file to the column_1430 repository that creates a repository dependency on the filter_1430 repository.
In Galaxy:
1) Install the column_1430 repository, making sure to check the checkbox to Handle repository dependencies so that the filter
   r

2) Uninstall the filter_1430 repository.
3) Repair the column_1430 repository.
4) Make sure the filter_1430 repository is reinstalled and the tool is loaded into the tool panel in the same section specified in step 1.
'''
class TestRepairRepository( ShedTwillTestCase ):
    '''Test repairing an installed repository.'''
    
    def test_0000_initiate_users_and_category( self ):
        """Create necessary user accounts and login as an admin user."""
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
        self.create_category( name=category_name, description=category_description )
        self.logout()
        self.login( email=common.test_user_2_email, username=commo

        test_user_2 = self.test_db_util.get_user( common.test_user_2_email )
        assert test_user_2 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_2_email
        test_user_2_private_role = self.test_db_util.get_private_role( test_user_2 )
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = self.test_db_util.get_private_role( test_user_1 )
        
    def test_0005_create_filter_repository( self ):
        '''Create and populate the filter_1430 repository.'''
        '''
        This is step 1 - Create and populate the filter_1430 repository.
        
        This repository will be depended on by the column_1430 repository.
        '''
        cate
"""
    Sahana Eden Stats Controller
"""
module = request.controller
resourcename = request.function
if not settings.has_module(module):
    raise HTTP(404, body="Module disabled: %s" % module)
def index():
    """ Module's Home Page """
    return s3db.cms_index(module, alt_function="index_alt")
def index_alt():
    """
        Module homepage for non-Admin users when no CMS content found
    """
    redirect(URL(f="demographic_data", args="summary"))
def parameter():
    """ REST Controller """
    return s3_rest_controller()
def data():
    """ REST Controller """
    return s3_rest_controller()
def source():
    """ REST Controller """
    return s3_rest_controller()
def demographic():
    """ REST Controller """
    return s3_rest_controller()
def demographic_data():
    """ REST Controller """
    return s3_rest_controller()
def demographic_aggregate():
    """ REST Controller """
    def clear_aggregates(r, **attr):
        if not s3_has_role(ADMIN):
            auth.permission.
log = logging.getLogger("worker.management.start_scenario")
class Command(BaseCommand):
    help = ("Example: bin/django lw_start_scenario "\
            "--scenario_id 50 "\
            "--workflowtemplate_id 1 "\
            "--log_level DEBUG")
    option_list = BaseCommand.option_list + (
            make_option('--log_level',
                        help='logging level 10=debug 50=critical',
                        default='DEBUG',
                        type='str'),
            make_option('--scenario_id',
                        help='scenarios',
                        type='int'),
            make_option('--workflowtemplate_id',
                        help='id of workflow template',
                        type='int'))
    def handle(self, *args, **options):
        """
        Opens connection to broker.
        Creates ActionWorkflow object.
        Creates logging handler to send loggings to broker.
        Sets logging handler to ActionWorkflow object.
        Performs w
last_update = time()
timeout = .75
def learnedAction(controller, prediction):
    controller.dispatch(prediction)
def trackUpAction(controller):
    controller.lock()
    controller.trackUp()
    print "Track Up - current track: %d" % controller.current_track
def trackDownAction(controller):
    controller.lock()
    controller.trackDown()
    print "Track Down - current track: %d" % controller.current_track
def tempoChangeAction(controller, bpm):
    print "Received tempo %f " % bpm 
    controller.setTempo(bpm)
def trackStartAction(controller):
    if controller.locked():
        return
    controller.lock()
    tracknum = controller.current_track
    print "Start Track"
    controller.midi_interface.play_track(tracknum)
    controller.stopped = False
def trackStopAction(controller):
    if controller.locked():
        return
    controller.lock()
    tracknum = controller.current_track
    print "Stop Track"
    controller.midi_interface.stop_track(tracknum)
    controller.stopped =
MetadataRequest = namedtuple("MetadataRequest",
    ["topics"])
MetadataResponse = namedtuple("MetadataResponse",
    ["brokers", "topics"])
ProduceRequest = namedtuple("ProduceRequest",
    ["topic", "partition", "messages"])
ProduceResponse = namedtuple("ProduceResponse",
    ["topic", "partition", "error", "offset"])
FetchRequest = namedtuple("FetchRequest",
    ["topic", "partition", "offset", "max_bytes"])
FetchResponse = namedtuple("FetchResponse",
    ["topic", "partition", "error", "highwaterMark", "messages"])
OffsetRequest = namedtuple("OffsetRequest",
    ["topic", "partition", "time", "max_offsets"])
OffsetResponse = namedtuple("OffsetResponse",
    ["topic", "partition", "error", "offsets"])
OffsetCommitRequest = namedtuple("OffsetCommitRequest",
    ["topic", "partition", "offset", "metadata"])
OffsetCommitResponse = namedtuple("OffsetCommitResponse",
    ["topic", "partition", "error"])
OffsetFetchRequest = namedtuple("OffsetFetchRequest",
    ["topic", "partition"])
Off

    ["topic", "partition", "offset", "metadata", "error"])
BrokerMetadata = namedtuple("BrokerMetadata",
    ["nodeId", "host", "port"])
TopicMetadata = namedtuple("TopicMetadata",
    ["topic", "error", "partitions"])
PartitionMetadata = namedtuple("PartitionMetadata",
    ["topic", "partition", "leader", "replicas", "isr", "error"])
OffsetAndMessage = namedtuple("OffsetAndMessage",
    ["offset", "message"])
Message = namedtuple("Message",
    ["magic", "attributes", "key", "value"])
TopicAndPartition = namedtuple("TopicAndPartition",
    ["topic", "partition"])
KafkaMessage = namedtuple("KafkaMessage",
    ["topic", "partition", "offset", "key", "value"])
class KafkaError(RuntimeError):
    pass
class BrokerResponseError(KafkaError):
    pass
class UnknownError(BrokerResponseError):
    errno = -1
    message = 'UNKNOWN'
class OffsetOutOfRangeError(BrokerResponseError):
    errno = 1
    message = 'OFFSET_OUT_OF_RANGE'
class InvalidMessageError(BrokerResponseError):
    errno = 2
 

class UnknownTopicOrPartitionError(BrokerResponseError):
    errno = 3
    message = 'UNKNOWN_TOPIC_OR_PARTITON'
class InvalidFetchRequestError(BrokerResponseError):
    errno = 4
    message = 'INVALID_FETCH_SIZE'
class LeaderNotAvailableError(BrokerResponseError):
    errno = 5
    message = 'LEADER_NOT_AVAILABLE'
class NotLeaderForPartitionError(BrokerResponseError):
    errno = 6
    message = 'NOT_LEADER_FOR_PARTITION'
class RequestTimedOutError(BrokerResponseError):
    errno = 7
    message = 'REQUEST_TIMED_OUT'
class BrokerNotAvailableError(BrokerResponseError):
    errno = 8
    message = 'BROKER_NOT_AVAILABLE'
class ReplicaNotAvailableError(BrokerResponseError):
    errno = 9
    message = 'REPLICA_NOT_AVAILABLE'
class MessageSizeTooLargeError(BrokerResponseError):
    errno = 10
    message = 'MESSAGE_SIZE_TOO_LARGE'
class StaleControllerEpochError(BrokerResponseError):
    errno = 11
    message = 'STALE_CONTROLLER_EPOCH'
class OffsetMetadataTooLargeError(BrokerResponseErr
    ActionWorkflow, ActionTaskPublisher, ActionHeartbeat)
log = logging.getLogger("flooding.management.start_scenario")
def start_workflow(scenario_id, workflowtemplate_id, log_level='INFO'):
    """
    Opens connection to broker.
    Creates ActionWorkflow object.
    Creates logging handler to send loggings to broker.
    Sets logging handler to ActionWorkflow object.
    Performs workflow.
    Closes connection.
    """
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        log.error("Invalid log level: %s" % log_level)
        numeric_level = 10
    broker = BrokerConnection()
    connection = broker.connect_to_broker()
    if connection is None:
        log.error("Could not connect to broker.")
        return
    action = ActionWorkflow(
        connection, scenario_id, workflowtemplate_id)
    logging.handlers.AMQPMessageHandler = AMQPMessageHandler
    broker_handler = logging.handlers.AMQPMessageHandler(action,
        

    action.set_broker_logging_handler(broker_handler)
    status = action.perform_workflow()
    if connection.is_open:
        connection.close()
    return status
def start_task(task_id, log_level='INFO'):
    """
    Publish a message to execute a separate task.
    """
    task = WorkflowTask.objects.get(pk=task_id)
    numeric_level = getattr(logging, log_level.upper(), None)
    if not isinstance(numeric_level, int):
        log.error("Invalid log level: %s" % log_level)
        numeric_level = 10
    broker = BrokerConnection()
    connection = broker.connect_to_broker()
    if connection is None:
        log.error("Could not connect to broker.")
        return
    action = ActionTaskPublisher(connection, task)
    logging.handlers.AMQPMessageHandler = AMQPMessageHandler
    broker_handler = logging.handlers.AMQPMessageHandler(action,
                                                         numeric_level)
    action.set_broker_logging_handler(broker_handler)
    success = actio
cmd_subfolder = os.path.realpath(os.path.abspath(os.path.join(os.path.split(inspect.getfile( inspect.currentframe() ))[0],"..")))
if cmd_subfolder not in sys.path:
    sys.path.insert(0, cmd_subfolder)
rc = 1
keepalive = 60
connect_packet = mosq_test.gen_connect("bridge-reconnect-test", keepalive=keepalive)
connack_packet = mosq_test.gen_connack(rc=0)
mid = 180
suback_packet = mosq_test.gen_suback(mid, 0)
publish_packet = mosq_test.gen_publish("bridge/reconnect", qos=0, payload="bridge-reconnect-message")
try:
    os.remove('mosquitto.db')
except OSError:
    pass
broker = subprocess.Popen(['../../src/mosquitto', '-p', '1888'], stderr=subprocess.PIPE)
time.sleep(0.5)
local_broker = subprocess.Popen(['../../src/mosquitto', '-c', '06-bridge-reconnect-local-out.conf'], stderr=subprocess.PIPE)
time.sleep(0.5)
local_broker.terminate()
local_broker.wait()
local_broker = subprocess.Popen(['../../src/mosquitto', '-c', '06-bridge-reconnect-local-out.conf'], stderr=subprocess.PIPE)
pub = None
tr
BOB = 'Bob'
MALORY = 'Malory'
class ControllerTest(TestCase):
    def setUp(self):
        self.initialize_controller(11, 11)
    def initialize_controller(self, x, y):
        self.controller = Controller(x, y)
        self.controller.register(BOB)
        self.controller.register(MALORY)
    def testIllegalMove(self):
        self.controller.move(Action.SOUTH)
        result = self.controller.move(Action.NORTH)
        self.assertEqual(ActionResults(MALORY, terminated=True), result)
    def testOutOfGameEast(self):
        self.controller.move(Action.EAST)
        self.controller.move(Action.EAST)
        self.controller.move(Action.EAST)
        self.controller.move(Action.EAST)
        self.controller.move(Action.EAST)
        result = self.controller.move(Action.EAST)
        self.assertEqual(ActionResults(BOB, terminated=True), result)
    def testOutOfGameWest(self):
        self.controller.move(Action.WEST)
        self.controller.move(Action.WEST)
        self.controller.move(

        self.controller.move(Action.WEST)
        self.controller.move(Action.WEST)
        self.controller.move(Action.NORTH_EAST)
        self.controller.debug = True
        self.controller.move(Action.WEST)
        result = self.controller.move(Action.WEST)
        self.assertEqual(ActionResults(MALORY, terminated=True), result)
    def testLostInCorner(self):
        self.controller.move(Action.NORTH_WEST)
        self.controller.move(Action.NORTH_WEST)
        self.controller.move(Action.NORTH_WEST)
        self.controller.move(Action.NORTH_WEST)
        result = self.controller.move(Action.NORTH_WEST)
        self.assertEqual(ActionResults(MALORY, terminated=True, winner=MALORY), result)
    def testZigZag(self):
        self.initialize_controller(11, 15)
        self.controller.move(Action.WEST)
        self.controller.move(Action.NORTH_EAST)
        self.controller.move(Action.WEST)
        self.controller.move(Action.NORTH_EAST)
        self.controller.move(Action.WEST)
    

        self.controller.move(Action.WEST)
        self.controller.move(Action.NORTH_EAST)
        self.controller.move(Action.WEST)
        self.controller.move(Action.NORTH_EAST)
        self.controller.move(Action.WEST)
        self.controller.move(Action.NORTH_EAST)
        self.controller.move(Action.SOUTH)
        self.controller.move(Action.SOUTH)
        self.controller.move(Action.SOUTH)
        self.controller.move(Action.SOUTH)
        self.controller.move(Action.SOUTH)
        self.controller.move(Action.SOUTH)
        result = self.controller.move(Action.SOUTH)
        self.assertEqual(ActionResults(MALORY, terminated=False), result)
    def testMaloryTheActivePlayerLose(self):
        self.controller.move(Action.NORTH)
        self.controller.move(Action.NORTH)
        self.controller.move(Action.NORTH)
        self.controller.move(Action.NORTH)
        self.controller.move(Action.NORTH)
        result = self.controller.move(Action.NORTH)
        self.assertEqual(ActionRe
def resetdb():
  local('rm -f rocket/default.db')
  local('python manage.py syncdb --noinput --migrate')
  local('python manage.py loaddata messages_demo.yaml')
  local('python manage.py rebuild_index --noinput')
def deploy():
    """fab [environment] deploy"""
    local('heroku maintenance:on')
    local('DJANGO_SETTINGS_MODULE=rocket.settings.staging python manage.py collectstatic --noinput')
    local('git push heroku HEAD:master')
    local('heroku run python manage.py syncdb --noinput')
    local('heroku run python manage.py migrate')
    local('heroku run python manage.py collectstatic --noinput')
    local('heroku maintenance:off')
    local('heroku ps')
    local('heroku open')
def deploy_staging():
  local('heroku maintenance:on --app rocket-listings-staging')
  local('DJANGO_SETTINGS_MODULE=rocket.settings.staging python manage.py collectstatic --noinput')
  local('git push --force staging HEAD:master')
  local('heroku run python manage.py syncdb --noinput --app rocket-listin
"""Routes configuration
The more specific and detailed routes should be defined first so they
may take precedent over the more generic routes. For more information
refer to the routes manual at http://routes.groovie.org/docs/
"""
def make_map(config):
    """Create, configure and return the routes Mapper"""
    map = Mapper(directory=config['pylons.paths']['controllers'],
                 always_scan=config['debug'])
    map.minimization = False
    map.connect('/error/{action}', controller='error')
    map.connect('/error/{action}/{id}', controller='error')
    map.resource('wmt', 'wmts')
    map.resource('publisher', 'publishers')
    map.resource('cmslayer', 'cmslayer')
    map.resource('zeitreihen', 'zeitreihen')
    map.resource('bodgrid', 'bodgrid')
    map.connect('/crossdomain.xml', controller='entry', action='crossdomain')
    map.connect('/clientaccesspolicy.xml', controller='entry', action='clientaccesspolicy')
    map.connect('/loader.js', controller='entry', action='loader

    map.connect('/swisssearch', controller='swisssearch', action='index')
    map.connect('/swisssearch/geocoding', controller='swisssearch', action='index')
    map.connect('/geocatsearch', controller='gcsearch', action='search')
    map.connect("/feature/search",controller="feature", action="search")
    map.connect('/owschecker/bykvp', controller='owschecker', action='bykvp')
    map.connect('/owschecker/form', controller='owschecker', action='form')
    map.connect("/feature/bbox",controller="feature", action="bbox")
    map.connect("/feature/geometry",controller="feature", action="geometry")
    map.connect("/feature/{path_info:.*}",controller="feature", action="index")
    map.connect("/wmts/{path_info:.*}",controller="wmts", action="manager")
    map.connect("/wmts5/{path_info:.*}",controller="wmts", action="manager")
    map.connect("/wmts6/{path_info:.*}",controller="wmts", action="manager")
    map.connect("/wmts7/{path_info:.*}",controller="wmts", action="manager")
    map.

    map.connect("/wmts9/{path_info:.*}",controller="wmts", action="manager")
    map.connect('/checker', controller='checker', action='index')
    map.connect('/sanity', controller='checker', action='sanity')
    map.connect('/qrcodegenerator', controller='qrcodegenerator', action='qrcodegenerator')
    map.connect('/shorten', controller='shortener', action='shorten')
    map.connect('/shorten.json', controller='shortener', action='shortenjson')
    map.connect('/shorten/{id}', controller='shortener', action='decode')
    map.connect('/ogcproxy', controller='ogcproxy', action='index')
    map.connect('/apiprintproxy', controller='apiprintproxy', action='index')
    map.connect('/height', controller="height", action='index')
    map.connect('/profile.csv', controller="profile", action='csv')
    map.connect('/profile.json', controller="profile", action='json')
    
    map.connect('/layers/{id}', controller="layers", action='index')
    map.connect('/layers', controller="layers", actio
class Repository(IRepository):
	__abstract__                = True
	repositoryDirectoryName     = None
	repositoryDirectoryLockName = "lock"
	repositoryDirectoryPath     = None
	repositoryDirectoryLock     = None
	def __init__(self):
		super(Repository, self).__init__()
		
		self.init()
	@reconstructor
	def init(self):
		self._repositoryLock = None
	def gc(self, databaseSession):
		self.getRepositoryDirectoryLock().lock()
		if databaseSession.query(self.repositoryTreeClass).with_parent(self).count() == 0:
			self.uninitialize()
			databaseSession.delete(self)
			databaseSession.commit()
		self.getRepositoryDirectoryLock().unlock()
	def getFullPath(self):
		return os.path.join(self.getRepositoryDirectoryPath(), self.directoryName)
	@property
	def redactedUrl(self):
		return re.sub(r"/[^/:@]*(:[^/:@]*)?@", u"/", self.url)
	@classmethod
	def create(cls, databaseSession, url):
		cls.getRepositoryDirectoryLock().lock()
		
		repository = cls.getByUrl(databaseSession, url)
		if repository: re

		
		repository = cls()
		repository.url = url
		repository.directoryName = cls.generateDirectoryName(databaseSession, repository)
		
		repository.initialize()
		
		databaseSession.add(repository)
		databaseSession.commit()
		cls.getRepositoryDirectoryLock().unlock()
		
		return repository
	@classmethod
	def setRepository(cls, databaseSession, repositoryUrl, repositoryTree):
		databaseSession.commit()
		
		cls.getRepositoryDirectoryLock().lock()
		repository = repositoryTree.repository
		
		if repositoryUrl is None:
			repositoryTree.repository = None
			databaseSession.delete(repositoryTree)
		else:
			repositoryTree.repository = cls.create(databaseSession, repositoryUrl)
			databaseSession.add(repositoryTree)
		
		databaseSession.commit()
		
		if repository is not None:
			repository.gc(databaseSession)
		
		cls.getRepositoryDirectoryLock().unlock()
	@classmethod
	def getByUrl(cls, databaseSession, url):
		repository = databaseSession.query(cls).filter(cls.url == url).first()
		retu

	@classmethod
	def getByDirectoryName(cls, databaseSession, directoryName):
		repository = databaseSession.query(cls).filter(cls.directoryName == directoryName).first()
		return repository
	@property
	def repositoryTreeClass(self):
		raise NotImplementedError()
	def initialize(self):
		raise NotImplementedError()
	def uninitialize(self):
		raise NotImplementedError()
	def directoryExists(self):
		return os.path.exists(self.getFullPath())
	@property
	def repositoryLock(self):
		if self._repositoryLock is None:
			lockPath = self.getFullPath() + ".lock"
			self._repositoryLock = knotcake.concurrency.FileLock(lockPath)
		
		return self._repositoryLock
	@classmethod
	def getRepositoryDirectoryPath(cls):
		if cls.repositoryDirectoryPath is None:
			cls.repositoryDirectoryPath = os.path.join(__file__, "../../data")
			cls.repositoryDirectoryPath = os.path.join(cls.repositoryDirectoryPath, cls.repositoryDirectoryName)
			cls.repositoryDirectoryPath = os.path.normpath(cls.repositoryDirectoryP
"""Manage repos referenced in the current Dusty specs.
By default, Dusty automatically manages the repos referenced
in your app and lib specs. This includes cloning the repo and
pulling updates from master to keep the Dusty-managed copy up-to-date.
Alternatively, you can override a repo to manage it yourself. This
is useful for actively developing apps and libs that depend on that
repo. To override a repo, use the `override` or `from` commands.
Usage:
  repos from <source_path>
  repos list
  repos manage (--all | <repo_name>)
  repos override <repo_name> <source_path>
  repos update
Commands:
  from        Override all repos from a given directory
  list        Show state of all repos referenced in specs
  manage      Tell Dusty to manage a repo or all repos, removing any overrides
  override    Override a repo with a local copy that you manage
  update      Pull latest master on Dusty-managed repos
Options:
  --all       When provided to manage, dusty will manage all currently overri
"""Standard management interface support
"""
class Tabs(Base):
    """Mix-in provides management folder tab support."""
    security = ClassSecurityInfo()
    security.declarePublic('manage_tabs')
    manage_tabs=DTMLFile('dtml/manage_tabs', globals())
    manage_options  =()
    security.declarePublic('filtered_manage_options')
    def filtered_manage_options(self, REQUEST=None):
        validate=getSecurityManager().validate
        result=[]
        try:
            options=tuple(self.manage_options)
        except TypeError:
            options=tuple(self.manage_options())
        for d in options:
            filter=d.get('filter', None)
            if filter is not None and not filter(self):
                continue
            path=d.get('path', None)
            if path is None:
                    path=d['action']
            o=self.restrictedTraverse(path, None)
            if o is None:
                continue
            result.append(d)
        return result
    manage_wo

    def manage_workspace(self, REQUEST):
        """Dispatch to first interface in manage_options
        """
        options=self.filtered_manage_options(REQUEST)
        try:
            m=options[0]['action']
            if m=='manage_workspace':
                    raise TypeError
        except (IndexError, KeyError):
            raise Unauthorized, (
                'You are not authorized to view this object.')
        if m.find('/'):
            raise Redirect, (
                "%s/%s" % (REQUEST['URL1'], m))
        return getattr(self, m)(self, REQUEST)
    def tabs_path_default(self, REQUEST,
                          unquote=urllib.unquote,
                          ):
        steps = REQUEST._steps[:-1]
        script = REQUEST['BASEPATH1']
        linkpat = '<a href="%s/manage_workspace">%s</a>'
        out = []
        url = linkpat % (escape(script, 1), '&nbsp;/')
        if not steps:
            return url
        last = steps.pop()
        for step in steps:
      

            out.append(linkpat % (escape(script, 1), escape(unquote(step))))
        script = '%s/%s' % (script, last)
        out.append('<a class="strong-link" href="%s/manage_workspace">%s</a>'%
                   (escape(script, 1), escape(unquote(last))))
        return '%s%s' % (url, '/'.join(out))
    def tabs_path_info(self, script, path,
                       quote=urllib.quote,
                       ):
        out=[]
        while path[:1]=='/':
            path = path[1:]
        while path[-1:]=='/':
            path = path[:-1]
        while script[:1]=='/':
            script = script[1:]
        while script[-1:]=='/':
            script = script[:-1]
        path=path.split('/')[:-1]
        if script:
            path = [script] + path
        if not path:
            return ''
        script=''
        last=path[-1]
        del path[-1]
        for p in path:
            script="%s/%s" % (script, quote(p))
            out.append('<a href="%s/manage_workspace">%s</a
"""
Fabric local configuration Vagrant template
"""
ROLEDEFS = {
    "couchdb": ["192.168.100.10"],
    "common":  ["192.168.100.20"],
    "worker":  ["192.168.100.30", "192.168.100.40", "192.168.100.50"]
COUCH_HOST = ROLEDEFS['couchdb'][0]
COUCH_VHOST = "couchdb"
COUCH_PORT = '80'
USER_AGENT = "Rdc-Crawler/0.0"
COUCH_USER = "admin"
COUCH_PASS = "pass"
CACHE_BACKEND = "memcached.MemcachedCache"
CACHE_HOST = ROLEDEFS['common'][0]
CACHE_PORT = "11211"
DB_ENGINE = "mysql"
DB_NAME = "couchdb"
DB_USER = "root"
DB_PASS = "pass"
DB_HOST = ROLEDEFS['common'][0]
DB_PORT = "3306"
SECRET_KEY = "999888777666"
BROKER_HOST = ROLEDEFS['couchdb'][0]
BROKER_PORT = "80"
BROKER_USER = "admin"
BROKER_PASS = "pass"
BROKER_VHOST = "couchdb/celery"
CODE_DIR = "/opt/rdc-web-crawler"
WHOOSH_PATH = "/opt/rdc-web-crawler/whoosh"
LOCK_ATTEMPTS = '5'
USER = "crawler"
PASSWORD = "pass"
VAGRANT_PATH = "/opt/workspace/chef-crawler"
ENVIRO = "vagrant"
KEY_FILENAME = "/home/rdc/.ssh/crawler_rsa.pub"
NEW_STYLE_TASKS = T
class Migration(SchemaMigration):
    def forwards(self, orm):
        db.create_table('broker_proxyrequest', (
            ('url', self.gf('django.db.models.fields.URLField')(max_length=200)),
            ('token', self.gf('django.db.models.fields.TextField')(unique=True, primary_key=True, db_index=True)),
        ))
        db.send_create_signal('broker', ['ProxyRequest'])
        db.create_table('broker_proxy', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('request', self.gf('django.db.models.fields.related.OneToOneField')(related_name='data', unique=True, to=orm['broker.ProxyRequest'])),
            ('manifest', self.gf('django.db.models.fields.TextField')()),
            ('mode_read', self.gf('django.db.models.fields.TextField')(null=True, blank=True)),
            ('mode_write', self.gf('django.db.models.fields.TextField')(null=True, blank=True)),
            ('mode_query', self.gf('django.db.models.fields.TextField')(null=True

        ))
        db.send_create_signal('broker', ['Proxy'])
        db.create_table('broker_metadata', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('proxy', self.gf('django.db.models.fields.related.ForeignKey')(related_name='metadata', to=orm['broker.Proxy'])),
            ('BB_north', self.gf('django.db.models.fields.FloatField')()),
            ('BB_east', self.gf('django.db.models.fields.FloatField')()),
            ('BB_south', self.gf('django.db.models.fields.FloatField')()),
            ('BB_west', self.gf('django.db.models.fields.FloatField')()),
            ('meta', self.gf('django.db.models.fields.TextField')()),
            ('name', self.gf('django.db.models.fields.TextField')()),
        ))
        db.send_create_signal('broker', ['Metadata'])
        db.create_table('broker_metadatarefreshtime', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('metadata', self.gf('djan

            ('crontab', self.gf('django.db.models.fields.TextField')(default='0 1 * * SAT')),
        ))
        db.send_create_signal('broker', ['MetadataRefreshTime'])
    def backwards(self, orm):
        db.delete_table('broker_proxyrequest')
        db.delete_table('broker_proxy')
        db.delete_table('broker_metadata')
        db.delete_table('broker_metadatarefreshtime')
    models = {
        'broker.metadata': {
            'BB_east': ('django.db.models.fields.FloatField', [], {}),
            'BB_north': ('django.db.models.fields.FloatField', [], {}),
            'BB_south': ('django.db.models.fields.FloatField', [], {}),
            'BB_west': ('django.db.models.fields.FloatField', [], {}),
            'Meta': {'object_name': 'Metadata'},
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'meta': ('django.db.models.fields.TextField', [], {}),
            'name': ('django.db.models.fields.TextField', [], {}),
            'pro
urlpatterns = patterns('',
    url(r'^$', 'home_app.views.home', name='home'),
    url(r'^about/', TemplateView.as_view(template_name = "index.html"), name='about'),
    url(r'^api/home/',
        'home_app.views.home_api',
        name='api.home'
        ),
    url(r'^api/faq/',
        'faq_about_app.views.faq_api',
        name='api.faq_and_about'
        ),
    url(r'^api/about/',
        'faq_about_app.views.about_api',
        name='api.about'
        ),
    url(r'^api/donors/',
        'donors_app.views.donors_api',
        name='api.donors'
        ),
    url(r'^api/progress/$',
        'progress_app.views.progress_api',
        name='api.progress'
        ),
    url(r'^api/progress/(?P<slug>[\w-]+)/$',
        'progress_app.views.progress_single_api',
        name='api.progress_single'
        ),
    url(r'^api/events/$',
        'gallery_app.views.event_api',
        name='api.events'
        ),
    url(r'^api/events/(?P<slug>[\w-]+)/$',
        'gallery_app.views.event_singl
if __name__ == "__main__":
    if sys.argv[1] and sys.argv[2] and sys.argv[3]:
        config.gh_id = sys.argv[1]
        config.gh_secret = sys.argv[2]
        config.app_secret = sys.argv[3]
        application = tornado.web.Application([
            (r"/api/login/?", api.login.Handler),
            (r"/api/user/?", api.user.UserHandler),
            (r"/api/profile/(?P<uid>[^\/]+)/?", api.user.ProfileHandler),
            (r"/api/like/(?P<target_id>[^\/]+)/?", api.user.LikeHandler),
            (r"/api/reject/(?P<target_id>[^\/]+)/?", api.user.RejectHandler),
            (r"/api/find/?", api.user.FindHandler),
            (r"/api/matches/?", api.user.MatchesHandler),
            (r"/api/token/?", api.user.TokenHandler),
            (r"/api/snippet/(?P<uid>[^\/]+)/?", api.user.SnippetHandler),
            (r"/api/notifications/?", api.notifications.NotificationsWebSocket),
            (r"/api/chat/?", api.chat.ChatWebSocket)
        ], cookie_secret=config.app_secret)
        applica
class EveApiManager():
    def __init__(self):
        pass
    @staticmethod
    def get_characters_from_api(api_id, api_key):
        chars = []
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            chars = account.characters()
        except evelink.api.APIError as error:
            print error
        return chars
    @staticmethod
    def get_corporation_ticker_from_id(corp_id):
        ticker = ""
        try:
            api = evelink.api.API()
            corp = evelink.corp.Corp(api)
            response = corp.corporation_sheet(corp_id)
            ticker = response[0]['ticker']
        except evelink.api.APIError as error:
            print error
        return ticker
    @staticmethod
    def get_alliance_information(alliance_id):
        results = {}
        try:
            api = evelink.api.API()
            eve = evelink.eve.EVE(api=api)
            alliance = eve.alliances()
       

        except evelink.api.APIError as error:
            print error
        return results
    @staticmethod
    def get_corporation_information(corp_id):
        results = {}
        try:
            api = evelink.api.API()
            corp = evelink.corp.Corp(api=api)
            corpinfo = corp.corporation_sheet(corp_id=int(corp_id))
            results = corpinfo[0]
        except evelink.api.APIError as error:
            print error
        return results
    @staticmethod
    def check_api_is_type_account(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return info[0]['type'] == "account"
        except evelink.api.APIError as error:
            print error
        return False
    @staticmethod
    def check_api_is_full(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account

            info = account.key_info()
            return info[0]['access_mask'] == 268435455
        except evelink.api.APIError as error:
            print error
        return False
    @staticmethod
    def get_api_info(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return info
        except evelink.api.APIError as error:
            print error
        return False
    @staticmethod
    def api_key_is_valid(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return True
        except evelink.api.APIError as error:
            return False
        return False
    @staticmethod
    def check_if_api_server_online():
        try:
            api = evelink.api.API()
            server = evelin
 	
class ControllerTest(unittest.TestCase):
	"""ControllerTest: Test Controller Singleton"""
	def assertNotNone(self):
		"""ControllerTest: Test instance not null"""
		controller = org.puremvc.python.core.Controller.getInstance()
   		self.assertNotEqual(None, controller) 
	def assertIController(self):
		"""ControllerTest: Test instance implements IController"""
		controller = org.puremvc.python.core.Controller.getInstance()
   		self.assertEqual(True, isinstance(controller, org.puremvc.python.interfaces.IController))
	def testRegisterAndExecuteCommand(self):
 		"""ControllerTest: Test registerCommand() and executeCommand(0)"""
		controller = org.puremvc.python.core.Controller.getInstance()
		controller.registerCommand('ControllerTest', utils.controller.ControllerTestCommand)
		
		vo = utils.controller.ControllerTestVO(12)
		note = org.puremvc.python.patterns.observer.Notification('ControllerTest', vo)
		controller.executeCommand(note)
		
		self.assertEqual(True, vo.result == 24 )
  		

	def testRegisterAndRemoveCommand(self): 
		"""ControllerTest: Test registerCommand() and removeCommand()"""
		controller = org.puremvc.python.core.Controller.getInstance()
		controller.registerCommand('ControllerRemoveTest', utils.controller.ControllerTestCommand)
		vo = utils.controller.ControllerTestVO(12)
		note = org.puremvc.python.patterns.observer.Notification('ControllerRemoveTest', vo)
		controller.executeCommand(note)
		self.assertEqual(True, vo.result == 24 )
		vo.result = 0
		controller.removeCommand('ControllerRemoveTest')
		controller.executeCommand(note)
		self.assertEqual(True, vo.result == 0)
 			
	def testHasCommand(self): 
		"""ControllerTest: Test hasCommand()"""
		
		controller = org.puremvc.python.core.Controller.getInstance()
		controller.registerCommand('hasCommandTest', utils.controller.ControllerTestCommand)
		self.assertEqual(True, controller.hasCommand('hasCommandTest'))
		controller.removeCommand('hasCommandTest')
		self.assertEqual(False, controller.hasCo
"""
    deployr
    created by hgschmidt on 29.12.12, 13:28 CET
    
    Copyright (c) 2012 - 2013 apitrary
"""
class ConfigLoader(object):
    """
        Deployr base object. Used for configurations.
    """
    def __init__(self, config):
        """
            Transfer configuration object into this class.
        """
        super(ConfigLoader, self).__init__()
        self.config = config
        self.read_config()
    def get(self, name):
        """
            Get a single variable from the config object
        """
        if name in self.config:
            return self.config[name]
        else:
            logging.error("Config variable:{} does not exist.".format(name))
            return ''
    def read_config(self):
        """
            Read out the config object
        """
        self.supervisord_host = self.get("SUPERVISORD_HOST")
        self.supervisord_web_port = self.get("SUPERVISORD_WEB_PORT")
        self.supervisord_xml_rpc_username = self.get("SUPERVISOR_X

        self.supervisord_xml_rpc_password = self.get("SUPERVISOR_XML_RPC_PASSWORD")
        self.supervisord_xml_rpc_server = self.get("SUPERVISOR_XML_RPC_SERVER_ADDRESS")
        self.rmq_broker_password = self.get("BROKER_PASSWORD")
        self.rmq_broker_username = self.get("BROKER_USER")
        self.rmq_broker_prefetch_count = self.get("BROKER_PREFETCH_COUNT")
        self.rmq_broker_host = self.get("BROKER_HOST")
        self.rmq_broker_port = self.get("BROKER_PORT")
        self.logging_level = self.get("LOGGING")
        self.environment = self.get("ENV")
        self.config_file = self.get("DEPLOYR_CONFIG_FILE")
        self.service_name = self.get("SERVICE")
        self.debug = True if self.get("DEBUG") == "1" or self.get("DEBUG") == True else False
        self.loadbalancer_api_base_name = self.get("LOADBALANCER_API_BASE_NAME")
        self.loadbalancer_host = self.get("LOADBALANCER_HOST")
        self.loadbalancer_riak_pb_port = self.get("LOADBALANCER_RIAK_PB_PORT")
    

    def show_all_settings(self):
        """
            Show all configured constants
        """
        logging.info('Starting service: deployr')
        logging.info('Environment: {}'.format(self.environment))
        logging.info('Logging: {}'.format(self.logging_level))
        logging.info('Config file: {}'.format(self.config_file))
        logging.info('Service: {}'.format(self.service_name))
        logging.info('Debug: {}'.format("ON" if self.debug == True else "OFF"))
        logging.info('Loadbalancer HOST: {}'.format(self.loadbalancer_host))
        logging.info('Loadbalancer API base name: {}'.format(self.loadbalancer_api_base_name))
        logging.info('Loadbalancer Riak Protobuf port: {}'.format(self.loadbalancer_riak_pb_port))
        logging.info('Loadbalancer Riak REST port: {}'.format(self.loadbalancer_riak_rest_port))
        logging.info('Supervisor host: {}'.format(self.supervisord_host))
        logging.info('Supervisor web port: {}'.format(self.supervisord_we
class BaseController(controller.CementBaseController):
    class Meta(object):
        label = 'base'
        description = 'ShowPy manages your shows.'
    def _setup(self, base_app):
        super(BaseController, self)._setup(base_app)
    @controller.expose(hide=True)
    def default(self):
        app.args.print_help()
    @controller.expose(aliases=['ls', 'l'], help='Print the show list.')
    def list(self):
        print self.shows
    @controller.expose(help='Show help.')
    def help(self):
        app.args.print_help()
class AddShowController(controller.CementBaseController):
    class Meta(object):
        aliases = ['add', 'a']
        label = 'add_show'
        description = 'Add a show to the collection'
        stacked_on = 'base'
        stacked_type = 'nested'
        arguments = [
            (['show'], dict(nargs='+')),
            ]
class ShowPy(foundation.CementApp):
    class Meta(object):
        label = 'showpy'
        base_controller = BaseController
app = Sho
YAHOO_APPID = '2Jbx0yvV34HWgMKIfe0PQppGYz9LvZj5m2_jBbSJzPddShB5Ue.3hSkNsD75zmmJDA--'
def main():
    application = webapp.WSGIApplication(
      [
        ('/', sbugs.FrontPage),
        
        ('/news', DisplayNews),
	('/news/edit/(.*)', EditNews),
	('/news/delete/(.*)', DeleteNews),
        ('/(.*).html', DisplayPost),
        
        ('/post', CreatePost),
        ('/page/manage', ManagePages),
        ('/page/delete/(.*)', DeletePost),
        ('/page/edit/(.*)', EditPost),
        ('/page/(.*)', DisplayPost),
        
        ('/user/alias', SetAlias),
        ('/user/login', Login),
        ('/user/logout', Logout),
        ('/user/register', Register),
        ('/user/manage', ManageUsers),
        ('/user/confirm', Confirm),
        ('/gallery', ManageGalleries),
        ('/gallery/(.*)/(.*)_thumb\.(png|jpg)', GetThumb),
        ('/gallery/(.*)/(.*)\.(png|jpg)', GetImage),
        ('/gallery/(.*)/images.xml', ImagesXML),
        ('/gallery/(.*)/view', ViewGallery),
        (
def tiff_save(temp_processed, target, save_offsetx, save_offsety, save_xsize, save_ysize, nodata, ot):
    save_tile = "gdal_translate -co compress=lzw %s -of GTiff %s -srcwin %s %s %s %s -a_nodata %s %s > /dev/null" %(temp_processed, target, save_offsetx, save_offsety, save_xsize, save_ysize, nodata, ot)
    os.system(save_tile)
def numpy_read(gtiff):
    temp_ds = gdal.Open(gtiff, GA_ReadOnly)
    temp_geotransform = temp_ds.GetGeoTransform()
    temp_band = temp_ds.GetRasterBand(1)
    temp_nodata = int(temp_band.GetNoDataValue() or 0)
    temp_data = numpy.array(temp_band.ReadAsArray())
    return temp_ds, temp_geotransform, temp_band, temp_nodata, temp_data
def numpy_save(processed_numpy, target, save_offsetx, save_offsety, save_xsize, save_ysize, geotransform_original, nodata, ot):
    cut_array = processed_numpy[save_offsety:save_offsety + save_ysize, save_offsetx:save_offsetx + save_xsize]
    geotransform = [
        geotransform_original[0] + geotransform_original[1] * save_o
def home(request):
    controller = CreateUserController(request)    
@login_required
def dashboard(request):
    controller = DashboardController(request)    
    return controller.dashboard()
@login_required
def create_game(request):
    controller = CreateGameController(request)  
    return controller.create_game()
@login_required
def view_games(request):
    controller = ViewGamesController(request)
    return controller.view_games()
@login_required
def help(request):
    controller = HelpController(request)    
    return controller.help()
@login_required
def explore(request):
    controller = ExploreController(request)    
    return controller.explore()
def game_rsvp(request, game=None):
    controller = GameRsvpController(request, Game.for_id(game))
    return controller.rsvp()
def game_rsvp_thanks(request, game=None):
    controller = GameRsvpThanksController(request, Game.for_id(game))
    return controller.render()
@login_required
def logout_user(request):
    
    logout(r

    return HttpResponseRedirect(reverse('pickup_finder.views.home'))
def mobile_home(request):
    controller = CreateUserController(request, mobile=True)
    return controller.create_user()
def mobile_view_games(request):
    controller = MobileViewGamesController(request)
    return controller.render()
def mobile_create_game(request):
    controller = CreateGameController(request, mobile=True)
    return controller.create_game()
def mobile_game_details(request, game=None):
    controller = MobileGameDetailsController(request, Game.for_id(game))
    return controller.render()
def mobile_game_rsvp(request, game=None):
    controller = GameRsvpController(request, Game.for_id(game), mobile=True)
    return controller.rsvp()
def mobile_game_rsvp_thanks(request, game=None):
    controller = GameRsvpThanksController(request, Game.for_id(game), mobile=True)
    return controller.render()
def ajax_seen_notifications(request):
    Notification.mark_as_seen(request.user)
    return HttpRespons
def sort_safe_rc ( n, indx, isgn, i_save, j_save, k_save, l_save, n_save ):
  if ( indx == 0 ):
      
    k_save = ( n // 2 )
    l_save = k_save
    n_save = n
  elif ( indx < 0 ):
    if ( indx == -2 ):
      if ( isgn < 0 ):
        i_save = i_save + 1
      j_save = l_save
      l_save = i_save
      indx = -1
      i = i_save
      j = j_save
      return indx, i, j, i_save, j_save, k_save, l_save, n_save
    if ( 0 < isgn ):
      indx = 2
      i = i_save
      j = j_save
      return indx, i, j, i_save, j_save, k_save, l_save, n_save
    if ( k_save <= 1 ):
      if ( n_save == 1 ):
        i_save = 0
        j_save = 0
        indx = 0
      else:
        i_save = n_save
        n_save = n_save - 1
        j_save = 1
        indx = 1
      i = i_save
      j = j_save
      return indx, i, j, i_save, j_save, k_save, l_save, n_save
    k_save = k_save - 1
    l_save = k_save
  elif ( indx == 1 ):
    l_save = k_save
  while ( True ):
    i_save = 2 * l_save
    if ( i_save == n

      j_save = l_save
      l_save = i_save
      indx = -1
      i = i_save
      j = j_save
      return indx, i, j, i_save, j_save, k_save, l_save, n_save
    elif ( i_save <= n_save ):
      j_save = i_save + 1
      indx = -2
      i = i_save
      j = j_save
      return indx, i, j, i_save, j_save, k_save, l_save, n_save
    if ( k_save <= 1 ):
      break
    k_save = k_save - 1
    l_save = k_save
  if ( n_save == 1 ):
    i_save = 0
    j_save = 0
    indx = 0
    i = i_save
    j = j_save
  else:
    i_save = n_save
    n_save = n_save - 1
    j_save = 1
    indx = 1
    i = i_save
    j = j_save
  return indx, i, j, i_save, j_save, k_save, l_save, n_save
def sort_safe_rc_i4vec_test ( ):
  n = 20
  print ''
  print 'SORT_SAFE_RC_I4VEC_TEST'
  print '  SORT_SAFE_RC sorts objects externally.'
  print '  This function does not use persistent memory.'
  i4_lo = 1
  i4_hi = n
  seed = 123456789
  a, seed = i4vec_uniform_ab ( n, i4_lo, i4_hi, seed )
  i4vec_print ( n, a, '  Unsort
def process():
	cursor = connection.cursor()
	cursor.execute("DELETE FROM landing_question")
	cursor.execute("DELETE FROM landing_answer")
	cursor.close()
	q = Question(code=1, question="¿Utiliza medios digitales para consultar la información de viajes?", qtype=0)
	a1 = Answer(question=q, body="Si",code=1)
	a2 = Answer(question=q, body="No",code=2)
	q.save()
	a1.save()
	a2.save()
	q = Question(code=2, question="¿Le parece apropiada la estandarización de precios en el trasporte?", qtype=0)
	a1 = Answer(question=q, body="Si", code=1)
	a2 = Answer(question=q, body="No", code=2)
	q.save()
	a1.save()
	a2.save()
	q = Question(code=3, question="¿Qué tipo de servicio de transporte presta?", qtype=1)
	a1 = Answer(question=q, body="Transporte terrestre de carga", code=1)
	a2 = Answer(question=q, body="Transporte de valores", code=2)
	a3 = Answer(question=q, body="Transporte urbano de mercancías", code=3)
	a4 = Answer(question=q, body="Otro", code=4)
	q.save()
	a1.save()
	a2.save()
	a3.save()
	a4

	q = Question(code=4, question="¿Cómo consigue sus clientes?", qtype=1)
	a1 = Answer(question=q, body="Publicidad", code=1)
	a2 = Answer(question=q, body="Página web", code=2)
	a3 = Answer(question=q, body="Vendedores", code=3)
	a4 = Answer(question=q, body="Otro", code=4)
	q.save()
	a1.save()
	a2.save()
	a3.save()
	a4.save()
	q = Question(code=5, question="¿Tiene suficientes clientes?", qtype=0)
	a1 = Answer(question=q, body="Si", code=1)
	a2 = Answer(question=q, body="No", code=2)
	q.save()
	a1.save()
	a2.save()
	q = Question(code=6, question="¿Cómo fija el precio de un servicio de transporte?", qtype=0)
	a1 = Answer(question=q, body="Negociación con el cliente", code=1)
	a2 = Answer(question=q, body="Tabla de precios según peso", code=2)
	a3 = Answer(question=q, body="Tabla de precios según ocupación", code=3)
	q.save()
	a1.save()
	a2.save()
	a3.save()
	q = Question(code=7, question="¿Le llama la atención utilizar una plataforma virtual para promocionar sus servicios?", qtype=0)
	a
class TestRiemannBroker(unittest.TestCase):
    def setUp(self):
        self.basic_modconf = Module(
            {
                'module_name': 'riemannBroker',
                'module_type': 'riemannBroker',
            }
        )
        self.broker = RiemannBroker(self.basic_modconf)
        self.broker.use_udp = True
        self.broker.init()
    def test_get_instance(self):
        result = get_instance(self.basic_modconf)
        self.assertTrue(type(result) is RiemannBroker)
    def test_init(self):
        modconf = Module(
            {
                'module_name': 'influxdbBroker',
                'module_type': 'influxdbBroker',
                'host': 'testhost',
                'port': '1111',
                'tick_limit': '3333',
                'use_udp': '1'
            }
        )
        broker = RiemannBroker(modconf)
        self.assertEqual(broker.host, 'testhost')
        self.assertEqual(broker.port, 1111)
        self.assertEqual(broker.tick_limit, 3333)


    def test_init_defaults(self):
        broker = RiemannBroker(self.basic_modconf)
        self.assertEqual(broker.host, 'localhost')
        self.assertEqual(broker.port, 5555)
        self.assertEqual(broker.tick_limit, 300)
        self.assertEqual(broker.use_udp, False)
    def test_transport_modes(self):
        broker = RiemannBroker(self.basic_modconf)
        broker.use_udp = True
        broker.init()
        self.assertTrue(
            type(broker.client.transport) is riemann_client.transport.UDPTransport
        )
    def test_get_check_result_perfdata_events(self):
        perf_data = 'ramused=1009MB;;;0;1982 memused=1550GB;2973;3964;0;5810'
        result = self.broker.get_check_result_perfdata_events(perf_data, 1234567890, 'testhost', 'testservice')
        self.assertEqual(len(result), 2)
        self.assertEqual(result[0].time, 1234567890)
        self.assertEqual(result[0].service, 'testservice')
        self.assertEqual(result[0].host, 'testhost')
        self.ass

        self.assertEqual(result[0].metric_f, 1009)
        self.assertEqual(len(result[0].attributes), 3)
        self.assertEqual(result[0].attributes[0].key, "max")
        self.assertEqual(result[0].attributes[0].value, "1982")
        self.assertEqual(result[0].attributes[1].key, "unit")
        self.assertEqual(result[0].attributes[1].value, "MB")
        self.assertEqual(result[0].attributes[2].key, "min")
        self.assertEqual(result[0].attributes[2].value, "0")
        self.assertEqual(result[1].description, 'memused')
    def test_get_state_update_points(self):
        data = {
            'last_chk': 1403618279,
            'state': 'WARNING',
            'last_state': 'CRITICAL',
            'state_type': 'SOFT',
            'last_state_type': 'SOFT',
            'output': 'BOB IS NOT HAPPY',
            'host_name': 'testhost',
            'service_description': 'testservice'
        }
        result = self.broker.get_state_update_points(data)
        event = result[0]

'''
Created on 2013-1-29
@author: lcy
'''
urlpatterns = patterns('corporation.views',
    url(r'^my_corporations_news/$','my_corporations_news'),
    url(r'^my_corporations_reply/$','my_corporations_reply'),
    url(r'^my_corporations_creat/$','my_corporations_creat'),
    url(r'^creat_corporation/$', 'creat_corporation'),
    url(r'^(\d+)/$', 'redirect_to_topics'),
    url(r'^(\d+)/topics/$','visit_corporation_topics'),
    url(r'^(\d+)/structure/$','visit_corporation_structure'),
    url(r'^(\d+)/activity/$','visit_corporation_activity'),
    url(r'^(\d+)/activity/(\d+)/$','showactivity'),
    url(r'^(\d+)/watch/$','watch_corporation'),
    url(r'^(\d+)/cancle_watch/$','cancle_watch_corporation'),
    url(r'^(\d+)/topic/(\d+)/$', 'showtopic'),
    url(r'^(\d+)/topic_inactive/$','topic_inactive'),
    url(r'^(\d+)/ask/$','ask_for_admin'),
    url(r'^(\d+)/manage_edit/$','corporation_manage_edit'),
    url(r'^(\d+)/manage_members/$','corporation_manage_members'),
    url(r'^(\d+)/manag
class MongoDBIO:
    def __init__(self, host, port, name, password, database, collection):
        self.host = host
        self.port = port
        self.name = name
        self.password = password
        self.database = database
        self.collection = collection
    def Connection(self):
        connection = pymongo.Connection(host=self.host, port=self.port)
        db = connection[self.database]
        if self.name or self.password:
        posts = db[self.collection]
        return posts
def ResultSave(save_host, save_port, save_name, save_password, save_database, save_collection, save_content):
    posts = MongoDBIO(save_host, save_port, save_name, save_password, save_database, save_collection).Connection()
    posts.save(save_content)
def num2name(category_num):
    Category_Map = {
        "1":u"外汇",
        "2":u"股市",
        "3":u"商品",
        "4":u"债市",
        "5":u"央行",
        "9":u"中国",
        "10":u"美国",
        "11":u"欧元区",
        "12":u"日本",
        "13":u"英国",


        "15":u"加拿大",
        "16":u"瑞士",
        "17":u"其他地区"
    }
    if Category_Map.has_key(category_num):
        return Category_Map[category_num]
    else:
        return ""
def Spider(url, data):
    return content
def ContentSave(item):
    save_host = "localhost"
    save_port = 27017
    save_name = ""
    save_password = ""
    save_database = "textclassify"
    save_collection = "WallstreetcnSave"
    source = "wallstreetcn"
    createdtime = datetime.datetime.now()
    type = item[0]
    content = content.encode("utf-8")
    categorySet = item[2]
    category_num = categorySet.split(",")
    category_name = map(num2name, category_num)
    districtset = set(category_name)&{u"中国", u"美国", u"欧元区", u"日本", u"英国", u"澳洲", u"加拿大", u"瑞士", u"其他地区"}
    district = ",".join(districtset)
    propertyset = set(category_name)&{u"外汇", u"股市", u"商品", u"债市"}
    property = ",".join(propertyset)
    centralbankset = set(category_name)&{u"央行"}
    centralbank = ",".join(centralbankset)
    sa

        "source":source,
        "createdtime":createdtime,
        "content":content,
        "type":type,
        "district":district,
        "property":property,
        "centralbank":centralbank
    }
    ResultSave(save_host, save_port, save_name, save_password, save_database, save_collection, save_content)
def func(page):
    url = "http://api.wallstreetcn.com/v2/livenews"
    data = {
        "page":page
    }
    content = Spider(url, data)
    if len(items) == 0:
        print "The End Page:", page
        full_url = url+'?'+data
        print full_url
    else:
        print "The Page:", page, "Downloading..."
        for item in items:
            ContentSave(item)
if __name__ == '__main__':
    start = datetime.datetime.now()
    start_page = 1
    end_page = 3300
    pages = [i for i in range(start_page, end_page)]
    p = mp.Pool()
    p.map_async(func, pages)
    p.close()
    p.join()
    page = end_page
    while True:
        url = "http://api.wallstreetcn.com/v2/li
admin.autodiscover()
log = logging.getLogger(__name__)
urlpatterns = patterns('',
    url(r'^$', home),
    url(r'^players/$', players),
    url(r'^teams/$', teams),
    url(r'^years/$', years),
    url(r'^players/(\d*)/$', player),
    url(r'^teams/(\d*)/$', team),
    url(r'^teams/([A-Za-z]{3})/$', team_abbr),
    url(r'^years/(\d{4})/$', year),
    url(r'^admin/', include(admin.site.urls)),
    url(r'^client/$', client),
    url(r'^sql/$', sql),
    url(r'^api/players/(\d*)/years/(\d*)$', api.player_year),
    url(r'^api/players/(\d*)/years$', api.player_years),
    url(r'^api/players/(\d*)/$', api.player),
    url(r'^api/players/$', api.players),
    url(r'^api/teams/(\d*)/years/(\d*)$', api.team_year),
    url(r'^api/teams/(\d*)/years$', api.team_years),
    url(r'^api/teams/(\d*)/$', api.team),
    url(r'^api/teams/$', api.teams),
    url(r'^api/years/(\d*)/$', api.year),
    url(r'^api/years/$', api.years),
    url(r'^api/search/([ a-zA-Z0-9\%]+)/$', api.search),
    
    url(r'
deploy_contracts = [
    "BuildByteArrayFactory",
def test_creating_request_for_execution(deploy_client, deploy_broker_contract,
                                        deployed_contracts, get_log_data,
                                        deploy_coinbase, StatusEnum, denoms):
    broker = deploy_broker_contract(deployed_contracts.BuildByteArrayFactory._meta.address)
    request_txn_hash = broker.requestExecution("abcdefg", value=10 * denoms.ether)
    request_txn_receipt = deploy_client.wait_for_transaction(request_txn_hash)
    event_data = get_log_data(broker.Created, request_txn_hash)
    _id = event_data['id']
    req_data = broker.getRequest(_id)
    assert req_data[0] == sha3.sha3_256("abcdefg").digest()
    assert req_data[1] == "\x00" * 32
    assert req_data[2] == deploy_coinbase
    assert req_data[3] == "0x0000000000000000000000000000000000000000"
    assert req_data[4] == int(request_txn_receipt['blockNumber'], 16)
    assert req_data[5] == StatusEnum.Pending
    assert
class TeleopController:
    def __init__(self, sp, hid_sp, control_stick=None, drive_controller=None, record_controller=None, playback_controller=None):
        self.sp = sp
        self.hid_sp = hid_sp
        if control_stick and drive_controller and record_controller and playback_controller:
            self.control_stick = control_stick
            self.drive_controller = drive_controller
            self.record_controller = self.record_controller
            self.playback_controller = self.playback_controller
            self.playback = False
            self.control_stick.add_listener(self._joylistener)
    def poll(self):
        self.sp.poll()
        self.hid_sp.poll()
    def _joylistener(self, sensor, state_id, datum):
        if state_id == "button2":
            if datum:
                os.execv(sys.executable, [sys.executable, 'robot.py', 'sim'])
        if state_id == "button9":
            if datum:
                self.drive_macro.engage()
        if state_id == "butt
                                consumer_from_config)
mod = 'pikachewie.helpers'
config = load(open(resource_filename(__name__, 'rabbitmq.yaml')))
class DescribeConsumerFromConfig(unittest.TestCase):
    def setUp(self):
        self.consumer = consumer_from_config(
            config['rabbitmq']['consumers']['message_logger'])
    def should_return_consumer(self):
        self.assertIsInstance(self.consumer, LoggingConsumer)
    def should_pass_arguments_to_init(self):
        self.assertEqual(self.consumer.level, 'debug')
class DescribeBrokerFromConfig(unittest.TestCase):
    connect_options = {
        'virtual_host': '/integration',
        'heartbeat_interval': 60,
    }
    def setUp(self):
        self.broker_config = config['rabbitmq']['brokers']['default']
        self.broker = broker_from_config(self.broker_config)
    def should_return_broker(self):
        self.assertIsInstance(self.broker, Broker)
    def should_set_nodes(self):
        self.assertEqual(dict(self.broker._n

    def should_set_connect_options(self):
        self.assertEqual(self.broker._connect_options, self.connect_options)
class DescribeConsumerAgentFromConfig(_BaseTestCase):
    __contexts__ = (
        ('ConsumerAgent', patch(mod + '.ConsumerAgent',
                                return_value=sentinel.agent)),
        ('consumer_from_config', patch(mod + '.consumer_from_config',
                                       return_value=sentinel.consumer)),
        ('broker_from_config', patch(mod + '.broker_from_config',
                                     return_value=sentinel.broker)),
    )
    def configure(self):
        self.name = 'message_logger'
        self.broker_config = config['rabbitmq']['brokers']['default']
        self.bindings = config['rabbitmq']['consumers'][self.name]['bindings']
    def execute(self):
        self.agent = consumer_agent_from_config(config, 'message_logger')
    def should_create_consumer(self):
        self.ctx.consumer_from_config.assert_called_once
def load_data(apps, schema_editor):
    Language = apps.get_model('hicks_language', 'Language')
    Language(code='ar-AE', display_name='Arabic (U.A.E.)').save()
    Language(code='az-AZ', display_name='Azeri (Latin) (Azerbaijan)').save()
    Language(code='bg-BG', display_name='Bulgarian (Bulgaria)').save()
    Language(code='ca-ES', display_name='Catalan (Spain)').save()
    Language(code='cs-CZ', display_name='Czech (Czech Republic)').save()
    Language(code='da-DK', display_name='Danish (Denmark)').save()
    Language(code='de-AT', display_name='German (Austria)').save()
    Language(code='de-CH', display_name='German (Switzerland)').save()
    Language(code='de-DE', display_name='German (Germany)').save()
    Language(code='el-GR', display_name='Greek (Greece)').save()
    Language(code='en-US', display_name='English (United States)').save()
    Language(code='es-ES', display_name='Spanish (Spain)').save()
    Language(code='es-MX', display_name='Spanish (Mexico)').save()
    Lan

    Language(code='fi-FI', display_name='Finnish (Finland)').save()
    Language(code='fr-BE', display_name='French (Belgium)').save()
    Language(code='fr-CH', display_name='French (Switzerland)').save()
    Language(code='fr-FR', display_name='French (France)').save()
    Language(code='hr-HR', display_name='Croatian (Croatia)').save()
    Language(code='hu-HU', display_name='Hungarian (Hungary)').save()
    Language(code='id-ID', display_name='Indonesian (Indonesia)').save()
    Language(code='it-CH', display_name='Italian (Switzerland)').save()
    Language(code='it-IT', display_name='Italian (Italy)').save()
    Language(code='ja-JP', display_name='Japanese (Japan)').save()
    Language(code='ko-KR', display_name='Korean (Korea)').save()
    Language(code='lt-LT', display_name='Lithuanian (Lithuania)').save()
    Language(code='lv-LV', display_name='Latvian (Latvia)').save()
    Language(code='ms-MY', display_name='Malay (Malaysia)').save()
    Language(code='nb-NO', display_nam

    Language(code='nl-BE', display_name='Dutch (Belgium)').save()
    Language(code='nl-NL', display_name='Dutch (Netherlands)').save()
    Language(code='pl-PL', display_name='Polish (Poland)').save()
    Language(code='pt-BR', display_name='Portuguese (Brazil)').save()
    Language(code='pt-PT', display_name='Portuguese (Portugal)').save()
    Language(code='ro-RO', display_name='Romanian (Romania)').save()
    Language(code='ru-RU', display_name='Russian (Russia)').save()
    Language(code='sk-SK', display_name='Slovak (Slovakia)').save()
    Language(code='sv-SE', display_name='Swedish (Sweden)').save()
    Language(code='th-TH', display_name='Thai (Thailand)').save()
    Language(code='tl-PH', display_name='Tagalog (Philippines)').save()
    Language(code='tr-TR', display_name='Turkish (Turkey)').save()
    Language(code='uk-UA', display_name='Ukrainian (Ukraine)').save()
    Language(code='vi-VN', display_name='Vietnamese (Viet Nam)').save()
    Language(code='zh-CN', display_na
LOG = logging.getLogger(__name__)
config = RoboticeSettings('reasoner')
BROKER_URL = config.broker
if "amqp" in config.broker:
    CELERY_RESULT_BACKEND = "amqp"
    default_exchange = Exchange('default')
    monitor_exchange = Exchange('monitor', type='fanout')
    reactor_exchange = Exchange('reactor', type='fanout')
    planner_exchange = Exchange('planner', type='fanout')
    control_exchange = Exchange('control', type='fanout')
    CELERY_QUEUES = (
        Queue('default', default_exchange, routing_key='default'),
    )
elif "redis" in config.broker:
    CARROT_BACKEND = "redis"
    CELERY_RESULT_BACKEND = BROKER_URL
    CELERY_QUEUES = {
        "default": {"default": "default"},
    }
CELERY_IMPORTS = (
    "reasoner.tasks", "monitor.tasks", "reactor.tasks", "planner.tasks")
CELERY_ROUTES = {
    'monitor.get_real_data': {
        'queue': 'monitor',
    },
    'planner.get_model_data': {
        'queue': 'planner',
    },
    'reasoner.compare_data': {
        'queue': 'reason
def trackUpAction(controller):
    controller.trackUp()
    print "Track Up - current track: %d" % controller.current_track
def trackDownAction(controller):
    controller.trackDown()
    print "Track Down - current track: %d" % controller.current_track
def tempoChangeAction(controller, bpm):
    print "Received tempo %f " % bpm 
    controller.setMidi(bpm)
def trackStartAction(controller):
    tracknum = controller.current_track
    print "Start Track"
    controller.midi_interface.play_track(tracknum)
    controller.stopped = False
def trackStopAction(controller):
    tracknum = controller.current_track
    print "Stop Track"
    controller.midi_interface.stop_track(tracknum)
    controller.stopped = True
def lowerVolumeAction(controller, vol=0.75):
    tracknum = controller.current_track
    volume = controller.current_vol - vol
    print "Lower Volume: %d" % volume
    controller.midi_interface.vol_track(tracknum, volume)
    controller.current_vol = volume
def raiseVolumeAction(co
'''
Created on April 05, 2013
@author: AxelVoitier
@license: GNU LGPL v3
Python module allowing to create a ALBroker as if it was a contextmanager (use with the 'with' statement).
It will also try to resolve automatically all IPs and ports of NaoQis we could connect to.
'''
def getLocalIp(destAddr):
    '''
    Return the IP of the *net interface capable of reaching destAddr.
    '''
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    s.connect((destAddr, 0))
    ip = s.getsockname()[0]
    s.close()
    return ip
    
class Broker(ALBroker):
    '''
    Create a broker with the given name.
    Automatically find out NAO IP. Set the broker to listen only on the IP that is on the same network than NAO.
    You can specify brokerIp to listen to localhost only (127.0.0.1) or to everybody (0.0.0.0).
    
    When you are finished with your broker, call the shutdown() method on it.
    '''
    def __init__(self, brokerName, brokerIp=None, brokerPort=0, naoIp=None, naoPort=None):
  

        else:
            naoIp = str(naoIp)
        if naoPort is None:
            allNaos = avahi.findAllNAOs()
                for aNao in allNaos:
                    if naoIp in aNao.values():
                        naoPort = aNao['naoqi_port']
                        break
                for aNao in allNaos:
                        naoIp = aNao['ip_address']
                        naoPort = aNao['naoqi_port']
                        break
                        naoIp = allNaos[0]['ip_address']
                        naoPort = allNaos[0]['naoqi_port']
                        naoIp = 'nao.local'
                        naoPort = 9559
        else:
            naoPort = int(naoPort)
                    
        if brokerIp is None:
            brokerIp = getLocalIp(naoIp)
      
        ALBroker.__init__(self, brokerName, brokerIp, brokerPort, naoIp, naoPort)
    
@contextmanager
def create(brokerName, brokerIp=None, brokerPort=0, naoIp=None, naoPort=None):
    '''
    Create
datatypes_repository_name = 'blast_datatypes_0120'
datatypes_repository_description = 'Galaxy applicable datatypes for BLAST'
datatypes_repository_long_description = 'Galaxy datatypes for the BLAST top hit descriptons tool'
tool_repository_name = 'blastxml_to_top_descr_0120'
tool_repository_description = 'BLAST top hit descriptions'
tool_repository_long_description = 'Make a table from BLAST XML'
'''
Tool shed side:
1) Create and populate blast_datatypes_0120.
1a) Check for appropriate strings.
2) Create and populate blastxml_to_top_descr_0120.
2a) Check for appropriate strings.
3) Upload repository_dependencies.xml to blastxml_to_top_descr_0120 that defines a relationship to blast_datatypes_0120.
3a) Check for appropriate strings.
'''
base_datatypes_count = 0
repository_datatypes_count = 0
class TestRepositoryMultipleOwners( ShedTwillTestCase ):
    def test_0000_initiate_users( self ):
        """Create necessary user accounts and login as an admin user."""
        """
        Create

        Previously created accounts will not be re-created.
        """
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.test_user_2_email, username=common.test_user_2_name )
        test_user_2 = test_db_util.get_user( common.test_user_1_email )
        assert test_user_2 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_2_email
        test_user_2_private_role = test_db_util.get_private_role( test_user_2 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = test_db_util.get_user( common.adm

        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = test_db_util.get_private_role( admin_user )
    def test_0005_create_datatypes_repository( self ):
        """Create and populate the blast_datatypes_0120 repository"""
        """
        We are at step 1.
        Create and populate blast_datatypes.
        """
        category = self.create_category( name='Test 0120', description='Description of test 0120' )
        self.logout()
        self.login( email=common.test_user_2_email, username=common.test_user_2_name )
        strings_displayed = [ 'Repository %s' % "'%s'" % datatypes_repository_name, 
                              'Repository %s has been created' % "'%s'" % datatypes_repository_name ]
        repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                                    description=datatypes_repository_description, 
   
'''
Created on Apr 23, 2013
@author: rtw
'''
class Test(unittest.TestCase):
    def setUp(self):
        manifest = '%s/data/manifest.csv' % os.path.dirname(__file__)        
        InstrumentDb.Instance().load(manifest)
        
    def tearDown(self):
        pass
    
    def on_bars_1(self,bars):
        if not self._placed_markorder:
            o = self._broker.createMarketOrder(Order.Action.BUY, 'AC', 100, False)
            self._broker.placeOrder(o)
            self._placed_markorder = True
        else:
            self.assertEqual(self._broker.getPositions()['AC'], 100) 
            
    def on_order_update_1(self, broker, order):
        self.assertEqual(order.getExecutionInfo().getPrice(),2.215)
        
    def testMarketOrder(self):
        self._placed_markorder = False
        mf = MultiFeed()
        mf.register_feed(Feed(InstrumentDb.Instance().get('AC')))
        self._broker = BacktestingFuturesBroker(1000000, mf)
        mf.subscribe(self.on_bars_1)
        self.

        mf.start()
        self.assertEqual(self._broker.getCash(), 1000015.0)
        self.assertEqual(self._broker.calc_margin(), 160000.0)
    
    def on_bars_2(self,bars):
        if not self._placed_markorder:
            o = self._broker.createMarketOrder(Order.Action.BUY, 'CT', 500, False)
            self._broker.placeOrder(o)
            self._placed_markorder = True
        else:
            self.assertEqual(self._broker.getPositions()['CT'], 500) 
            
    def on_order_update_2(self, broker, order):
        self.assertEqual(order.getExecutionInfo().getPrice(),92.43)
        
    def testMarketOrderMarginCall(self):
        self._placed_markorder = False
        mf = MultiFeed()
        mf.register_feed(Feed(InstrumentDb.Instance().get('CT')))
        self._broker = BacktestingFuturesBroker(1000000, mf)
        mf.subscribe(self.on_bars_2)
        self._broker.getOrderUpdatedEvent().subscribe(self.on_order_update_2)
        with self.assertRaisesRegexp(Exception, "M

            mf.start()
        self.assertAlmostEqual(self._broker.getCash(), 214000.0, places=2)
        self.assertEqual(self._broker.calc_margin(), 800000.0)
    
    def on_bars_3(self,bars):
        if not self._placed_markorder:
            o = self._broker.createMarketOrder(Order.Action.SELL_SHORT, 'CT', 500, False)
            self._broker.placeOrder(o)
            self._placed_markorder = True
        else:
            self.assertEqual(self._broker.getPositions()['CT'], -500) 
            
    def on_order_update_3(self, broker, order):
        self.assertEqual(order.getExecutionInfo().getPrice(),92.43)
        
    def testShortEntry(self):
        self._placed_markorder = False
        mf = MultiFeed()
        mf.register_feed(Feed(InstrumentDb.Instance().get('CT')))
        self._broker = BacktestingFuturesBroker(1000000, mf)
        mf.subscribe(self.on_bars_3)
        self._broker.getOrderUpdatedEvent().subscribe(self.on_order_update_3)
        mf.start()
        self.as
class MyController(object):
    @view(format='xml')
    def xml_action(self, *args, **kwargs):
        return {}
    @view(format='xml/text')
    def xml_full_mime_action(self):
        return {}
    @view(format='html', template='test')
    def html_action(self):
        return {}
    @view(format='json')
    def bool_action(self):
        return True
class TestViewDecorator(object):
    def test_view_model_format(self):
        controller = MyController()
        controller_response = controller.xml_action()
        assert isinstance(controller_response, views.Model)
        assert controller_response.format == 'xml'
        assert controller.xml_full_mime_action().format == 'xml/text'
    def test_view_model_template(self):
        controller = MyController()
        controller_response = controller.html_action()
        assert isinstance(controller_response, views.Model)
        assert controller_response.format == 'html'
        assert controller_response.template == 'test'
    de
asset_upload_redirect = dispatch.Signal(providing_args=['uuid'])
asset_download_redirect = dispatch.Signal(providing_args=['uuid'])
asset_delete_trigger = dispatch.Signal(providing_args=['uuid'])
store_asset = dispatch.Signal(providing_args=['asset', 'asset_file'])
retrieve_asset = dispatch.Signal(providing_args=['asset_uuid'])
initialize_asset_storage = dispatch.Signal(providing_args=['asset'])
destroy_asset_storage = dispatch.Signal()
requisition_instance = dispatch.Signal(providing_args=['activity'])
unrequisition_instance = dispatch.Signal(providing_args=['instance'])
validate_instance = dispatch.Signal(providing_args=['instance', 'validation'])
list_instances = dispatch.Signal(providing_args=['instances', 'request'])
pre_instance_update = dispatch.Signal(providing_args=['instance'])
post_instance_update = dispatch.Signal(providing_args=['instance'])
receive_error_log = dispatch.Signal(providing_args=['instance', 'requisitioner', 'content'])
account_tools = dispatch.Signal(providin
class ProfileService(object):
    def __init__(self, database_factory):
        self._database_factory = database_factory
        database = self._database_factory.get('default')
        session  = database.open_session('primary')
        self._session = session
    def repository(self):
        return self._session.repository(Profile)
    def find_by_id(self, id):
        repository = self.repository()
        if type(id) is not ObjectId:
            id = ObjectId(id)
        query = repository.new_criteria()
        query.expect('e.id = :id')
        query.define('id', id)
        query.limit(1)
        return repository.find(query)
    def find_by_email(self, email):
        repository = self.repository()
        query = repository.new_criteria()
        query.expect('e.email = :email')
        query.define('email', email)
        query.limit(1)
        return repository.find(query)
    def save(self, profile):
        repository = self.repository()
        repository.persist(profil
class TestEvent(unittest.TestCase):
    def setUp(self):
        location_a = Location(5, 3)
        node_a = Node(node_id="1", location=location_a)
        arguments_a = {'arg_1':1, 'arg_2':2, 'arg_3':3}
        self.asynchronous_event_1 = AsynchronousEvent(node_id=node_a.id, function_to_call=self.an_example_function, arguments=arguments_a)
        location_b = Location(1, 2)
        node_b = Node(node_id="1", location=location_b)
        arguments_b = {'arg_1':5, 'arg_2':4, 'arg_3':3}
        self.asynchronous_event_2 = AsynchronousEvent(node_id=node_b.id, function_to_call=self.an_example_function, arguments=arguments_b)
        self.simulator_event_1 = SimulatorEvent(arguments=arguments_a)
        self.simulator_event_2 = SimulatorEvent(arguments=arguments_b)
        self.event_broker = EventBroker()
    def test_asynchronous_event_list_empty(self):
        self.assert_(self.event_broker.is_asynchronous_events_empty())
        self.event_broker.add_asynchronous_event(self.asynchrono

        self.assertFalse(self.event_broker.is_asynchronous_events_empty())
        event = self.event_broker.get_asynchronous_event()
        self.assertTrue(self.event_broker.is_asynchronous_events_empty())
    def test_asynchronous_event_addition_and_get(self):
        self.event_broker.add_asynchronous_event(self.asynchronous_event_1)
        event = self.event_broker.get_asynchronous_event()
        self.assertEqual(event, self.asynchronous_event_1)
        self.event_broker.add_asynchronous_event(self.asynchronous_event_2)
        event = self.event_broker.get_asynchronous_event()
        self.assertEqual(event, self.asynchronous_event_2)
    def test_asynchronous_event_reset(self):
        self.assert_(self.event_broker.is_asynchronous_events_empty())
        self.event_broker.add_asynchronous_event(self.asynchronous_event_1)
        self.assertFalse(self.event_broker.is_asynchronous_events_empty())
        self.event_broker.add_asynchronous_event(self.asynchronous_event_2)
    

        self.assertEqual(event, self.asynchronous_event_2)
        self.event_broker.reset_asynchronous_events()
        self.assertTrue(self.event_broker.is_asynchronous_events_empty())
    def test_simulator_event_reset(self):
        self.assert_(self.event_broker.is_simulator_events_empty())
        self.event_broker.add_simulator_event(self.simulator_event_1)
        self.assertFalse(self.event_broker.is_simulator_events_empty())
        self.event_broker.add_simulator_event(self.simulator_event_2)
        event = self.event_broker.get_simulator_event()
        self.assertEqual(event, self.simulator_event_2)
        self.event_broker.reset_simulator_events()
        self.assertTrue(self.event_broker.is_simulator_events_empty())
    def test_simulator_event_addition_and_get(self):
        self.event_broker.add_simulator_event(self.simulator_event_1)
        event = self.event_broker.get_simulator_event()
        self.assertEqual(event, self.simulator_event_1)
        self.event_br
class ControllerState:
    """
    控制器管理状态的基类
    """
    @staticmethod
    def alpha(controller, ch):
        pass
    @staticmethod
    def punctuation(controller, p):
        pass
    @staticmethod
    def enter(controller):
        pass
    @staticmethod
    def backspace(controller):
        pass
    @staticmethod
    def c_l(controller):
        pass
    @staticmethod
    def tab(controller):
        pass
    @staticmethod
    def esc(controller):
        pass
    @staticmethod
    def c_p(controller):
        pass
    @staticmethod
    def c_n(controller):
        pass
    @staticmethod
    def recover(controller):
        raise NotImplementedError
    @staticmethod
    def c_k(controller):
        pass
class WordInput(ControllerState):
    """
    查询状态下的各种操作处理
    """
    en_chars = r'[a-zA-Z]'
    @staticmethod
    def _update_relevant(controller):
        """
        根据目前输入的单词刷新补全单词
        根据补全单词更新显示
        更新选中单词的下标
        """
        controller.set_relevant(controller.tr

        controller.cn_last = controller.search_window.show_relevant(controller.relevant_words, 0)
        controller.selected_index = 0
    @staticmethod
    def _search_en_word(controller):
        if controller.relevant_words and controller.relevant_words[0] == controller.input_word:
            explained_word = controller.local_dict.get_meaning(controller.input_word)
        else:
            explained_word = controller.online_dict.get_en_word_meaning(controller.input_word)
        return explained_word
    @staticmethod
    def _search_zh_word(controller):
        explained_word = controller.online_dict.get_zh_word_meaning(controller.input_word)
        return explained_word
    @staticmethod
    def alpha(controller, ch):
        """
        输入字母时刷新字符串
        """
        if ch == ' ' and len(controller.input_word) == 0:
            controller.change_to_state(WordDisplay)
        elif len(controller.input_word) < controller.word_max_length:
            controller.input_word += ch

            controller.search_window.show_input_word(controller.input_word)
            WordInput._update_relevant(controller)
    @staticmethod
    def enter(controller):
        """
        查询单词，隐藏查询框
        切换到展示状态并展示单词内容
        """
        has_en_char = re.search(WordInput.en_chars, controller.input_word)
        controller.word_meanings_window.clear()
        if has_en_char:
            explained_word = WordInput._search_en_word(controller)
            controller.word_meanings_window.display_en_word(explained_word)
        else:
            explained_word = WordInput._search_zh_word(controller)
            controller.word_meanings_window.display_zh_word(explained_word)
        controller.input_word = str()
        controller.change_to_state(WordDisplay)
    @staticmethod
    def backspace(controller):
        """
        删除最后一个字母，刷新字符串
        """
        controller.input_word = controller.input_word[:-1]
        if len(controller.input_word) == 0:
            controller.change
def test_basic_functionality():
    with open('test_save.sav', 'rb') as f:
        save = SaveDataGen1(f.read())
    save.money.should.equal(40398)
    save.trainer_name.should.equal('RED')
    save.trainer_id.should.equal(20152)
    save.rival_name.should.equal('BLUE')
    save.party_size.should.equal(6)
    len(save.party).should.equal(6)
    battery_jesus = save.party[0]
    battery_jesus.species.should.equal('Zapdos')
    battery_jesus.nickname.should.equal('AA-j')
    battery_jesus.trainer_id.should.equal(save.trainer_id)
    len(battery_jesus.moves).should.equal(4)
    battery_jesus.move_names[3].should.equal('Thunder')
    battery_jesus.level.should.equal(81)
    battery_jesus.index.should.equal(0x4B)
    battery_jesus.pokedex_num.should.equal('145')
    bird_jesus = save.party[5]
    bird_jesus.species.should.equal('Pidgeot')
    bird_jesus.trainer_name.should.equal('RED')
    bird_jesus.nickname.should.equal('aaabaaajss')
    bird_jesus.exp.should.equal(343472)
    bird_jesus.
"""Defines the factory for creating brokers"""
logger = logging.getLogger(__name__)
_BROKERS = {}
def add_broker_type(broker_class):
    """Registers a broker class so it can be used for storage operations.
    :param broker_class: The class definition for a broker.
    :type broker_class: class:`storage.brokers.broker.Broker`
    """
    broker = broker_class()
    if broker.broker_type in _BROKERS:
        logger.warning('Duplicate broker registration: %s', broker.broker_type)
    _BROKERS[broker.broker_type] = broker_class
def get_broker(broker_type):
    """Returns a broker of the given type.
    :param broker_type: The unique identifier of a registered broker.
    :type broker_type: string
    :returns: A broker for storing and retrieving files.
    :rtype: :class:`storage.brokers.broker.Broker`
    """
    if broker_type in _BROKERS:
        return _BROKERS[broker_type]()
    raise KeyError('\'%s\' is an invalid broker type' % broker_type)
def get_broker_types():
    """Returns a
try:
    QPID_MESSAGING_AVAILABLE = True
except ImportError:
    QPID_MESSAGING_AVAILABLE = False
try:
    QPIDTOOLLIBS_AVAILABLE = True
except ImportError:
    QPIDTOOLLIBS_AVAILABLE = False
_logger = logging.getLogger(__name__)
def migrate(*args, **kwargs):
    """
    Migrate qpid queues:
    - Ensure pulp.task is no longer *exclusive*.
    - Rename agent queues: consumer_id> => pulp.agent.<consumer_id>
    """
    transport = pulp_conf.get('messaging', 'transport')
    if transport != 'qpid':
        return
    if not QPID_MESSAGING_AVAILABLE:
        msg = _('Migration 0009 did not run because the python package qpid.messaging is not '
                'installed. Pulp\'s Qpid client dependencies can be installed with the '
                '\"pulp-server-qpid\" package group. See the installation docs for more '
                'information. Alternatively, you may reconfigure Pulp to use RabbitMQ.')
        _logger.error(msg)
        raise Exception(msg)
    if not QPIDTOOLLIBS_AVA

        msg = _('Migration 0009 did not run because the python package qpidtoollibs is not '
                'installed. Pulp\'s Qpid client dependencies can be installed with the '
                '\"pulp-server-qpid\" package group. See the installation docs for more '
                'information. Alternatively, you may reconfigure Pulp to use RabbitMQ.')
        _logger.error(msg)
        raise Exception(msg)
    url = urlparse(pulp_conf.get('messaging', 'url'))
    connection = Connection(
        host=url.hostname,
        port=url.port,
        transport=url.scheme,
        reconnect=False,
        ssl_certfile=pulp_conf.get('messaging', 'clientcert'),
        ssl_skip_hostname_check=True)
    connection.attach()
    broker = BrokerAgent(connection)
    _migrate_reply_queue(broker)
    _migrate_agent_queues(broker)
    connection.detach()
def _migrate_reply_queue(broker):
    """
    Ensure pulp.task is no longer *exclusive*.
    :param broker: A qpidtools broker.
    :type bro

    """
    name = ReplyHandler.REPLY_QUEUE
    queue = broker.getQueue(name)
    if not queue:
        return
    if queue.values['exclusive'] or queue.values['arguments'].get('exclusive', False):
        _del_queue_catch_queue_in_use_exception(broker, name)
        broker.addQueue(name, durable=True)
def _migrate_agent_queues(broker):
    """
    Rename agent queues: consumer_id> => pulp.agent.<consumer_id>
    :param broker: A qpidtools broker.
    :type broker: BrokerAgent
    """
    _add_agent_queues(broker)
    _del_agent_queues(broker)
def _add_agent_queues(broker):
    """
    Add queues named: pulp.agent.<consumer_id> foreach consumer.
    :param broker: A qpidtools broker.
    :type broker: BrokerAgent
    """
    collection = Consumer.get_collection()
    for consumer in collection.find():
        name = 'pulp.agent.%s' % consumer['id']
        queue = broker.getQueue(name)
        if queue:
            continue
        broker.addQueue(name, durable=True)
def _del_agent_qu
class ZohoBooks:
    """
    This class is used to create an object for books service and to provide instance for all APIs.
    """
   
    def __init__(self, authtoken, organization_id):
        """Initialize the parameters for Zoho books.
        Args:
            authtoken(str): User's Authtoken.
            organization_id(str): User's Organization id.
        """
        self.authtoken=authtoken
        self.organization_id=organization_id
    
    def get_contacts_api(self):
        """Get instance for contacts api.
  
        Returns:
            instance: Contacts api instance.
        """
        contacts_api = ContactsApi(self.authtoken, self.organization_id)
        return contacts_api
    def get_contact_persons_api(self):
        """Get instance for contact persons api.
        Returns:
            instance: Contact persons api.
        """
        contact_persons_api = ContactPersonsApi(self.authtoken, 
                                                self.organization_id)

        return contact_persons_api
    
    def get_estimates_api(self):
        """Get instance for estimates api.
        Returns: 
            instance: Estimates api.
        """
        estimates_api = EstimatesApi(self.authtoken, self.organization_id)
        return estimates_api
    
    def get_invoices_api(self):
        """Get instance for invoice api.
        Returns:
            instance: Invoice api.
        """
        invoices_api = InvoicesApi(self.authtoken, self.organization_id)
        return invoices_api
    def get_recurring_invoices_api(self):
        """Get instance for recurring invoices api.
        Returns:
            instance: Recurring invoice api.
        """
        recurring_invoices_api = RecurringInvoicesApi(self.authtoken, \
                                                      self.organization_id)
        return recurring_invoices_api
    def get_creditnotes_api(self):
        """Get instance for creditnotes api.
        Returns:
            instan

        """
        creditnotes_api = CreditNotesApi(self.authtoken, self.organization_id)
        return creditnotes_api
    def get_customer_payments_api(self):
        """Get instance for customer payments api.
        Returns:
            instance: Customer payments api.
        """
        customer_payments_api = CustomerPaymentsApi(self.authtoken, 
                                                    self.organization_id)
        return customer_payments_api
    
    def get_expenses_api(self):
        """Get instance for expenses api.
         
        Returns:
            instance: Expenses api.
        """
        expenses_api = ExpensesApi(self.authtoken, self.organization_id)
        return expenses_api
    
    def get_recurring_expenses_api(self):
        """Get instance for recurring expenses api.
        Returns:
            instance: Recurring expenses api.
        """
        recurring_expenses_api = RecurringExpensesApi(self.authtoken, 
                               
datatypes_repository_name = 'blast_datatypes_0120'
datatypes_repository_description = 'Galaxy applicable datatypes for BLAST'
datatypes_repository_long_description = 'Galaxy datatypes for the BLAST top hit descriptons tool'
tool_repository_name = 'blastxml_to_top_descr_0120'
tool_repository_description = 'BLAST top hit descriptions'
tool_repository_long_description = 'Make a table from BLAST XML'
'''
Tool shed side:
1) Create and populate blast_datatypes_0120.
1a) Check for appropriate strings.
2) Create and populate blastxml_to_top_descr_0120.
2a) Check for appropriate strings.
3) Upload repository_dependencies.xml to blastxml_to_top_descr_0120 that defines a relationship to blast_datatypes_0120.
3a) Check for appropriate strings.
'''
base_datatypes_count = 0
repository_datatypes_count = 0
class TestRepositoryMultipleOwners( ShedTwillTestCase ):
    def test_0000_initiate_users( self ):
        """Create necessary user accounts and login as an admin user."""
        """
        Create

        Previously created accounts will not be re-created.
        """
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = self.test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.test_user_2_email, username=common.test_user_2_name )
        test_user_2 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_2 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_2_email
        test_user_2_private_role = self.test_db_util.get_private_role( test_user_2 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_

        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
    def test_0005_create_datatypes_repository( self ):
        """Create and populate the blast_datatypes_0120 repository"""
        """
        We are at step 1.
        Create and populate blast_datatypes.
        """
        category = self.create_category( name='Test 0120', description='Description of test 0120' )
        self.logout()
        self.login( email=common.test_user_2_email, username=common.test_user_2_name )
        strings_displayed = self.expect_repo_created_strings(datatypes_repository_name)
        repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                                    description=datatypes_repository_description, 
                                                    long_description=datatypes_repository_long_de
urlpatterns = patterns(
    '',
    url(r'^$', 'stucampus.master.views.manage.index.redirect',
        name='admin_index_redirect'),
    url(r'^index$',
        'stucampus.master.views.manage.index.index', name='admin_index'),
    url(r'^organization/list$', ListOrganization.as_view(),
        name='manage_organization_list'),
    url(r'^organization/(?P<id>\d+)$', ShowOrganization.as_view(),
        name='manage_organization_show'),
    url(r'^organization/(?P<id>\d+)/manager$', OrganzationManager.as_view(),
        name='manage_organization_manage'),
    url(r'^account/list$', ListAccount.as_view(), name='manage_account_list'),
    url(r'^account/(?P<id>\d+)$', ShowAccount.as_view(),
        name='manage_account_show'),
    url(r'^infor/list$', ListInfor.as_view(), name='manage_infor_list'),
    url(r'^infor/post$', PostInfor.as_view(), name='manage_infor_post'),
    url(r'^infor/(?P<id>\d+)$', Information.as_view(),
        name='manage_infor_infor'),
    url(r'^organization$',
    
class FreeVarsVisitor(Visitor):
    def visitName(self, n):
        if n.name in builtin_functions:
            return set([])
        else:
            return set([n.name])
    def visitConst(self, n):
        return set([])
    def visitAdd(self, n):
        return self.dispatch(n.left) | self.dispatch(n.right)
    def visitUnarySub(self, n):
        return self.dispatch(n.expr)
    def visitCallFunc(self, n):
        sss = [self.dispatch(arg) for arg in n.args]
        ss = reduce(lambda a,b: a | b, sss, set([]))
        return ss | self.dispatch(n.node)
    def visitLambda(self, n):
        local_vars = FindLocalsVisitor().preorder(n.code)
        return (self.dispatch(n.code) - local_vars) - set(n.argnames)
    def visitIfExp(self, n):
        return self.dispatch(n.test) | self.dispatch(n.then) | self.dispatch(n.else_)        
    def visitCompare(self, n):
        return self.dispatch(n.expr) | self.dispatch(n.ops[0][1])
    def visitSubscript(self, n):
        return self.dispa

    def visitGetTag(self, n):
        return self.dispatch(n.arg)
    def visitInjectFrom(self, n):
        return self.dispatch(n.arg)
    def visitProjectTo(self, n):
        return self.dispatch(n.arg)
    def visitLet(self, n):
        return self.dispatch(n.rhs) | (self.dispatch(n.body) - set([n.var]))
    def visitSetSubscript(self, n):
        return self.dispatch(n.container) | self.dispatch(n.key) | self.dispatch(n.val)
    def visitStmt(self, n):
        sss  = [self.dispatch(s) for s in n.nodes]
        return reduce(lambda a,b: a | b, sss, set([]))
    def visitPrintnl(self, n):
        return self.dispatch(n.nodes[0])
    def visitAssign(self, n):
        return self.dispatch(n.expr)
    def visitDiscard(self, n):
        return self.dispatch(n.expr)
    def visitReturn(self, n):
        return self.dispatch(n.value)
    def visitInjectFrom(self, n):
        return self.dispatch(n.arg)
    def visitProjectTo(self, n):
        return self.dispatch(n.arg)
    def visitGetTa
"""Routes configuration
The more specific and detailed routes should be defined first so they
may take precedent over the more generic routes. For more information
refer to the routes manual at http://routes.groovie.org/docs/
"""
routing_plugins = PluginImplementations(IRoutes)
def make_map():
    """Create, configure and return the routes Mapper"""
    map = Mapper(directory=config['pylons.paths']['controllers'],
                 always_scan=config['debug'], explicit=True)
    map.minimization = False
    map.connect('/error/{action}', controller='error')
    map.connect('/error/{action}/{id}', controller='error')
    map.connect('/_error_test/{action}', controller='error_test')
    for plugin in routing_plugins:
        plugin.before_map(map)
    map.connect('/', controller='home', action='index')
    map.connect('/25kspending', controller='home', action='govspending')
    map.connect('/getinvolved', controller='home', action='getinvolved')
    map.connect('/locale', controller='home

    map.connect('/login', controller='account', action='login')
    map.connect('/register', controller='account', action='register')
    map.connect('/settings', controller='account', action='settings')
    map.connect('/after_login', controller='account', action='after_login')
    map.connect('/after_logout', controller='account', action='after_logout')
    map.connect('search', '/search', controller='search', action='index')
    map.connect('/dataset/{dataset}/dimension.{format}',
                controller='dimension', action='index')
    map.connect('/dataset/{dataset}/dimension',
                controller='dimension', action='index')
    map.connect('/dataset/{dataset}/dimension/{dimension}.{format}',
                controller='dimension', action='view')
    map.connect('/dataset/{dataset}/dimension/{dimension}',
                controller='dimension', action='view')
    map.connect('/dataset', controller='dataset', action='index')
    map.connect('/dataset.json', controller='

                format='json')
    map.connect('/dataset.csv', controller='dataset', action='index',
                format='csv')
    map.connect('/dataset/{id}.json', controller='dataset', action='view',
                format='json')
    map.connect('/dataset/{id}.html', controller='dataset', action='view',
                format='html')
    map.connect('/dataset/{id}', controller='dataset', action='view')
    map.connect('/dataset/{id}/{action}.{format}', controller='dataset')
    map.connect('/dataset/{id}/{action}', controller='dataset')
    map.connect('/entity', controller='entity', action='index')
    map.connect('/entity/{id}.json', controller='entity', action='view',
                format='json')
    map.connect('/entity/{id}.html', controller='entity', action='view',
                format='html')
    map.connect('/entity/{id}/entries.{format}', controller='entity',
                action='entries')
    map.connect('/entity/{id}/entries', controller='entity', action='entr
__author__ = 'kohn'
class TestCrawlController(unittest.TestCase):
    def test_crawl_group_members(self):
        """
        Check if the crawler successfully fetches the 22 group members
        :return:
        """
        crwler = FileCrawler()
        crwler_controller = CrawlController(crwler, "d0b7f41f-ad37-3b47-ab70-9feac35557cc")
        self.assertIsNotNone(crwler_controller.members)
        self.assertEqual(len(crwler_controller.members), 0)
        crwler_controller.crawl_group_members()
        self.assertEqual(len(crwler_controller.members), 19)
    def test_crawl_profiles(self):
        """
        Check if the crawler successfully fetches profiles and for all profiles at least an entry in the doc dict
        :return:
        """
        crwler = FileCrawler()
        crwler_controller = CrawlController(crwler, "d0b7f41f-ad37-3b47-ab70-9feac35557cc")
        crwler_controller.crawl_group_members()
        crwler_controller.crawl_profiles()
        self.assertIsNotNone(c

        self.assertEqual(len(crwler_controller.profiles), 19)
        for member in crwler_controller.members:
            self.assertIn(member.profile_id, crwler_controller.profile_documents)
    def test_crawl_group_documents(self):
        crwler = FileCrawler()
        crwler_controller = CrawlController(crwler, "d0b7f41f-ad37-3b47-ab70-9feac35557cc")
        crwler_controller.crawl_group_members()
        crwler_controller.crawl_group_documents()
        self.assertGreater(len(crwler_controller.group_documents), 0)
    def test_execute(self):
        crwler = FileCrawler()
        crwler_controller = CrawlController(crwler, "d0b7f41f-ad37-3b47-ab70-9feac35557cc")
        crwler_controller.execute()
        self.assertEqual(len(crwler_controller.profiles), 19)
        for member in crwler_controller.members:
            self.assertIn(member.profile_id, crwler_controller.profile_documents)
        self.assertGreater(len(crwler_controller.group_documents), 0)
        self.assertTrue
"""
This script plots results from the UNH-RVAT turbinesFoam case.
"""
if __name__ == "__main__":
    set_sns()
    plt.rcParams["axes.grid"] = True
    parser = argparse.ArgumentParser(description="Generate plots.")
    parser.add_argument("plot", nargs="*", help="What to plot", default="perf",
                        choices=["perf", "wake", "blade-perf", "strut-perf",
                                 "perf-curves", "perf-curves-exp", "recovery",
                                 "wake-profiles", "wake-profiles-exp",
                                 "verification"])
    parser.add_argument("--all", "-A", help="Generate all figures",
                        default=False, action="store_true")
    parser.add_argument("--save", "-s", help="Save to `figures` directory",
                        default=False, action="store_true")
    parser.add_argument("--no-show", default=False, action="store_true",
                        help="Do not call matplotlib show function")
    parser.add_argum

                        default=["alpha", "rel_vel_mag"])
    args = parser.parse_args()
    if args.save:
        if not os.path.isdir("figures"):
            os.mkdir("figures")
    if "wake" in args.plot or args.all:
        plot_meancontquiv(save=args.save)
        plot_kcont(save=args.save)
    if "wake-profiles" in args.plot or args.all:
        plot_wake_profiles(save=args.save)
    if "wake-profiles-exp" in args.plot or args.all:
        plot_wake_profiles(exp=True, save=args.save)
    if "perf" in args.plot or args.all:
        plot_cp(save=args.save)
    if "blade-perf" in args.plot or args.all:
        plot_blade_perf(save=args.save, quantities=args.q)
    if "strut-perf" in args.plot or args.all:
        plot_strut_perf(save=args.save, quantities=args.q)
    if "perf-curves" in args.plot or args.all:
        plot_perf_curves(exp=False, save=args.save)
    if "perf-curves-exp" in args.plot or args.all:
        plot_perf_curves(exp=True, save=args.save)
    if "recovery" in 
"""Routes configuration
refer to the routes manual at http://routes.groovie.org/docs/
"""
def make_map(config):
	"""Create, configure and return the routes Mapper"""
	map = Mapper(directory=config['pylons.paths']['controllers'], always_scan=config['debug'])
	map.minimization = False
	map.explicit = False
	map.connect('/error/{action}', controller='error')
	map.connect('/error/{action}/{id}', controller='error')
	map.connect('/', controller='login', action='index')
	map.connect('/{controller}/', action='index')
	map.connect('/{controller}', action='index')
	map.connect('/plugins/{id}/{id2}/{id3}', controller='plugins', action='index')
	map.connect('/plugins/{id}/{id2}', controller='plugins', action='index')
	map.connect('/plugins/{id}/', controller='plugins', action='index')
	map.connect('/plugui/{id}/{id2}', controller='plugui', action='index')
	map.connect('/plugui/{id}/', controller='plugui', action='index')
	map.connect('/{controller}/{action}/{id}/{id2}/{id3}/{id4}/')
	map.connect(
'''Testing module for various problematic context managers.'''
                                                    ContextManagerType,
                                                    SelfHook)
def test_defining_enter_and_manage_context():
    '''
    Test context manager class defining both `__enter__` and `manage_context`.
    '''
    
    with cute_testing.RaiseAssertor(
        Exception,
        'both an `__enter__` method and a'
        ):
        
        class MyContextManager(ContextManager):
            def manage_context(self):
                yield self
            def __enter__(self):
                return self
            
def test_defining_exit_and_manage_context():
    '''
    Test context manager class defining both `__exit__` and `manage_context`.
    '''
    
    with cute_testing.RaiseAssertor(
        Exception,
        'both an `__exit__` method and a'
        ):
        
        class MyContextManager(ContextManager):
            def manage_context(self):
   

            def __exit__(self, *exc):
                pass
            
def test_defining_enter_on_top_of_manage_context():
    '''
    Test an `__enter__`-definer inheriting from a `manage_context`-definer.
    '''
    class MyBaseContextManager(ContextManager):
        def manage_context(self):
            yield self
            
    with cute_testing.RaiseAssertor(
        Exception,
        "defines an `__enter__` method, but not an `__exit__` method"
        ):
        
        class MyContextManager(MyBaseContextManager):
            def __enter__(self):
                return self
            
            
def test_defining_exit_on_top_of_manage_context():
    '''
    Test an `__exit__`-definer inheriting from a `manage_context`-definer.
    '''
    
    class MyBaseContextManager(ContextManager):
        def manage_context(self):
            yield self
            
    with cute_testing.RaiseAssertor(
        Exception,
        "defines an `__exit__` method, but not an `__ente
def tests_rentController():
    filmRepo =FilmRepository()
    filmValid = FilmValidator()
    filmController = FilmController(filmRepo, filmValid)
    
    clientRepo = ClientRepository()
    clientValid = ClientValidator()
    clientController = ClientController(clientRepo, clientValid)
    
    filmController.createFilm("1", "blabla", "blaaa", "fantasy")
    filmController.createFilm("2", "blabla2", "blaaa2", "fantasy")
    filmController.createFilm("3", "blabla3", "blaaa3", "adventure")
    
    clientController.createClient("1", "stefan", "1234")
    clientController.createClient("2", "stefan2", "12345")
    clientController.createClient("3", "stefan3", "123456")
    
    
    
    
    repo = RentRepository()
    valid = RentValidator()
    ctrl = RentController(repo, valid, filmRepo, clientRepo)
    
    rent1 = ctrl.createRent("1", "2")
    assert len(ctrl.getAllRents()) == 1
    assert rent1.getIDC() == "1"
    assert rent1.getIDF() == "2"
    
    try:
        ctrl.createRent
BROKER_URL = 'amqp://will:dampier@localhost:5672/'
CELERY_RESULT_BACKEND = 'amqp://'
CELERY_TASK_SERIALIZER = 'pickle'
CELERY_RESULT_SERIALIZER = 'pickle'
CELERY_IMPORTS = ('HIVTransTool',
                  'TreeingTools',
                  'HIVSeqDBManagement')
CELERY_MAX_CACHED_RESULTS = 100000
CELERY_TRACK_STARTED = True
CELERYD_MAX_TASKS_PER_CHILD = 10
CELERYD_POOL_RESTARTS = True
CELERY_SEND_EVENTS = True
CELERYD_HIJACK_ROOT_LOGGER = False
CELERYD_PREFETCH_MULTIPLIER = 1
CELERY_ACKS_LATE = True
CELERY_QUEUES = [Queue('HIVTransTool'),
                 Queue('celery'),
                 Queue('long-running'),
                 Queue('base'),
                 Queue('HIVSeqDBManagement'),
                 Queue('writingqueue'),
                 ]
CELERY_ANNOTATIONS = {
    'HIVSeqDBManagement.query_LANL': {'rate_limit': '10/m'},
    'TreeingTools.write_results_to_mongo': {'rate_limit': '10/s'},
    'TreeingTools.process_region': {'rate_limit': '10/m'}
CELERY_ROUTES = {
    'TreeingTools
"""
tlBrokers
Store, retrieve, list and find Brokers. Broker get and set params
"""
class BrokerNotFound(Exception):
    pass
class BrokerNotSynced(Exception):
    pass
class BrokersNotDefined(Exception):
    pass
class tlBrokers(QObject):
    """
    Class to manage array of Brokers including storage
    
    """
    _this = None
    brokersLoaded = pyqtSignal(object)
    kDefaultFile = "brokers.json.default"
    kBrokerFile = 'brokerFile'
    kBrokerList = "brokers/list"
    @staticmethod
    def instance():
        return tlBrokers._this
    def __init__(self, pluginDir):
        super(tlBrokers, self).__init__()
        self._jsonfile = None
        self._loaded = False
        self._dirty = False
        self._brokers = {}
        self._oldBrokers = None
        self._dirty = False
        self._dirtyList = []
        self._defaultFile = os.path.join(pluginDir, self.kDefaultFile)
        self._jsonfile = Settings.get("brokerFile", self._defaultFile)
        tlBrokers._this = self


        self.load()
        try:
            if not filename:
                filename = self._jsonfile
            if os.path.exists(filename):
                return json.loads(open(filename).read())
            else:
                Log.debug("Broker file " + filename + " not found!")
        except Exception as e:
            Log.critical(e)
        self._dirty = False
        return ""
        pass
    def load(self):
        try:
            jsonstr = Settings.get(self.kBrokerList)
            if not jsonstr:
               Log.debug("Load brokers from file") 
            else:
               self._brokers = dict(json.loads( jsonstr ))
            self._validate()
            self.brokersLoaded.emit(self._dirtyList)
            self._dirtyList[:] = []
        except Exception as e:
            Log.debug("Error loading broker: " + str(e))
            exc_type, exc_value, exc_traceback = sys.exc_info()
            Log.debug(repr(traceback.format_exception(exc_type, exc_value,
    

        finally:
            self._dirty = False
    def _file(self):
        if self._jsonfile == self._defaultFile:
                                                   "~/",
                                                   "*.json")
            if fileName:
                Settings.set(self.kBrokerFile, fileName)
                self._jsonfile = fileName
            else:
                Log.critical("Broker data being saved to plugin directory and will be lost on upgrade!")
        return self._jsonfile
    def sync(self, load=True):
        try:
            Settings.set(self.kBrokerList,json.dumps(self._brokers))
        except Exception as e:
            Log.critical(e)
        if load:
            self.load()
    def exportFile(self):
        if not self._dirty:
            return
        try:
            with open(self._file(), 'w') as f:
                json.dump(f)
            self._dirty = False
            if load:
                self.load()
        except Exception as e:
app = Flask(__name__)
app.config.from_object('config.DevelopmentConfig')
api = Api(app)
db = SQLAlchemy(app)
API_VERSION = Config.API_VERSION
api.add_resource(Home,
                 '/'.format(version=API_VERSION))
api.add_resource(Index,
                 '/index'.format(version=API_VERSION))
api.add_resource(SignUp,
                 '/signup'.format(version=API_VERSION))
api.add_resource(SignIn,
                 '/signin'.format(version=API_VERSION))
api.add_resource(UserListAPI,
                 '/users'.format(version=API_VERSION),
                 endpoint='users', strict_slashes=False)
api.add_resource(UserAPI,
                 '/users/<int:id>'.format(version=API_VERSION),
                 endpoint='user', strict_slashes=False)
api.add_resource(SongsListAPI,
                 '/songs'.format(version=API_VERSION),
                 endpoint='songs', strict_slashes=False)
api.add_resource(SongAPI,
                 '/songs/<int:id>'.format(version=API_VERSION),
                 endpoi
""" set following variables according to your setup """
INTERVAL = 60
def fetch_info(host, port):
    """ connect to mongo and fetch server status """
    try:
        m_info = urllib.urlopen('http://' + host + ':' + str(port) + '/serverStatus').read()
        j_info = json.loads(m_info)
        return j_info
    except:
        print 'Could not connect to mongo, please check if port and hostname is right.'
def print_stat(metric, value, tags=""):
    """ prints values in hbase schema format """
    ts = int(time.time())
    if value is not None:
        print "mongo.%s %d %s %s" % (metric, ts, value, tags)
def dispatch_value(info, identifier, metric, extra_info=None):
    ts = int(time.time())
    if extra_info:
        return print_stat(identifier + '.' + metric + '.' + extra_info,
                          info[identifier][metric][extra_info],
                          'mongohost=' + MONGO_HOST)
    return print_stat(identifier + "." + metric,
                      info[identifier][m

                      'mongohost=' + MONGO_HOST)
def main():
    """ mongo-stats main loop """
    while True:
        info = fetch_info(MONGO_HOST, MONGO_PORT)
        dispatch_value(info, 'mem', 'resident')
        dispatch_value(info, 'mem', 'virtual')
        dispatch_value(info, 'mem', 'mapped')
        dispatch_value(info, 'network', 'bytesIn')
        dispatch_value(info, 'network', 'bytesOut')
        dispatch_value(info, 'network', 'numRequests')
        dispatch_value(info, 'opcounters', 'insert')
        dispatch_value(info, 'opcounters', 'query')
        dispatch_value(info, 'opcounters', 'update')
        dispatch_value(info, 'opcounters', 'delete')
        dispatch_value(info, 'opcounters', 'getmore')
        dispatch_value(info, 'opcounters', 'command')
        dispatch_value(info, 'connections', 'current')
        dispatch_value(info, 'connections', 'available')
        dispatch_value(info, 'extra_info', 'heap_usage_bytes')
        dispatch_value(info, 'extra_info', 'p

        dispatch_value(info, 'asserts', 'regular')
        dispatch_value(info, 'asserts', 'warning')
        dispatch_value(info, 'asserts', 'msg')
        dispatch_value(info, 'asserts', 'user')
        dispatch_value(info, 'asserts', 'rollovers')
        dispatch_value(info, 'indexCounters', 'btree', 'missRatio')
        dispatch_value(info, 'indexCounters', 'btree', 'resets')
        dispatch_value(info, 'indexCounters', 'btree', 'hits')
        dispatch_value(info, 'indexCounters', 'btree', 'misses')
        dispatch_value(info, 'indexCounters', 'btree', 'accesses')
        dispatch_value(info, 'globalLock', 'totalTime')
        dispatch_value(info, 'globalLock', 'lockTime')
        dispatch_value(info, 'globalLock', 'ratio')
        dispatch_value(info, 'globalLock', 'currentQueue', 'total')
        dispatch_value(info, 'globalLock', 'currentQueue', 'readers')
        dispatch_value(info, 'globalLock', 'currentQueue', 'writers')
        dispatch_value(info, 'globalLock', 'active
kitten = bacon.Image('res/kitten.png')
class Game(bacon.Game):
    controller = None
    def on_tick(self):
        bacon.clear(0, 0, 0, 1)
        if self.controller:
            bacon.translate(bacon.window.width / 2, bacon.window.height / 2)
            bacon.translate(self.controller.left_thumb_x * 100, self.controller.left_thumb_y * 100)
            bacon.rotate(self.controller.right_thumb_x)
            bacon.scale(self.controller.right_thumb_y + 1, self.controller.right_thumb_y + 1)
            bacon.draw_image(kitten, -kitten.width / 2, -kitten.height / 2)
    def on_controller_button(self, controller, button, pressed):
        print('bacon.ControllerButtons.%s on controller %d was %s' % (bacon.ControllerButtons.tostring(button), controller.controller_index, 'pressed' if pressed else 'released'))
    def on_controller_axis(self, controller, axis, value):
        print('bacon.ControllerAxes.%s on controller %d value is now %f' % (bacon.ControllerAxes.tostring(axis), controller.c
'''
Created on 13 nov. 2014
@author: Narcis2007
'''
'''
class TestControllerPLab:
    def __init__(self):
        self.__repository=RepositoryPLab()
        self.__controller=ControllerPLab(self.__repository,ValidatorPlab())
        p1=ProblemaLaborator(1,1,"q","marti")
        p2=ProblemaLaborator(2,2,"w","miercuri")
        p3=ProblemaLaborator(3,3,"t","y")
        self.__repository.save(p1)
        self.__repository.save(p2)
        self.__repository.save(p3)
        
    def test_adauga_problema(self):
        assert self.__repository.lungime()==3
        self.__controller.adauga_problema(4,4,"u", "r")
        assert self.__repository.lungime()==4
            
    def test_sterge_problema(self):
        self.__controller.stergere_problema(11)
        assert self.__repository.lungime()==3
    
    def test_modifica_problema(self):
        self.__controller.modifica_problema(2, 2, "descriere", "deadline")
        p=ProblemaLaborator(2, 2, "descriere", "deadline")
        p1=self.__re

        assert p1==p
    
    def test_cauta(self):
        p=ProblemaLaborator(2,2, "descriere", "deadline")
        assert self.__controller.cauta_problema(22)==p
        
    
    def test_get_all(self):
        l=self.__controller.get_all()
        assert len(l)==3
            
    def test_controller_plab(self):
        self.test_adauga_problema()
        self.test_sterge_problema()
        self.test_modifica_problema()
        self.test_cauta()
        self.test_get_all()
'''
class TestControllerPLab(unittest.TestCase):
    def setUp(self):
        self.__repository=RepositoryPLab()
        self.__controller=ControllerPLab(self.__repository,ValidatorPlab())
        p1=ProblemaLaborator(1,1,"q","marti")
        p2=ProblemaLaborator(2,2,"w","miercuri")
        p3=ProblemaLaborator(3,3,"t","y")
        self.__repository.save(p1)
        self.__repository.save(p2)
        self.__repository.save(p3)
        
    def test_adauga_problema(self):
        assert self.__repository.lungime
class Public():
	def add_routes(self,mapper):
		svmanp_controller=wsgi.Resource(controllers.VMSVManProxy())
		mapper.connect('/filedeploy',controller=svmanp_controller,action='fileDeploy')	
		mapper.connect('/fileundeploy/{id}',controller=svmanp_controller,action='fileUndeploy')
		mapper.connect('/svs/{id}',controller=svmanp_controller,action='buildSvInst',conditions=dict(method=["POST"]))
		mapper.connect('/svs/{id}/{sv_inst_id}',controller=svmanp_controller,action='svStatequery',conditions=dict(method=["GET"]))
		mapper.connect('/svs/{id}/{sv_inst_id}/suspend',controller=svmanp_controller,action='svSuspend',conditions=dict(method=["PUT"]))
		mapper.connect('/svs/{id}/{sv_inst_id}',controller=svmanp_controller,action='svClose',conditions=dict(method=["DELETE"]))
		mapper.connect('/svs/{id}/{sv_inst_id}',controller=svmanp_controller,action='svCall',conditions=dict(method=["POST"]))
		mapper.connect('/svs/{id}/{sv_inst_id}/resume',controller=svmanp_controller,action='svResume',condition
def get_all(serial_number):
    sql = """SELECT * FROM controllers WHERE installation = %s"""
    return backend._query(sql, serial_number)
def get_controller(controller_ip, serial_number):
    sql = """SELECT * FROM `controllers` WHERE `ip` = %s AND `installation` = %s"""
    return backend._query_for_one(sql, controller_ip, serial_number)
def update_controller(controller):
    sql = """UPDATE controllers SET name = %s WHERE ip = %s AND installation = %s"""
    return backend._exec(sql, controller.get('name'), controller.get('ip'), controller.get('installation'))
def delete_controller(serial_number, controller_ip):
    sql = """DELETE FROM controllers WHERE installation = %s AND ip = %s"""
    return backend._exec(sql, serial_number, controller_ip)
def create_controller(controller):
    return backend._exec("""INSERT INTO controllers(`installation`, `ip`, `name`) VALUES(%s, %s, %s)""",
                         controller.get('installation'), controller.get('ip'), controller.get('name'
""" this is the dispatch plugin that dispatches events to commands. """
cpy = copy.deepcopy
def predispatch(bot, event):
    """ check whether we should check for commands. """
    if event.status == "done": logging.debug("dispatch - event is done .. ignoring") ; return False
    if event.isremote(): logging.debug("event is remote .. not dispatching") ; return False
    if event.isrelayed: logging.debug("event is relayed .. not dispatching") ; return False  
    if event.blocked(): logging.warn("blocking %s" % event.userhost) ; return False
    return True
def dispatch(bot, event):
    """ dispatch an event. """
    logging.info("dispatch - doing event %s" % event.tojson())
    if event.userhost in bot.ignore: logging.warn("%s - ignore on %s" % (bot.name, event.userhost)) ; return
    if event.nodispatch:
        logging.warn("dispatch - nodispatch option is set - ignoring %s" % event.userhost)
        return
    bot.status = "dispatch"
    event.bind(bot)
    if event.iscommand or eve

        try:
            event.iscommand = True
            if not event.options: event.makeoptions()
            try: result = event.execute()
            except NoSuchCommand, ex:
                logging.warn("no such command: %s" % event.usercmnd)
                if event.giveresponse: event.reply("no %s command found" % str(ex).strip())
                event.launched() ; event.ready()
        except Exception, ex: handle_exception()
    else:
        logging.debug("dispatch - no go for %s" % event.auth or event.userhost)
        event.launched() ; event.ready()
last_callbacks.add('PRIVMSG', dispatch, predispatch, speed=3)
last_callbacks.add('MESSAGE', dispatch, predispatch)
last_callbacks.add('BLIP_SUBMITTED', dispatch, predispatch)
last_callbacks.add('WEB', dispatch, predispatch)
last_callbacks.add('CONSOLE', dispatch, predispatch)
last_callbacks.add('DCC', dispatch, predispatch)
last_callbacks.add('DISPATCH', dispatch, predispatch)
last_callbacks.add('CMND', dispatch, predispatc
empty_frame = ''
def test_worker_idle():
    service = Broker.Service()
    worker = Broker.Worker('address', service)
    eq_(worker.idle, False)
    eq_(service.idle_workers, [])
    worker.idle = True
    eq_(service.idle_workers, [worker])
    eq_(worker.idle, True)
    worker.idle = False
    eq_(service.idle_workers, [])
    eq_(worker.idle, False)
def test_service():
    s = Broker.Service()
    listener = Mock()
    s.on_work(listener)
    eq_(listener.mock_calls, [])
    s.add_worker('worker1')
    eq_(s.idle_workers, ['worker1'])
    eq_(listener.mock_calls, [])
    s.add_request('reply_address', 'request1')
    listener.assert_called_once_with(('reply_address', 'request1'), 'worker1')
def test_broker_add_remove_worker():
    stream = Mock()
    broker = Broker(stream)
    s1 = Broker.Service()
    eq_(broker.workers, {})
    eq_(s1.idle_workers, [])
    w = Broker.Worker('worker1', s1)
    broker.add_worker(w)
    eq_(broker.workers, {'worker1': w})
    eq_(s1.idle_workers, 

    with assert_raises(DuplicateWorker):
        broker.add_worker(w)
    broker.remove_worker(w)
    eq_(broker.workers, {})
    eq_(s1.idle_workers, [])
    with assert_raises(UnknownWorker):
        broker.remove_worker(w)
def test_register_unregister_worker():
    stream = Mock()
    broker = Broker(stream)
    worker_address = 'worker1'
    service_name = 'test_service'
    msg = [worker_address, empty_frame, opcodes.REQUEST,
           'beehive.management.register_worker', service_name]
    broker.message(msg)
    eq_(len(broker.workers), 1)
    eq_(broker.services.keys(), [service_name])
    eq_(broker.workers.keys(), [worker_address])
    worker = broker.workers[worker_address]
    service = broker.services[service_name]
    eq_(service.idle_workers, [worker])
    eq_(worker.service, service)
    eq_(worker.idle, True)
    msg = [worker_address, empty_frame, opcodes.REQUEST,
           'beehive.management.unregister_worker', service_name]
    broker.message(msg)
    eq_(broker

    eq_(broker.services.keys(), [service_name])
    eq_(service.idle_workers, [])
    with assert_raises(UnknownWorker):
        broker.message(msg)
def test_register_duplicate_worker():
    stream = Mock()
    broker = Broker(stream)
    worker_address = 'worker1'
    service_name = 'test_service'
    msg = [worker_address, empty_frame, opcodes.REQUEST,
           'beehive.management.register_worker', service_name]
    broker.message(msg)
    with assert_raises(DuplicateWorker):
        broker.message(msg)
    eq_(len(broker.workers), 1)
    eq_(broker.services.keys(), [service_name])
    eq_(broker.workers.keys(), [worker_address])
    worker = broker.workers[worker_address]
    service = broker.services[service_name]
    eq_(service.idle_workers, [worker])
    eq_(worker.service, service)
    eq_(worker.idle, True)
def test_broker_stream_send():
    stream = Mock()
    broker = Broker(stream)
    broker.send('address', 'message')
    stream.send.assert_called_once_with('address', '
__doc__='''Zope registerable permissions
$Id: Permission.py 40222 2005-11-18 15:46:28Z andreasjung $'''
__version__='$Revision: 1.9 $'[11:-2]
view_management_screens = Permissions.view_management_screens
define_permissions = Permissions.define_permissions
class Permission(
    AccessControl.Role.RoleManager,
    Globals.Persistent, Acquisition.Implicit, OFS.SimpleItem.Item
    ):
    "Model Permission meta-data"
    meta_type='Zope Permission'
    icon='p_/Permission_icon'
    security = ClassSecurityInfo()
    manage_options=(
        (
        {'label':'Edit', 'action':'manage_main',
         'help':('OFSP','Zope-Permission_Edit.stx')},
        )
        +AccessControl.Role.RoleManager.manage_options
        +OFS.SimpleItem.Item.manage_options
        )
    def __init__(self, id, title, name):
        self.id=id
        self.title=title
        self.name=name
    security.declareProtected(define_permissions, 'manage_edit')
    def manage_edit(self, title, name, REQUEST=None):
       

        if title != self.title: self.title=title
        if name != self.name:
            self._unregister()
            self.name=name
            self._register()
        if REQUEST is not None: return self.manage_main(self, REQUEST)
    security.declarePrivate('manage_afterAdd')
    def manage_afterAdd(self, item, container):
        self._register()
    security.declarePrivate('manage_beforeDelete')
    def manage_beforeDelete(self, item, container):
        self._unregister()
    def _register(self):
        product=self.aq_parent
        product.aq_acquire('_manage_add_product_permission')(
            product, self.name)
    def _unregister(self):
        product=self.aq_parent
        product.aq_acquire('_manage_remove_product_permission')(
            product, self.name)
    security.declareProtected(view_management_screens, 'manage_main')
    manage_main=Globals.DTMLFile('dtml/editPermission',globals())
    index_html=None
Globals.InitializeClass(Permission)
class Permissio
    DialogResult, MessageBox, 
    MessageBoxButtons, MessageBoxIcon
class RemoveCommand(object):
    
    def __init__(self, tabController):
        self.tabController = tabController
        
    
    def execute(self):
        if not self.tabController.hasPages:
            return
        result = MessageBox.Show("Are you sure?",
                                 "Delete Page",
                                 MessageBoxButtons.OKCancel,
                                 MessageBoxIcon.Question)
        if result == DialogResult.OK:
            self.tabController.deletePage()
class RenameCommand(object):
    
    def __init__(self, tabController):
        self.tabController = tabController
        
        
    def execute(self):
        if not self.tabController.hasPages:
            return
        currentTitle = self.tabController.currentPageTitle
        
        newTitle = ShowDialog(currentTitle, True)
        if newTitle is not None:
            self.tabController.currentPageTit
""" AMQP as Broker """
BROKER_URL = 'amqp://guest:guest@localhost:5672//'
BROKER_CONNECTION_RETRY = True
""" Broker Heartbeat Settings => Time(sec.) = Broker_Heartbeat(sec.)/Rate """
BROKER_HEARTBEAT = 4
BROKER_HEARTBEAT_CHECKRATE = 2
""" REDIS as backend to store task state and results """
CELERY_RESULT_BACKEND = 'redis://localhost/0'
CELERY_RESULT_EXCHANGE = 'thugresults'
CELERY_RESULT_EXCHANGE_TYPE = 'direct'
""" Msg will not be lost if broker restarts/shutdown """
CELERY_RESULT_PERSISTENT = True
""" Time after which task results would delete """
CELERY_TASK_RESULT_EXPIRES = None		
""" Default Queue Configuration """
CELERY_DEFAULT_QUEUE = 'generic'
CELERY_DEFAULT_EXCHANGE = 'generic'
CELERY_DEFAULT_EXCHANGE_TYPE = 'direct'
CELERY_DEFAULT_BINDING = 'generic'
CELERY_DEFAULT_ROUTING_KEY = 'generic'
CELERY_DEFAULT_DELIVERY_MODE = 'persistent'
""" ACKS_LATE means that tasks msgs will be acknowledged after task has been
    executed and then only it will be deleted from queue.
"""
CELERY
@pytest.fixture
def controller():
    return HeatController()
def test_create_basic_heat_controller(controller):
    assert controller._boiler is not None
def test_pass_boiler_as_param_on_init():
    my_boiler = Boiler()
    ctrl = HeatController(boiler=my_boiler)
    assert ctrl._boiler is my_boiler
def test_controller_can_turn_on_and_off_the_boiler(controller):
    assert Boiler.OFF == controller.get_boiler_status()
    controller.turn_boiler_on()
    assert Boiler.ON == controller.get_boiler_status()
    controller.turn_boiler_off()
    assert Boiler.OFF == controller.get_boiler_status()
def test_controller_starts_with_no_trv_units_attached(controller):
    assert len(controller.trv_units) == 0
def test_controller_add_trv(controller):
    controller.add_trv(TRV())
    assert 1 == len(controller.trv_units)
def test_controller_remove_trv(controller):
    u1 = TRV()
    u2 = TRV()
    u3 = TRV()
    controller.add_trv(u1)
    controller.add_trv(u2)
    controller.add_trv(u3)
    contro

    assert set([u1, u3]) == controller.trv_units
def test_controller_cannot_add_the_same_trv_unit_twice(controller):
    unit = TRV()
    assert controller.trv_units == set()
    controller.add_trv(unit)
    controller.add_trv(unit)
    assert controller.trv_units == set([unit])
def test_trv_without_name_gets_name_assigned_when_added_to_controller(
        controller):
    trv = TRV()
    assert trv.name is None
    controller.add_trv(trv)
    trv_2 = TRV('Living room')
    controller.add_trv(trv_2)
    assert trv_2.name == 'Living room'
    trv_3 = TRV()
    controller.add_trv(trv_3)
def test_controller_can_retrieve_a_trv_unit_by_its_name(controller):
    trv_1 = TRV('TRV One')
    trv_2 = TRV('TRV Two')
    trv_3 = TRV('TRV Three')
    controller.add_trv(trv_1)
    controller.add_trv(trv_2)
    controller.add_trv(trv_3)
    returned_trv_2 = controller.get_trv('TRV Two')
    assert returned_trv_2 is trv_2
def test_controller_does_not_mess_up_with_trv_sequence_ids(controller):
    trv
api_index = [
    {
        'view': 'cast_api',
        'model': Cast
    },
    {
        'view': 'user_api',
        'model': LocastUser
    },
    {
        'view': 'collection_api',
        'model': Collection
    },
    {
        'description': u'Search',
        'view': 'search_api'
    },
    {
        'description': u'Geo features querying',
        'view': 'geofeatures_api'
    }
urlpatterns = patterns('traveler.api',
    url(r'^/?$', 'APIIndex', {'index': api_index}, name='api_index'),
urlpatterns += patterns('traveler.api.cast',
    url(r'^cast/(?P<cast_id>\d+)/media/(?P<media_id>\d+)/$', 'CastAPI', name='cast_media_api_single', kwargs={'method':'media_content'}),
    url(r'^cast/(?P<cast_id>\d+)/media/$', 'CastAPI', name='cast_media_api', kwargs={'method':'media'}),
    url(r'^cast/(?P<cast_id>\d+)/comments/(?P<comment_id>\d+)/flag/$', 'CastAPI', name='cast_comments_api_single', kwargs={'method':'comments_flag'}),
    url(r'^cast/(?P<cast_id>\d+)/comments/(?P<comment_id>\d+

    url(r'^cast/(?P<cast_id>\d+)/comments/$', 'CastAPI', name='cast_comments_api', kwargs={'method':'comments'}),
    url(r'^cast/(?P<cast_id>\d+)/favorite/$', 'CastAPI', kwargs={'method':'favorite'}),
    url(r'^cast/(?P<cast_id>\d+)/flag/$', 'CastAPI', kwargs={'method':'flag'}),
    url(r'^cast/(?P<cast_id>\d+)/geofeature/$', 'CastAPI', kwargs={'method':'geofeature'}),
    url(r'^cast/(?P<cast_id>\d+)(?P<format>\.\w*)/$', 'CastAPI'),
    url(r'^cast/(?P<cast_id>\d+)/$', 'CastAPI', name='cast_api_single'),
    url(r'^cast/$', 'CastAPI', name='cast_api'),
    url(r'^collection/(?P<coll_id>\d+)/cast/(?P<cast_id>\d+)/$', 'CastAPI', name='collection_api_cast_single'),
    url(r'^collection/(?P<coll_id>\d+)/cast/$', 'CastAPI', name='collection_cast_api'),
urlpatterns += patterns('traveler.api.user',
    url(r'^user/(?P<user_id>\d+)/$', 'UserAPI', name='user_api_single'),
    url(r'^user/me/?$', 'UserAPI', kwargs={'method':'me'}),
    url(r'^user/$', 'UserAPI', name='user_api'),
urlpattern
QUEUE_FORMAT = """
. %(name)s -> exchange:%(exchange)s (%(exchange_type)s) \
binding:%(binding_key)s
"""
BROKER_FORMAT = "%(carrot_backend)s://%(userid)s@%(host)s%(port)s%(vhost)s"
TIME_UNITS = (("day", 60 * 60 * 24, lambda n: int(math.ceil(n))),
              ("hour", 60 * 60, lambda n: int(math.ceil(n))),
              ("minute", 60, lambda n: int(math.ceil(n))),
              ("second", 1, lambda n: "%.2f" % n))
def humanize_seconds(secs, prefix=""):
    """Show seconds in human form, e.g. 60 is "1 minute", 7200 is "2
    hours"."""
    for unit, divider, formatter in TIME_UNITS:
        if secs >= divider:
            w = secs / divider
            punit = w > 1 and unit+"s" or unit
            return "%s%s %s" % (prefix, formatter(w), punit)
    return "now"
def textindent(t, indent=0):
    """Indent text."""
    return "\n".join(" " * indent + p for p in t.split("\n"))
def format_queues(queues, indent=0):
    """Format routing table into string for log dumps."""
    format = lamb

    info = "\n".join(format(name=name, **config)
                            for name, config in queues.items())
    return textindent(info, indent=indent)
def get_broker_info():
    broker_connection = establish_connection()
    carrot_backend = broker_connection.backend_cls
    if carrot_backend and not isinstance(carrot_backend, str):
        carrot_backend = carrot_backend.__name__
    carrot_backend = carrot_backend or "amqp"
    port = broker_connection.port or \
                broker_connection.get_backend_cls().default_port
    port = port and ":%s" % port or ""
    vhost = broker_connection.virtual_host
    if not vhost.startswith("/"):
        vhost = "/" + vhost
    return {"carrot_backend": carrot_backend,
            "userid": broker_connection.userid,
            "host": broker_connection.hostname,
            "port": port,
            "vhost": vhost}
def format_broker_info(info=None):
    """Get message broker connection info string for log dumps."""
    return BROKER_
"""Base implementation classes.
The public-facing ``Events`` serves as the base class for an event interface;
its public attributes represent different kinds of events.   These attributes
are mirrored onto a ``_Dispatch`` class, which serves as a container for
collections of listener functions.   These collections are represented both
at the class level of a particular ``_Dispatch`` class as well as within
instances of ``_Dispatch``.
"""
    _EmptyListener, _DispatchDescriptor
_registrars = util.defaultdict(list)
def _is_event_name(name):
    return not name.startswith('_') and name != 'dispatch'
class _UnpickleDispatch(object):
    """Serializable callable that re-generates an instance of
    :class:`_Dispatch` given a particular :class:`.Events` subclass.
    """
    def __call__(self, _parent_cls):
        for cls in _parent_cls.__mro__:
            if 'dispatch' in cls.__dict__:
                return cls.__dict__['dispatch'].dispatch_cls(_parent_cls)
        else:
            rais

class _Dispatch(object):
    """Mirror the event listening definitions of an Events class with
    listener collections.
    Classes which define a "dispatch" member will return a
    non-instantiated :class:`._Dispatch` subclass when the member
    is accessed at the class level.  When the "dispatch" member is
    accessed at the instance level of its owner, an instance
    of the :class:`._Dispatch` class is returned.
    A :class:`._Dispatch` class is generated for each :class:`.Events`
    class defined, by the :func:`._create_dispatcher_class` function.
    The original :class:`.Events` classes remain untouched.
    This decouples the construction of :class:`.Events` subclasses from
    the implementation used by the event internals, and allows
    inspecting tools like Sphinx to work in an unsurprising
    way against the public API.
    """
    _events = None
    """reference the :class:`.Events` class which this
        :class:`._Dispatch` is created for."""
    def __init__(s

        self._parent_cls = _parent_cls
    @util.classproperty
    def _listen(cls):
        return cls._events._listen
    def _join(self, other):
        """Create a 'join' of this :class:`._Dispatch` and another.
        This new dispatcher will dispatch events to both
        :class:`._Dispatch` objects.
        """
        if '_joined_dispatch_cls' not in self.__class__.__dict__:
            cls = type(
                "Joined%s" % self.__class__.__name__,
                (_JoinedDispatcher, self.__class__), {}
            )
            for ls in _event_descriptors(self):
                setattr(cls, ls.name, _JoinedDispatchDescriptor(ls.name))
            self.__class__._joined_dispatch_cls = cls
        return self._joined_dispatch_cls(self, other)
    def __reduce__(self):
        return _UnpickleDispatch(), (self._parent_cls, )
    def _update(self, other, only_propagate=True):
        """Populate from the listeners in another :class:`_Dispatch`
            object."""
       
"""Handle save prompt and character saving."""
def save(character):
    """Dump character data into external file."""
    save_file = open('save/arena.save', 'w')
    temp = character.next
    character.next = None
    pickle.dump(character, save_file)
    character.next = temp
    save_file.close()
def prompt(character):
    """Prompt for multiple save options."""
    clear()
    print color("""
  ____
 / ___|  __ ___   _____
 \___ \ / _` \ \ / / _ \\
  ___) | (_| |\ V /  __/
 |____/ \__,_| \_/ \___|
""", "pink")
    print_bar(0)
    print "Name:  %s" % character.name
    character.print_useful(True)
    save_options = [make_option('Save', 'S'),
                    make_option('Save and Exit', 'E'),
                    make_option('Quit', 'Q'),
                    make_option('Return', 'R')]
    print nav_menu(save_options, short=True)
    val = get_val("qsre")
    if "s" == val:
        save(character)
        character.move("town")
    elif "e" == val:
        save(character)
      
__author__ = 'Administrator'
class CheckService(object):
    checkStatue = {}
    def __init__(self):
        self.dao = BichonDao()
    def processCheck(self, hostKey, processName):
        broker = BrokerService.getBroker(hostKey)
        return broker.processCheck(processName)
    def portCheck(self, hostKey, port):
        broker = BrokerService.getBroker(hostKey)
        return broker.portCheck(port)
    def urlCheck(self, host, port, resource):
        return LocalCheck.httpCheck(host, port, resource=resource)
    @lock
    def check(self, host, name, port):
        '''mysql check'''
        psData = self.processCheck(host.encode("utf-8"), name.encode("utf-8"))
        portData = self.portCheck(host.encode("utf-8"), port.encode("utf-8"))
        if (len(portData) >=1) and (len(psData) >= 4):
            return True
        else:
            return False
    def checkInstalled(self,hostKey,softName):
        broker = BrokerService.getBroker(hostKey)
        data=broker.execCmd("se

        if "unrecognized" in data[1]:
            d=broker.execCmd("which "+softName)
            if d[0]!=0:
                return False
            else:
                return True
        else:
            return True
    def mysqlCheck(self, host, name="mysql", port="3306"):
        '''mysql check'''
        return self.check(host, name, port)
    def nginxCheck(self, host, port, name="nginx"):
        '''mysql check'''
        return self.check(host, name, port)
    def checkSoftInstallStatus(self,hostKey):
        softs=self.dao.selectAllSoft()[0]
        data=[]
        for s in softs:
            d={}
            statue=self.checkInstalled(hostKey,s["serviceName"])
            d["name"]=s["serviceName"]
            d["statue"]=statue
            data.append(d)
        return data
    def checkServiceRunning(self,hostKey,serviceName):
        broker = BrokerService.getBroker(hostKey)
        data=broker.execCmd("service  "+serviceName+"  status")
        if "unrecognized" in 
"""
GarfieltBlog(webpy) is a light weight blog system base on web.py.It is similar 
to WordPress that provides commonly functions and featurs of a blog system.
Homepage and details: http://www.iscsky.net/
Copyright (c) 2012, Garfielt <liuwt123@gmail.com>.
License: MIT (see LICENSE.txt for details)
"""
web.config.debug = Setting.is_debug
urls = (
    '/', 'Index',
    '/page/(\d+)', 'Index',
    '/category/(.+)/page/(\d+)', 'Category',
    '/category/(.+)', 'Category',
    '/tag/(.+)/page/(\d+)', 'Tag',
    '/tag/(.+)', 'Tag',
    '/blog/(.+).html', 'Post',
    '/comment/(\d+)', 'Comment',
    '/search', 'Search',
    '/rss', 'Rss',
    '/sitemap.xml', 'Sitemap',
    '/trans/(.+)/(\d+)', 'Trans',
    '/favicon.ico', 'Favicon',
    '/valiimage', 'Valiimage',
    '/install', 'Install',
    '/install/(\d+)', 'Install',
    Setting.login_url, 'Login',
    '/manage/main/(\w+)', 'Manage',
    '/manage/postlist', 'ManagePostlist',
    '/manage/postlist/(\w+)/(\d+)', 'ManagePostlist',
    '/man

    '/manage/post/(\d+)', 'ManagePost',
    '/manage/category', 'ManageCategory',
    '/manage/category/(\w+)/(\d+)', 'ManageCategory',
    '/manage/tags', 'ManageTags',
    '/manage/tags/edit/(\d+)', 'ManageTags',
    '/manage/data', 'ManageData',
    '/manage/attachment', 'ManageAttachment',
    '/manage/comment/(\w+)/(\d+)', 'ManageComment',
    '/manage/comment', 'ManageComment',
    '/manage/links', 'ManageLinks',
    '/manage/links/(\w+)/(\d+)', 'ManageLinks',
    '/manage/setting', 'ManageSetting',
    '/manage/upload', 'ManageUpload',
    '/manage/files', 'ManageFiles',
    '/manage/user', 'ManageUser',
    '/manage/logout', 'ManageLogout',
    '/manage/result/(.+)', 'ManageResult'
app = web.application(urls, globals())
if Setting.runtime == "SAE":
    application = sae.create_wsgi_app(app.wsgifunc())
elif Setting.runtime == "BAE":
    application = WSGIApplication(app.wsgifunc())
else:
    pass
web.config.session_parameters['cookie_name'] = 'Garfitle_session'
web.config.sessi
def deploy():
    start_time = time.time()
    client = Client(config.endpoint, config.username, config.password)
    env = client.get_environment(config.organization, 'Openshift')
    
    try:
      env.settings().create("domain", config.domain)
    except:
      print "Did not reconfigure domain since a setting was already defined. Run teardown if you wanted to cleanup first"
    try:
      broker = env.get_host('Openshift Broker')
    except EntityNotFoundException:
      broker = create_host(env, 'Openshift Broker', config.platform, config.distribution, [])
      print "Deploying Openshift Broker"
      broker.provision()
      broker.refresh()
    if broker.state == "PROVISIONING":
      print "Waiting for Broker to be deployed"
      broker.wait_for_state('READY', config.time_out)
      if broker.state == "PROVISIONING":
          raise Exception("Timed out waiting for host to be provisioned.")
    broker_ip = broker.get_instance().wait_for_property("ip.eth0", config.time_out)
 

        raise Exception("Failed to retrieve the host IP")
    print "Installing the Bind server"
    broker.install("openshift-bind-server", {"dns_records": [{"host":"broker", "type": "A", "ttl": "180", "target": broker_ip}]})
    track_changes(broker)
    env.settings().create("nameserver", broker_ip)
    print "Reconfiguring network"
    broker.install("openshift-dhcp-dns-config", {"hostname": "broker"})
    track_changes(broker)
    
    print "Installing MongoDB"
    mongo_pw = generate_id(12)
    broker.install("openshift-mongodb", {"smallfiles": True, "secure": True, "users": [{"database": "openshift", "username": "openshift", "password": mongo_pw}]})
    track_changes(broker)
    print "Installing RabbitMQ"
    broker.install("openshift-rabbitmq-server", {})
    track_changes(broker)
    print "Installing MCollective Client"
    broker.install("openshift-mcollective-client", {})
    track_changes(broker)
    print "Installing Openshift Broker"
    broker.install("openshift-brok
repository = load_repository("./repository/")
targets = repository.get_filepaths_in_directory("./repository/targets/1024/",
                                                recursive_walk=True, followlinks=True)
repository.release.add_key(pubKey)
repository.timestamp.add_key(pubKey)
repository.release.load_signing_key(privKey)
repository.timestamp.load_signing_key(privKey)
class threadTargets(threading.Thread):
    def __init__(self, target, privKey):
        threading.Thread.__init__(self)
        self.target = target
        self.privKey = privKey
    def run(self):
        t = hashlib.sha256()
            
        s = self.target[0:21] + self.target[26:]
            
        t.update(s)
        y = t.hexdigest()
        num = int(y[0:3], 16)
        mod = num % 4
        num -= mod
        y = hex(num)
        y = y[2:]
        if len(y) == 1:
            y = "00" + y
        elif len(y) == 2:
            y = "0" + y
            
        tmp = getattr(repository.targets.unclaimed, y)
def parse_index(json_dict, store_location, python_version=PY_VER):
    """
    Parse the given json index data and iterate package instance over its
    content.
    Parameters
    ----------
    json_dict: dict
        Parsed legacy json index
    store_location: str
        A label describing where the index is coming from
    python_version: str
        The major.minor string describing the python version. This generator
        will iterate over every package where the python attribute is `null` or
        equal to this string. If python_version == "*", then every package is
        iterated over.
    """
    fake_repository_info = OldstyleRepositoryInfo(store_location)
    return enstaller.repository.parse_index(json_dict,
                                            fake_repository_info,
                                            python_version)
def repository_factory(session, indices):
    """
    Create a repository from legacy indices.
    Parameters
    ----------
    session
__author__ = 'kohn'
class TestPipeline(unittest.TestCase):
    def test_execute(self):
        sqlite_in_memory = SQLiteConfiguration("")
        data_controller = DataController(sqlite_in_memory)
        data_controller.run_schema()
        crawler = FileCrawler()
        crawl_controller = CrawlController(crawler, "d0b7f41f-ad37-3b47-ab70-9feac35557cc")
        analysis_controller = AnalysisController()
        pipeline_controller = PipelineController(
            data_controller=data_controller,
            crawl_controller=crawl_controller,
            analysis_controller=analysis_controller
        )
        pipeline_controller.execute()
        pipeline_controller.execute()
        pipeline_controller.execute()
def sample_pipeline(app_id=None, app_secret=None):
    sqlite_in_memory = SQLiteConfiguration("")
    data_controller = DataController(sqlite_in_memory)
    data_controller.run_schema()
    crawler = None
    if app_id is None and app_secret is None:
        crawler = File

    else:
        crawler = SDKCrawler(app_id=app_id, app_secret=app_secret)
    crawl_controller = CrawlController(crawler, "d0b7f41f-ad37-3b47-ab70-9feac35557cc")
    analysis_controller = AnalysisController()
    pipeline_controller = PipelineController(
        data_controller=data_controller,
        crawl_controller=crawl_controller,
        analysis_controller=analysis_controller
    )
    pipeline_controller.execute()
    rows = data_controller.engine.execute("SELECT * FROM profile").fetchall()
    print()
    print("Profiles:")
    for row in rows:
        print(row)
    rows = data_controller.engine.execute("SELECT * FROM cache_profile").fetchall()
    print()
    print("Cache profiles:")
    for row in rows:
        print(row)
    rows = data_controller.engine.execute("SELECT id, owner_mendeley_id, title, authors, tags FROM document").fetchall()
    print()
    print("Documents:")
    for row in rows:
        print(row)
    rows = data_controller.engine.execute("SELECT * FR
class AdminApi(wsgi.Router):
    """WSGI entry point for admin Keystone API requests."""
    def __init__(self, options):
        self.options = options
        mapper = routes.Mapper()
        db.configure_backends(options)
        auth_controller = AuthController(options)
        mapper.connect("/tokens", controller=auth_controller,
                       action="authenticate",
                       conditions=dict(method=["POST"]))
        mapper.connect("/tokens/{token_id}", controller=auth_controller,
                        action="validate_token",
                        conditions=dict(method=["GET"]))
        mapper.connect("/tokens/{token_id}", controller=auth_controller,
                        action="check_token",
                        conditions=dict(method=["HEAD"]))
        mapper.connect("/tokens/{token_id}", controller=auth_controller,
                        action="delete_token",
                        conditions=dict(method=["DELETE"]))
        mapper.connect("

                        controller=auth_controller,
                        action="endpoints",
                        conditions=dict(method=["GET"]))
        tenant_controller = TenantController(options)
        mapper.connect("/tenants", controller=tenant_controller,
                    action="get_tenants", conditions=dict(method=["GET"]))
        mapper.connect("/tenants/{tenant_id}",
                    controller=tenant_controller,
                    action="get_tenant", conditions=dict(method=["GET"]))
        roles_controller = RolesController(options)
        mapper.connect("/tenants/{tenant_id}/users/{user_id}/roles",
            controller=roles_controller, action="get_user_roles",
            conditions=dict(method=["GET"]))
        user_controller = UserController(options)
        mapper.connect("/users/{user_id}",
                    controller=user_controller,
                    action="get_user",
                    conditions=dict(method=["GET"]))
        mapper.c

            controller=roles_controller, action="get_user_roles",
            conditions=dict(method=["GET"]))
        version_controller = VersionController(options)
        mapper.connect("/", controller=version_controller,
                    action="get_version_info", file="admin/version",
                    conditions=dict(method=["GET"]))
        extensions_controller = ExtensionsController(options)
        mapper.connect("/extensions",
                        controller=extensions_controller,
                        action="get_extensions_info",
                        path="content/admin/extensions",
                        conditions=dict(method=["GET"]))
        static_files_controller = StaticFilesController(options)
        mapper.connect("/identityadminguide.pdf",
                    controller=static_files_controller,
                    action="get_pdf_contract",
                    root="content/admin/", pdf="identityadminguide.pdf",
                    conditions=dic
light = Light()
ceiling_fan = CeilingFan()
garage_door = GarageDoor()
stereo = Stereo()
remote_controller = RemoteController()
remote_controller.set_command(0,
                              LightOnCommand(light),
                              LightOffCommand(light))
remote_controller.set_command(1,
                              CeilingFanLowCommand(ceiling_fan),
                              CeilingFanOffCommand(ceiling_fan))
remote_controller.set_command(2,
                              CeilingFanMediumCommand(ceiling_fan),
                              CeilingFanOffCommand(ceiling_fan))
remote_controller.set_command(3,
                              CeilingFanHighCommand(ceiling_fan),
                              CeilingFanHighCommand(ceiling_fan))
remote_controller.set_command(4,
                              GarageDoorUpCommand(garage_door),
                              GarageDoorDownCommand(garage_door))
remote_controller.set_command(5,
                              StereoOnComma
class BrokerMetadata(base.CueObject):
    dbapi = db_api.get_instance()
    fields = {
        'id': obj_utils.str_or_none,
        'broker_id': obj_utils.str_or_none,
        'key': obj_utils.str_or_none,
        'value': obj_utils.str_or_none,
        'deleted': obj_utils.bool_or_none,
        'created_at': obj_utils.datetime_or_str_or_none,
        'updated_at': obj_utils.datetime_or_str_or_none,
        'deleted_at': obj_utils.datetime_or_str_or_none,
    }
    @staticmethod
    def _from_db_object(broker_metadata, db_broker_metadata):
        """Convert a database object to a universal brokerMetadata object."""
        for field in BrokerMetadata.fields:
            broker_metadata[field] = db_broker_metadata[field]
        return broker_metadata
    def create_broker_metadata(self, context):
        """Creates a new broker metadata.
       :param context: request context object
       """
        metadata_values = self.as_dict()
        db_broker = self.dbapi.create_broker_metada

        self._from_db_object(self, db_broker)
    def delete_broker_metadata(self, context):
        """Deletes a BrokerMetadata object for specified broker_id.
        :param context: request context object
        """
        self.dbapi.delete_broker_metadata(context, self.id)
    @classmethod
    def get_broker_metadata_by_broker_id(cls, context, broker_id):
        """Returns a list of BrokerMetadata objects for specified broker_id.
        :param context: request context object
        :param broker_id: broker id
        :returns: a list of :class:'BrokerMetadata' object
        """
        db_broker_metadata = cls.dbapi.get_broker_metadata_by_broker_id(
            context, broker_id)
        return [BrokerMetadata._from_db_object(BrokerMetadata(), obj)
                for obj in db_broker_metadata]
    @classmethod
    def get_image_id_by_broker_name(cls, context, broker_name):
        """Returns a image_id for the broker
        :param context: request context object
        :
class MdsModel(GridModel):
    def __init__(self, 
            registry_type=Registry,
            broker_means=dists.normal(0.05),
            **kw):
        super(MdsModel, self).__init__(**kw)
        regions = self.graph.regions
        self.regions = [i for i in range(regions[0]*regions[1])]
        self.brokers = dict()
        for r in self.regions:
            node = self.random_region_node(r)
            node.server.service_time = self.service_dist(broker_means())
            broker = Broker(
                    r, 
                    node, 
                    registry_type(),
                    60,
                    self.brokers)
            
            for node in self.graph.nodes_in_region(r):
                state = ResourceState(node.resource_agent, node.resource.free)
                broker.registry.update_state(state)
            self.brokers[r] = broker
        for node in self.graph.nodes_iter():
            node.broker = self.brokers[node.region]
            no

            self.graph.make_link(node, node.broker.node)
        for i, broker in enumerate(self.brokers.itervalues()):
            for other in self.brokers.values()[i:]:
                self.graph.make_link(broker.node, other.node)
        self.mons["broker_util"] = Monitor("broker_util")
        self.mons["broker_queue"] = Monitor("broker_queue")
    def new_process(self):
        node = self.random_node()
        job = self.new_job()
        agent = MdsJobAgent(job, 20, 20, 5)
        agent.start_on(node)
    def start(self, *a, **kw):
        for n in self.graph.nodes_iter():
            n.resource_agent.start()
        for b in self.brokers.itervalues():
            b.start()
        super(MdsModel, self).start(*a, **kw)
    def calc_results(self):
        return record.calc_results(self)
        
    def collect_stats(self):
        super(MdsModel, self).collect_stats()
        self.mons["broker_util"].observe(stats.mean_broker_server_util(self))
        self.mons["broker_queue
class MemeApiTest(unittest.TestCase):
    
    def test_should_get_meme_by_name(self):
        meme_repository_mock = Mock()
        when(meme_repository_mock).get('some_name').thenReturn('ok')
        
        Meme.meme_repository = meme_repository_mock
        
        assert Meme.get(name='some_name') == 'ok'
    
    def test_should_search_for_memes(self):
        meme_repository_mock = Mock()
        when(meme_repository_mock).search('a query', 10).thenReturn(['search_result1'])
        when(meme_repository_mock).search('a query', 40).thenReturn(['search_result2'])
        Meme.meme_repository = meme_repository_mock
        assert Meme.search('a query') == ['search_result1']
        assert Meme.search('a query', count=40) == ['search_result2']
class MemePostsApiTest(unittest.TestCase):
    
    def test_should_get_one_post(self):
        post_repository_mock = Mock()
        when(post_repository_mock).get('123', '456').thenReturn('post')
        
        Meme.Posts.post_repository

        assert Meme.Posts.get(owner_guid='123', pubid='456') == 'post'
    def test_should_get_popular_posts(self):
        post_repository_mock = Mock()
        when(post_repository_mock).popular('en', 10).thenReturn(['popular_posts1'])
        when(post_repository_mock).popular('pt', 10).thenReturn(['popular_posts2'])
        when(post_repository_mock).popular('en', 33).thenReturn(['popular_posts3'])
        when(post_repository_mock).popular('pt', 33).thenReturn(['popular_posts4'])
        
        Meme.Posts.post_repository = post_repository_mock
        
        assert Meme.Posts.popular() == ['popular_posts1']
        assert Meme.Posts.popular(locale='pt') == ['popular_posts2']
        assert Meme.Posts.popular(count=33) == ['popular_posts3']
        assert Meme.Posts.popular(locale='pt', count=33) == ['popular_posts4']
        
    def test_should_search_for_posts(self):
        post_repository_mock = Mock()
        when(post_repository_mock).search('a query', 10).thenReturn(['
"""
(Description)
Created on Nov 6, 2014
"""
__author__ = 'Weber Jean-Paul'
__email__ = 'jean-paul.weber@govcert.etat.lu'
__copyright__ = 'Copyright 2013-2014, GOVCERT Luxembourg'
__license__ = 'GPL v3+'
class IndicatorTypeBroker(BrokerBase):
  def get_broker_class(self):
    """
    overrides BrokerBase.get_broker_class
    """
    return IndicatorType
  def get_type_by_name(self, name):
    try:
      for key, value in IndicatorType.get_dictionary().iteritems():
        if value == name:
          type_ = IndicatorType()
          type_.type = key
          return type_
      raise NoResultFound
    except NoResultFound:
      raise NothingFoundException('Nothing found with ID :{0} in {1}'.format(name, self.__class__.__name__))
    except MultipleResultsFound:
      raise TooManyResultsFoundException('Too many results found for ID :{0}'.format(name))
    except SQLAlchemyError as error:
      raise BrokerException(error)
class AttributeTypeBroker(BrokerBase):
  def get_broker_class(s
class EveApiManager():
    def __init__(self):
        pass
    @staticmethod
    def get_characters_from_api(api_id, api_key):
        chars = []
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            chars = account.characters()
        except evelink.api.APIError as error:
            print error
        return chars
    @staticmethod
    def get_corporation_ticker_from_id(corp_id):
        ticker = ""
        try:
            api = evelink.api.API()
            corp = evelink.corp.Corp(api)
            response = corp.corporation_sheet(corp_id)
            ticker = response[0]['ticker']
        except evelink.api.APIError as error:
            print error
        return ticker
    @staticmethod
    def get_alliance_information(alliance_id):
        results = {}
        try:
            api = evelink.api.API()
            eve = evelink.eve.EVE(api=api)
            alliance = eve.alliances()
       

        except evelink.api.APIError as error:
            print error
        return results
    @staticmethod
    def get_corporation_information(corp_id, api_id = None, api_key=None):
        results = {}
        try:
            api = evelink.api.API(api_key=(settings.ALLIANCE_EXEC_CORP_ID, settings.ALLIANCE_EXEC_CORP_VCODE))
            corp = evelink.corp.Corp(api=api)
            corpinfo = corp.corporation_sheet(corp_id)
            results = corpinfo[0]
        except evelink.api.APIError as error:
            print error
        return results
    @staticmethod
    def check_api_is_type_account(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return info[0]['type'] == "account"
        except evelink.api.APIError as error:
            print error
        return False
    @staticmethod
    def check_api_is_full(api_id, api_key):
  

            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return (info[0]['access_mask'] == 268435455) or (info[0]['access_mask'] == 268382671)
        except evelink.api.APIError as error:
            print error
        return False
    @staticmethod
    def get_api_info(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return info
        except evelink.api.APIError as error:
            print error
        return False
    @staticmethod
    def api_key_is_valid(api_id, api_key):
        try:
            api = evelink.api.API(api_key=(api_id, api_key))
            account = evelink.account.Account(api=api)
            info = account.key_info()
            return True
        except evelink.api.APIError as error:
            return 
class Changeset(Base):
    def __get__(self, repository_id=None, revision=None, is_diff=False, page=1, per_page=10):
        '''
        GET /api/changesets.json
        GET /api/changesets/repository.json?repository_id={REPOSITORY_ID}
        GET /api/changesets/{REVISION}.json?repository_id={REPOSITORY_ID}
        GET /api/changesets/{REVISION}/differences.json?repository_id={REPOSITORY_ID}
        Parameter {REVISION} uses revision number instead unique ID
        '''
        if repository_id is None:
            url = 'changesets.json?page=' + str(page) + '&per_page=' + str(per_page)
        elif revision is None:
            url = 'changesets/repository.json?repository_id=' + str(repository_id) + '&page=' + str(page) + '&per_page=' + str(per_page)
        elif is_diff is False:
            url = 'changesets/' + revision + '.json?repository_id=' + str(repository_id)
        else:
            url = 'changesets/' + revision + '/differences.json?repository_id=' + str(repository_id)
  
c_p = os.path.dirname(os.getcwd())+"/"
'''------------一些必要设置的选项-----------------'''
filename  = c_p+"model/im_info/10.19_33000/trainset.train"
indexs = [6,7,8,9,10]
stopword_filename = c_p+"model/im_info/10.19_33000/stopwords.txt"
'''------------一些可选设置的选项-----------------'''
model_name="im.model"
train_name = "svm.train"
param_name = "svm.param"
delete=True
str_splitTag="^"
tc_splitTag="\t"
'''------------------------分步训练时需要的设置的选项'''
dic_path =save_main_path+"model/" +dic_name
sample_save_path = save_main_path+"temp/"+"svm.train"
svm_model_save_path = save_main_path+"model/" +model_name
svm_param='-c 2.82842712475 -g 1.0' 
test_path = sample_save_path 
for_lsa_train_save_path =  save_main_path+"temp/" +"for_lsa.train"
k = 500
lsa_train_save_path =  save_main_path+"temp/"  +"lsa_"+str(k)+".train"
lsa_save_path = save_main_path+"temp/"  + "lsa_"+str(k)
lsa_svm_param  = '-c 2.0 -g 1.0'
lsa_svm_model_save_path  = save_main_path + "LSA_title_content"+str(k)+".model"
extra_filename = save_ma

print "欢迎使用旺旺聊天欺诈监控系统，LSA模型训练系统"
choice = int(raw_input("0为自动生成模型，1为构造SVM训练的样本； 2为训练模型;3为LSA模型生成训练文本格式；4为构造LSA模型；5为训练LSA生成的模型；6为用原模型计算内容得分提取其他特征;7为向原模型中增加原先误判的样本；7为向LSA模型中增加原先误判样本。-1为退出模型"))
while choice!=-1:
    if choice==0:
        ctm_train(filename,indexs,save_main_path,stopword_filename)
    if choice==1:
        cons_train_sample_for_cla(filename,indexs,dic_path,sample_save_path,delete,str_splitTag)
    if choice==2:
      m=ctm_train_model(sample_save_path,svm_param,svm_model_save_path) 
    if choice==3:
        save_train_for_lsa(test_path,svm_model_save_path,for_lsa_train_save_path)
    if choice==4:
        M = len(read_dic(dic_path))
        ctm_lsa(M,threhold,k,for_lsa_train_save_path,lsa_train_save_path,lsa_save_path)
    if choice ==5:
        ctm_train_model(lsa_train_save_path,lsa_svm_param,lsa_svm_model_save_path)
    if choice ==6:
      add_sample_to_model(extra_filename,indexs,dic_path,sample_save_path,delete,str_splitTag)  
    choice = int(raw_input("0为自动生成模型，1
'''
Created on 29/09/2010
@author: rodrigo
'''
class MainWindow(QMainWindow):
    log = logging.getLogger(__name__)
    trade_delegates = {1:DateDelegate(), 2:OperationDelegate()}
    def __init__(self, parent=None, flags=Qt.Widget):
        super(self.__class__, self).__init__(parent, flags)
        ui = Ui_main()
        self.ui = ui
        ui.setupUi(self)
        ui.operation.setModel(OperationListModel())
        ui.trade_list.setModel(TradeModel())
        for key in self.trade_delegates.keys():
            ui.trade_list.setItemDelegateForColumn(key, self.trade_delegates[key])
        ui.broker.setModel(BrokerModel())
        ui.broker.setModelColumn(0)
        ui.broker.model().setRows(Broker.query.all())
        ui.date.setDate(date.today())
        ui.month.setDate(date.today())
        ui.trade_list.horizontalHeader().setStretchLastSection(True)
    def on_month_dateChanged(self, date):
        self.load_trades()
    @QtCore.pyqtSlot()
    def on_add_clicked(self):
        u
LONG_DESCRIPTION = open('README.rst', 'r').read()
CLASSIFIERS = [
    'Development Status :: 3 - Alpha',
    'Intended Audience :: Developers',
    'License :: OSI Approved :: GNU General Public License (GPL)',
    'Natural Language :: English',
    'Operating System :: OS Independent',
    'Programming Language :: Python',
    'Topic :: Software Development :: Libraries :: Python Modules'
KEYWORDS = 'EVE Online CCP Django API'
setup(name='django-eve_api',
      version=VERSION,
      description="A wrapper for django-eve around EVE Online's data API.",
      long_description=LONG_DESCRIPTION,
      author='Gregory Taylor',
      author_email='snagglepants@gmail.com',
      url='https://github.com/gtaylor/django-eve-api',
      packages=[
          'eve_api',
          'eve_api.api_puller', 'eve_api.api_puller.account',
          'eve_api.api_puller.character', 'eve_api.api_puller.corporation',
          'eve_api.api_puller.eve', 'eve_api.api_puller.map',
          'eve_api.api_puller.
"""
URLconf for management pages.
"""
urlpatterns = patterns(
    "moztrap.view.manage",
    url(r"^$", "views.home", name="manage"),
    url(r"^users/$",
        "users.views.users_list",
        name="manage_users"),
    url(r"^user/add/$",
        "users.views.user_add",
        name="manage_user_add"),
    url(r"^user/(?P<user_id>\d+)/$",
        "users.views.user_edit",
        name="manage_user_edit"),
    url(r"^products/$",
        "products.views.products_list",
        name="manage_products"),
    url(r"^products/_detail/(?P<product_id>\d+)/$",
        "products.views.product_details",
        name="manage_product_details"),
    url(r"^product/add/$",
        "products.views.product_add",
        name="manage_product_add"),
    url(r"^product/(?P<product_id>\d+)/$",
        "products.views.product_edit",
        name="manage_product_edit"),
    url(r"^productversions/$",
        "productversions.views.productversions_list",
        name="manage_productversions"),
    url(r"^p

        "productversions.views.productversion_details",
        name="manage_productversion_details"),
    url(r"^productversion/add/$",
        "productversions.views.productversion_add",
        name="manage_productversion_add"),
    url(r"^productversion/(?P<productversion_id>\d+)/$",
        "productversions.views.productversion_edit",
        name="manage_productversion_edit"),
    url(r"^runs/$",
        "runs.views.runs_list",
        name="manage_runs"),
    url(r"^runs/_detail/(?P<run_id>\d+)/$",
        "runs.views.run_details",
        name="manage_run_details"),
    url(r"^run/add/$",
        "runs.views.run_add",
        name="manage_run_add"),
    url(r"^run/(?P<run_id>\d+)/$",
        "runs.views.run_edit",
        name="manage_run_edit"),
    url(r"^suites/$",
        "suites.views.suites_list",
        name="manage_suites"),
    url(r"^suites/_detail/(?P<suite_id>\d+)/$",
        "suites.views.suite_details",
        name="manage_suite_details"),
    url(r"^suite/add/

        "suites.views.suite_add",
        name="manage_suite_add"),
    url(r"^suite/(?P<suite_id>\d+)/$",
        "suites.views.suite_edit",
        name="manage_suite_edit"),
    url(r"^cases/$",
        "cases.views.cases_list",
        name="manage_cases"),
    url(r"^cases/_detail/(?P<caseversion_id>\d+)/$",
        "cases.views.case_details",
        name="manage_case_details"),
    url(r"^case/(?P<case_id>\d+)/$",
        "cases.views.case_id_redirect",
        name="manage_case"),
    url(r"^case/add/$",
        "cases.views.case_add",
        name="manage_case_add"),
    url(r"^case/add/bulk/$",
        "cases.views.case_add_bulk",
        name="manage_case_add_bulk"),
    url(r"^caseversion/(?P<caseversion_id>\d+)/$",
        "cases.views.caseversion_edit",
        name="manage_caseversion_edit"),
    url(r"^caseversion/(?P<caseversion_id>\d+)/clone/$",
        "cases.views.caseversion_clone",
        name="manage_caseversion_clone"),
    url(r"^tags/$",
        "tags.views.
sys.path.insert(0, os.pardir)
sys.path.append(os.getcwd())
                        BROKER_USER, BROKER_PASSWORD
CARROT_BACKEND = "amqp"
class DictWrapper(UserDict):
    def __init__(self, data):
        self.data = data
    def __getattr__(self, key):
        try:
            return self.data[key]
        except KeyError:
            raise AttributeError("'%s' object has no attribute '%s'" % (
                self.__class__.__name__, key))
def configured_or_configure(settings, **conf):
    if settings.configured:
        for conf_name, conf_value in conf.items():
            setattr(settings, conf_name, conf_value)
    else:
        settings.configure(default_settings=DictWrapper(conf))
class TestDjangoSpecific(unittest.TestCase):
    def test_DjangoBrokerConnection(self):
        try:
        except ImportError:
            sys.stderr.write(
                "Django is not installed. \
                Not testing django specific features.\n")
            return
        configured_or_co
class RootResource(object):
    __name__ = None
    __parent__ = None
    __acl__ = [
        (Allow, Everyone, 'everyone'),
        (Allow, Authenticated, 'authenticated'),
    ]
    def __init__(self, request):
        self.engine = Engine()
        self.engine.connect_to_host(host='localhost', port=8000, is_secure=False)
        self._repos = {
            "user": UserRepository(self.engine),
            "user_credential": UserCredentialRepository(self.engine),
            "access_token": AccessTokenRepository(self.engine),
            "refresh_token": RefreshTokenRepository(self.engine),
            "client_session": ClientSessionRepository(self.engine),
            "village": VillageRepository(self.engine),
            "resident": ResidentRepository(self.engine),
            "event": EventRepository(self.engine),
            "behavior": BehaviorRepository(self.engine),
        }
        self._message_handler = MessageHandler(self)
    @property
    def repos(self):
        return 
manage_add_wsse_form = PageTemplateFile('browser/add_plugin',
                            globals(), __name__='manage_add_wsse_form' )
def manage_add_wsse_helper(dispatcher, id, title=None, REQUEST=None):
    """Add an WSSE Helper to the PluggableAuthentication Service."""
    sp = plugin.WsseHelper(id, title)
    dispatcher._setObject(sp.getId(), sp)
    if REQUEST is not None:
        REQUEST['RESPONSE'].redirect( '%s/manage_workspace'
                                      '?manage_tabs_message='
                                      'wsseHelper+added.'
                                      % dispatcher.absolute_url() )
def register_wsse_plugin():
    try:
        registerMultiPlugin(plugin.WsseHelper.meta_type)
    except RuntimeError:
        pass    
def register_wsse_plugin_class(context):
    context.registerClass(plugin.WsseHelper,
                          permission = manage_users,
                          constructors = (manage_add_wsse_form,
                               
    with_urls, WAIT)
log = logging.getLogger(__name__)
@with_urls
def test_WorkerPool_start_twice(url):
    broker = get_broker(url)
    pool = WorkerPool(broker, get_broker, workers=1)
    with start_pool(pool):
        with assert_raises(Error):
            pool.start(handle_sigterm=False)
@with_urls
def test_WorkerPool_max_worker_tasks(url):
    broker = get_broker(url)
    pool = WorkerPool(broker, WorkerPool_max_worker_tasks_init,
        workers=1, max_worker_tasks=3)
    with start_pool(pool):
        q = get_queue(url)
        res = q.results([q.func() for n in range(4)])
        assert res.wait(WAIT), repr(res)
        results = res.value
        assert isinstance(results, list), results
        eq_([r[1] for r in results], [1, 2, 3, 1])
        eq_(len(set(r[0] for r in results)), 2)
def WorkerPool_max_worker_tasks_init(url):
    broker = get_broker(url)
    calls = [0]
    @broker.expose
    def func():
        calls[0] += 1
        return (os.getpid(), calls[0])
    @broker

    def results(res):
        return res
    return broker
@with_urls
def test_WorkerPool_heartrate(url):
    broker = get_broker(url)
    pool = WorkerPool(broker, WorkerPool_heartrate_init, workers=1)
    with start_pool(pool):
        q = get_queue(url)
        res = Task(q.suicide_worker, heartrate=0.1, result_timeout=5)()
        assert res.wait(WAIT), repr(res)
        print(repr(res))
        with assert_raises(TaskExpired):
            res.value
def WorkerPool_heartrate_init(url):
    broker = get_broker(url)
    @broker.expose
    def suicide_worker():
        log.warn("it's nice to work alone")
    broker.expose(os.getpid)
    return broker
@with_urls(exclude='memory')
def test_WorkerPool_crashed_worker(url):
    broker = get_broker(url)
    pool = WorkerPool(broker, WorkerPool_crashed_worker_init, workers=1)
    with start_pool(pool):
        q = get_queue(url)
        res = q.getpid()
        assert res.wait(WAIT), repr(res)
        pid = res.value
        q.kill_worker()


        assert res.wait(WAIT), repr(res)
        assert res.value != pid, pid
def WorkerPool_crashed_worker_init(url):
    broker = get_broker(url)
    @broker.expose
    def kill_worker():
        log.warn('alone we crash')
        sys.exit()
    broker.expose(os.getpid)
    return broker
@with_urls(exclude='memory')
def test_WorkerPool_sigterm(url):
    with tempdir() as tmp:
        logpath = join(tmp, 'output.log')
        proc = run_in_subprocess(worker_pool, url,
            WorkerPool_sigterm_init, (tmp, logpath), workers=3)
        with printlog(logpath), force_kill_on_exit(proc):
            q = get_queue(url)
            q.func('text')
            eventually(reader(tmp, 'func.started'), '')
            eventually(reader(tmp, 'func.out'), 'text')
            eventually(verify_shutdown(proc), True, timeout=WAIT)
def WorkerPool_sigterm_init(url, tmp, logpath):
    process_config(logpath, 'Worker-%s' % os.getpid())
    broker = get_broker(url)
    @broker.expose
    def func(arg
log = logging.getLogger( __name__ )
category_name = 'Test 1430 Repair installed repository'
category_description = 'Test script 1430 for repairing an installed repository.'
filter_repository_name = 'filter_1430'
column_repository_name = 'column_1430'
filter_repository_description = "Galaxy's filter tool for test 1430"
column_repository_description = 'Add a value as a new column'
filter_repository_long_description = '%s: %s' % ( filter_repository_name, filter_repository_description )
column_repository_long_description = '%s: %s' % ( column_repository_name, column_repository_description )
'''
In the Tool Shed:
1) Create and populate the filter_1430 repository
2) Create and populate the column_1430 repository
3) Upload a repository_dependencies.xml file to the column_1430 repository that creates a repository dependency on the filter_1430 repository.
In Galaxy:
1) Install the column_1430 repository, making sure to check the checkbox to Handle repository dependencies so that the filter
   r

2) Uninstall the filter_1430 repository.
3) Repair the column_1430 repository.
4) Make sure the filter_1430 repository is reinstalled and the tool is loaded into the tool panel in the same section specified in step 1.
'''
class TestRepairRepository( ShedTwillTestCase ):
    '''Test repairing an installed repository.'''
    
    def test_0000_initiate_users_and_category( self ):
        """Create necessary user accounts and login as an admin user."""
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
        self.create_category( name=category_name, description=category_description )
        self.logout()
        self.login( email=common.test_user_2_email, username=commo

        test_user_2 = self.test_db_util.get_user( common.test_user_2_email )
        assert test_user_2 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_2_email
        test_user_2_private_role = self.test_db_util.get_private_role( test_user_2 )
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = self.test_db_util.get_private_role( test_user_1 )
        
    def test_0005_create_filter_repository( self ):
        '''Create and populate the filter_1430 repository.'''
        '''
        This is step 1 - Create and populate the filter_1430 repository.
        
        This repository will be depended on by the column_1430 repository.
        '''
        cate
c_p = os.path.dirname(os.getcwd())+"/"
'''------------model_0829_dic1------------------
save_main_path = c_p+"model/model_0829_dic1/0901/"
dic_main_path = c_p+"Dictionary/ctm/"
filename  = save_main_path+"train_set.txt"
indexs = [1,2]
dic_path =dic_main_path+"Dic1_title_content.key"
glo_aff_path  = dic_main_path+"Dic1_title_content.glo"
sample_save_path = save_main_path+"title_content.train"
delete =True
tc_splitTag="\t"
str_splitTag ="^"
svm_model_save_path = save_main_path+"title.model"
svm_param='-c 16.0 -g 0.00048828125' 
test_path = sample_save_path 
for_lsa_train_save_path =  save_main_path +"for_lsa.train"
k = 10
lsa_train_save_path =  save_main_path +"0905_lsa_"+str(k)+".train"
lsa_save_path = save_main_path + "0905_lsa"
lsa_svm_param  = '-c -g'
lsa_svm_model_save_path  = save_main_path + "LSA_title.model"
extra_filename  = save_main_path +"data.extra"
-------------------------------------------------'''
'''------------model_ban禁限售样本---------------------------------------------
admin.autodiscover()
urlpatterns = patterns('',
	url(r'^$', 'sven.anta.views.index', name='anta_index'),
	url(r'^login/$', 'sven.anta.views.login_view', name='anta_login'),
	url(r'^logout/$', 'sven.anta.views.logout_view', name='anta_logout'),
	url(r'^upload/$', 'sven.anta.views.upload', name='anta_upload'),
    
    url(r'^overview/corpus/(?P<corpus_name>[a-z0-9-]+)/$', 'sven.anta.views.overview', name='anta_overview'),
    url(r'^status/corpus/(?P<corpus_name>[a-z0-9-]+)/$', 'sven.anta.views.status', name='anta_status'),
	url(r'^console/$', 'sven.anta.views.console', name='anta_console'),
    url(r'^document/(\d+)/$', 'sven.anta.views.document', name='anta_document'),
	url(r'^api/$', 'sven.anta.api.index', name='anta_api_index'),    
	url(r'^api/access-denied/$', 'sven.anta.api.access_denied', name='anta_api_access_denied' ),
	url(r'^api/login-requested/$', 'sven.anta.api.login_requested', name='anta_api_login_requested' ),
	url(r'^api/dummy-gummy/$', 'sven.anta.api.dummy_gummy', nam

	url(r'^api/logout/$', 'sven.anta.api.logout_view', name='anta_api_logout_view' ),
	url(r'^api/log-tail/$', 'sven.anta.api.log_tail', name='anta_api_log_tail' ),
	url(r'^api/log-test/$', 'sven.anta.api.log_test', name='anta_api_log_test' ),
	url(r'^api/documents/$', 'sven.anta.api.documents', name='anta_api_documents' ),    
	url(r'^api/documents/(\d+)/$', 'sven.anta.api.document', name='anta_api_document' ),    
	url(r'^api/relations/$', 'sven.anta.api.relations', name='anta_api_relations' ),    
	url(r'^api/relations/(\d+)/$', 'sven.anta.api.relation', name='anta_api_relation' ),    
	url(r'^api/corpus/$', 'sven.anta.api.corpora', name='anta_api_corpora' ),    
	url(r'^api/corpus/(?P<corpus_id>\d+)/download/$', 'sven.anta.api.corpus_download', name='anta_api_corpus_download'),
	url(r'^api/use-corpus/$', 'sven.anta.api.use_corpus', name='anta_api_use_corpus' ),
	url(r'^api/use-corpus/(\d+)/$', 'sven.anta.api.use_corpus', name='anta_api_use_corpus' ),
	url(r'^api/attach-corpus/(\d+)$'

	url(r'^api/tags/$', 'sven.anta.api.tags', name='anta_api_tags' ),    
	url(r'^api/tags/(?P<tag_id>\d+)/$', 'sven.anta.api.tag', name='anta_api_tag' ), 
	url(r'^api/stems/corpus/(?P<corpus_id>\d+)/$', 'sven.anta.api.segment_stems', name='anta_api_segment_stems' ),       
	url(r'^api/stems/(?P<segment_id>\d+)/corpus/(?P<corpus_id>\d+)/$', 'sven.anta.api.segment_stem', name='anta_api_segment_stem' ),    
	url(r'^api/attach-free-tag/document/(\d+)/$', 'sven.anta.api.attach_free_tag', name='anta_api_attach_free_tag' ),
	url(r'^api/attach-tag/document/(\d+)/tag/(\d+)/$', 'sven.anta.api.attach_tag', name='anta_api_attach_tag' ),
	url(r'^api/detach-tag/document/(\d+)/tag/(\d+)/$', 'sven.anta.api.detach_tag', name='anta_api_detach_tag' ),
	url(r'^api/tfidf/corpus/(\d+)/$', 'sven.anta.api.tfidf', name='anta_api_tfidf' ),
	url(r'^api/update-tfidf/corpus/(\d+)/$', 'sven.anta.api.update_tfidf', name='anta_api_update_tfidf' ),
	url(r'^api/update-similarity/corpus/(\d+)/$', 'sven.anta.api.update_si
def rotate(a, b,angle):
     x = [80.297,-24.52]
     y = [a, b]
     xx = y[0]-x[0]
     yy = y[1]-x[1]
     newx = (xx*cos(radians(angle))) - (yy*sin(radians(angle)))
     newy = (xx*sin(radians(angle))) + (yy*cos(radians(angle)))
     newx+= x[0]
     newy+= x[1]
     return newx,newy
num_lines = sum(1 for line in open('field0.dat'))
for_save_objid = np.array(())
for_save_longitude = np.array(())
for_save_latitude = np.array(())
for_save_mag_obs_g = np.array(())
for_save_mag_obs_r = np.array(())
for_save_mag_obs_i = np.array(())
for_save_l_rot = np.array(())
for_save_b_rot = np.array(())
data_field = np.loadtxt('field0.dat', delimiter = ',', skiprows=1)
objid      = data_field[:,0]
longitude  = data_field[:,1]
latitude   = data_field[:,2]
mag_obs_g  = data_field[:,3]
mag_obs_r  = data_field[:,4]
mag_obs_i  = data_field[:,5]
n_objects = len(mag_obs_r)
l_rot = np.zeros(n_objects)
b_rot = np.zeros(n_objects)
for obj in range(n_objects):
     l_rot[obj], b_rot[obj] = rotate(longitude[ob

for_save_objid      = np.concatenate((for_save_objid, objid))
for_save_longitude  = np.concatenate((for_save_longitude, longitude))
for_save_latitude   = np.concatenate((for_save_latitude, latitude))
for_save_mag_obs_g  = np.concatenate((for_save_mag_obs_g, mag_obs_g))
for_save_mag_obs_r  = np.concatenate((for_save_mag_obs_r, mag_obs_r))
for_save_mag_obs_i  = np.concatenate((for_save_mag_obs_i, mag_obs_i))
for_save_l_rot      = np.concatenate((for_save_l_rot, l_rot))
for_save_b_rot      = np.concatenate((for_save_b_rot, b_rot))	
save_array = np.zeros((len(for_save_objid), 8))
	 
save_array[:,0] = for_save_objid
save_array[:,1] = for_save_longitude			
save_array[:,2] = for_save_latitude
save_array[:,3] = for_save_mag_obs_g
save_array[:,4] = for_save_mag_obs_r
save_array[:,5] = for_save_mag_obs_i
save_array[:,6] = for_save_l_rot
save_array[:,7] = for_save_b_rot
save_filename = 'rotate_field.dat'
np.savetxt(save_filename, save_array, delimiter = ',')
for_save_objid = np.array(())
for_sav
class TestRobotController:
    
    def setup_method(self, method):
        
        configuration = Config( "settings.cfg" )
        initPositions = configuration.initPositions
        constrainments = configuration.constrainments
        maxSpeed = configuration.maxSpeed
        accuracy = configuration.accuracy
        robotArm = RobotArm( initPositions, constrainments, maxSpeed, accuracy )
        robotModelBounder = RobotModelBounder( robotArm, [], 0, 0 )
        self.robotController = RobotController(robotArm, robotModelBounder, lambda: True )
    
    def test_startRecording_simple(self):
        self.robotController.startRecording()
        
        assert self.robotController.isRecording
        
    def test_stopRecording_simple(self):
        self.robotController.startRecording()
        self.robotController.stopRecording()
        assert not self.robotController.isRecording
    def test_addDelegate_simple(self):
        delegate = RobotControllerRecordingDelegate()
        

        assert self.robotController.hasDelegate(delegate)
    
    def test_removeDelegate_simple(self):
        delegate = RobotControllerRecordingDelegate()
        self.robotController.addDelegate(delegate)
        self.robotController.removeDelegate(delegate)
        assert not self.robotController.hasDelegate(delegate)
        
    def test_invokeDelagate_1(self):
        delegate = RobotControllerRecordingDelegate()
        delegate.recording = True
        self.robotController.addDelegate(delegate)
        event = NewPositionEvent("data")
        
        self.robotController.invokeEvent(event)
        
        assert delegate.sequence.amount() == 1
    
    def test_invokeDelegate_Many(self):
        delegate = RobotControllerRecordingDelegate()
        delegate.recording = True
        delegate2 = RobotControllerRecordingDelegate()
        delegate2.recording = True
        self.robotController.addDelegate(delegate)
        self.robotController.addDelegate(delegate2)
        
"""
    :copyright: (c) 2011 by Tobias Heinzen
    :license: BSD, see LICENSE for more details
"""
frontend = Blueprint('repos', __name__)
get = functools.partial(frontend.route, methods=['GET'])
post = functools.partial(frontend.route, methods=['POST'])
def cache_keyfn(prefix, additional_fields=[]):
    def test(*args, **kwargs):
        id = GitRepository.resolve_ref(get_repository_path(kwargs['repository']), kwargs['tree'])
        path = ""
        for field in additional_fields:
            path = path + "-" + kwargs[field]
        if id is not None:
            return prefix + "-" + kwargs['repository'] + "-" + id + path
        return None
    return test
@frontend.errorhandler(EmptyRepositoryError)
def error_empty(error):
    return redirect(url_for('.empty', repository=error.repository))
@frontend.errorhandler(RepositoryError)
def error_repository(error):
    return redirect(url_for('base.not_found'))
@get("/")
@templated("repositories.xhtml")
def index():
    try:
        dir

    except StopIteration:
        logging.warning("repository base %s does not exist", dirnames)
        return dict(repositories=[])
    paths = (get_repository_path(name) for name in dirnames)
    paths = (path for path in paths if GitRepository.isRepository(path))
    return dict(
        repositories=[
            GitRepository(repository=path, force=True) for path in paths
        ]
    )
@get("/<repository>/")
@templated("detail.xhtml")
def repository(repository):
    repo = GitRepository(repository=get_repository_path(repository))
    return dict(
        repository=repo
    )
@get("/<repository>/empty/")
@templated("empty.xhtml")
def empty(repository):
    repo = GitRepository(repository=get_repository_path(repository), force=True)
    if not repo.is_empty:
        return redirect(url_for('.overview', repository=repository, tree=repo.active_branch))
    return dict(
        repository=repo
    )
@get("/<repository>/overview/<tree>/")
@cached(cache_keyfn('overview'))
@templated

def overview(repository, tree):
    repo = GitRepository(repository=get_repository_path(repository))
    return dict(
        repository=repo,
        treeid=tree
    )
def get_page():
    try:
        return int(request.values['p'])
    except:
        return 0
@get("/<repository>/shortlog/<tree>/")
@templated("shortlog.xhtml")
def shortlog(repository, tree):
    repo = GitRepository(repository=get_repository_path(repository))
    count = repo.commit_count(tree)
    page = get_page()
    if page < 0:
        page = 0
    if page*10 > count:
        page = count / 10
    return dict(
        repository=repo,
        treeid=tree,
        page = page,
        max_pages = count / 10
    )
@get("/<repository>/tree/<tree>/")
@cached(cache_keyfn('browse'))
@templated("browse.xhtml")
def browse(repository, tree):
    repo = GitRepository(repository=get_repository_path(repository))
    return dict(
        repository=repo,
        treeid=tree,
        browse=True
    )
@get("/<repository>/tre
starting_queue = None
stopping_queue = None
WORKER_NAME = 'worker/1'
def make_broker(manager, max_workers, start_queue=None, stop_queue=None):
    global starting_queue
    global stopping_queue
    starting_queue = start_queue
    stopping_queue = stop_queue
    return manager_worker_broker.get(max_workers, manager, _TestWorker)
class _TestWorker(object):
    def __init__(self, caller, worker_number):
        self._caller = caller
        self._thing_to_greet = 'everybody'
        self._starting_queue = starting_queue
        self._stopping_queue = stopping_queue
        self._options = optparse.Values({'verbose': False})
    def name(self):
        return WORKER_NAME
    def cleanup(self):
        pass
    def handle(self, message, src, an_int, a_str):
        assert an_int == 1
        assert a_str == "hello, world"
        self._caller.post_message('finished_test', 2)
    def safe_init(self):
        if self._starting_queue:
            self._starting_queue.put('')
        if self.

            self._stopping_queue.get()
    def stop(self):
        self._caller.post_message('done')
class FunctionTests(unittest.TestCase):
    def test_get__inline(self):
        self.assertTrue(make_broker(self, 1) is not None)
    def test_get__processes(self):
        if sys.platform in ('cygwin', 'win32'):
            return
        self.assertTrue(make_broker(self, 2) is not None)
class _TestsMixin(object):
    """Mixin class that implements a series of tests to enforce the
    contract all implementations must follow."""
    def name(self):
        return 'TesterManager'
    def is_done(self):
        return self._done
    def handle_done(self, src, log_messages):
        self._done = True
    def handle_finished_test(self, src, an_int, log_messages):
        self._an_int = an_int
    def handle_exception(self, src, exception_type, exception_value, stack):
        raise exception_type(exception_value)
    def setUp(self):
        self._an_int = None
        self._broker = None

        self._done = False
        self._exception = None
        self._max_workers = None
    def make_broker(self, starting_queue=None, stopping_queue=None):
        self._broker = make_broker(self, self._max_workers, starting_queue,
                                   stopping_queue)
    def test_name(self):
        self.make_broker()
        worker = self._broker.start_worker(1)
        self.assertEquals(worker.name(), WORKER_NAME)
        worker.cancel()
        worker.join(0.1)
        self.assertFalse(worker.is_alive())
        self._broker.cleanup()
    def test_cancel(self):
        self.make_broker()
        worker = self._broker.start_worker(1)
        self._broker.post_message('test_list', 1, 'hello, world')
        worker.cancel()
        worker.join(0.1)
        self.assertFalse(worker.is_alive())
        self._broker.cleanup()
    def test_done(self):
        self.make_broker()
        worker = self._broker.start_worker(1)
        self._broker.post_message('test_list', 1
class Handler(object):  
    def control(self, args = False):        
        controller = 'Home'
        path_file = './'
        method_name = 'index'
        method_args = []        
        if args:
            method_args = args.split('/')
            
            controller = method_args[0].title()
            method_args.pop(0)
            
            if len(method_args)>0 and method_args[0]=='':
                method_args.pop(0)
            if len(method_args) > 0 and method_args[0] != '':
                method_name = method_args[0]
                method_args.pop(0)            
        path_file += controller.lower()
        path_file += '.py'        
        if not os.path.isfile(path_file):
        try:           
            
            controller_instance = getattr(controller_module, controller)()
            if not hasattr(controller_instance, method_name):                            
            return getattr(controller_instance, method_name)(url=method_args)
      
__version__ = "$Revision:   11779/2 $"
urlpatterns = patterns('',
    url(r'results/$',                    handleNotifyMessage,           name="regression_notify_url"),
    url(r'controller/list$',             ControllerListView.as_view(),  name="controller_config_list"),
    url(r'controller/mode/choices',      getControllerModeChoices_ajax, name="controller_mode_choices_ajax"),
    url(r'controller/mode/update',       updateControllerMode_ajax,     name="controller_mode_update_ajax"),
    url(r'controller/mode/$',            getControllerInfo,             name="controller_mode_ajax"),
    url(r'cluster',                      getStationInfo_ajax,           name="regression_station_ajax"),
    url(r'queue',                        getWorkorderQueue_ajax,        name="regression_workorder_queue_ajax"),
    url(r'stationinfo/(?P<station>.*)$', getRawStationProfile_ajax,     name="test_station_info_raw_ajax"),    
    url(r'controller/selftest$',         requestControllerSelfTest,     name
unittest_toolbox = unittest_toolbox.Modified_TestCase
unittest_toolbox.bind_keys_to_roles()
def create_keystore(keystore_directory):
  if not unittest_toolbox.rsa_keystore or not unittest_toolbox.rsa_passwords:
    msg = 'Populate \'rsa_keystore\' and \'rsa_passwords\''+\
          ' before invoking this method.'
    sys.exit(msg)
  keystore._keystore = unittest_toolbox.rsa_keystore
  keystore._key_passwords = unittest_toolbox.rsa_passwords
  keystore.save_keystore_to_keyfiles(keystore_directory)
def build_server_repository(server_repository_dir, targets_dir):
  server_metadata_dir = os.path.join(server_repository_dir, 'metadata')
  os.mkdir(server_metadata_dir)
  keystore_dir = os.path.join(server_repository_dir, 'keystore')
  os.mkdir(keystore_dir)
  create_keystore(keystore_dir)
  config_filepath = signerlib.build_config_file(server_repository_dir, 365,
                                                unittest_toolbox.semi_roledict)
  role_keyids = {}
  for role in unittest_toolbox.s

    role_keyids[role] = unittest_toolbox.semi_roledict[role]['keyids']
  signerlib.build_root_file(config_filepath, role_keyids['root'],
                            server_metadata_dir)
  signerlib.build_targets_file(targets_dir, role_keyids['targets'],
                            server_metadata_dir)
  signerlib.build_release_file(role_keyids['release'], server_metadata_dir)
  signerlib.build_timestamp_file(role_keyids['timestamp'], server_metadata_dir)
def create_repositories():
  '''
  Main directories have the following structure:
                        repository_dir
                             |
                     ------------------
                     |                |
       client_repository_dir      server_repository_dir
                   client_repository_dir
                             |
                          metadata
                             |
                      ----------------
                      |              |
                  previous        cu

                   server_repository_dir
                             |
                 ----------------------------
                 |           |              |
             metadata     targets        keystore
  NOTE: Do not forget to remove the directory using remove_all_repositories
        after the tests.
  <Return>
    A tuple consisting of all repositories.
    (repository_dir, client_repository_dir, server_repository_dir)
  '''
  repository_directory = tempfile.mkdtemp()
  server_repository_dir  = os.path.join(repository_dir, 'server_repository')
  client_repository_dir  = os.path.join(repository_dir, 'client_repository')
  os.mkdir(server_repository_dir)
  os.mkdir(client_repository_dir)
  client_metadata_dir = os.path.join(client_repository_dir, 'metadata')
  os.mkdir(client_metadata_dir)
  current_directory = os.path.join(client_metadata_dir, 'current')
  previous_directory = os.path.join(client_metadata_dir, 'previous')
  os.mkdir(current_directory)
  os.mkdir(previous_
class Parser(object):
    __json_data = {}
    def __init__(self, json_data):
        self.__json_data = json_data
    def get_repository_namespace(self):
        repository_name = ''
        if "repository" in self.__json_data and "homepage" in self.__json_data["repository"]:
            match = re.match("[^:]*:([^/]*).*", self.__json_data["repository"]["url"])
            repository_name = match.group(1)
        return repository_name
    def get_repository_url(self):
        repository_url = ''
        if "repository" in self.__json_data and "url" in self.__json_data["repository"]:
            repository_url = self.__json_data["repository"]["url"]
        return repository_url
    def get_branch_name(self):
        branch_name = ''
        if "ref" not in self.__json_data:
            return branch_name
        branch_name = re.match("refs/heads/(.*)", self.__json_data["ref"])
        return branch_name.group(1)
    def get_project_name(self):
        project_name = ''
        if "r
def _repo(request, name):
    try:
        repository = Repository.objects.get(name=name)
    except:
        raise Http404
    repo = vcs.create(repository.type, repository.path)
    ref = request.GET['c'] if 'c' in request.GET else repo.ref()
    return repo, ref
def _nav_data(request, repo, ref, path=None):
    path = path if path else ''
    navigation = dict(zip(('dirs', 'files'), repo.browse(ref, path)))
    return {'navigation': navigation}
def _log_data(request, repo, ref, path=None):
    offset = int(request.GET['o']) if 'o' in request.GET else 0
    limit = 20
    path = path if path else ''
    log = repo.log(ref, path=path, max=limit, offset=offset)
    newer = offset - limit if offset > limit else 0
    last = log[-1]
    older = offset + limit if last.parents else 0
    return {
            'path': path,
            'repo': repo,
            'log': log,
            'ref': ref,
            'offset': offset,
            'newer': newer,
            'older': older,
          

@permission_required('dashboard.browse')
def log(request, repository, path=None):
    repo, ref = _repo(request, repository)
    data = RequestContext(request, {
        'repository': repository
    })
    data.update(_log_data(request, repo, ref, path))
    data.update(_nav_data(request, repo, ref, path))
    return render_to_response('browser/log.html', data)
@permission_required('dashboard.browse')
def commit(request, repository, ref):
    try:
        repository = Repository.objects.get(name=repository)
    except:
        raise Http404
    repo = vcs.create(repository.type, repository.path)
    commit = repo.commit(ref)
    diffs = repo.diff(ref)
    data = RequestContext(request, {
        'repository': repository,
        'repo': repo,
        'ref': ref,
        'commit': commit,
        'diffs': diffs,
    })
    return render_to_response('browser/view.html', data)
@permission_required('dashboard.browse')
def blob(request, repository, path):
    repo, ref = _repo(request, rep
__doc__ = """YTombola product module."""
__version__ = '0.1'
manage_addForm = HTMLFile('tombolaAdd', globals())
def manage_add(self, id, title='', REQUEST=None):
	"""Add a Tombola to a folder."""
	self._setObject(id, YTombola(id, title, REQUEST['bolas']))
	if REQUEST is not None:
		return self.manage_main(self, REQUEST)
class YTombola(
	):
	"""Tombola class."""
	meta_type = 'YTombola'
	def __init__(self, id, title, bolas):
		"""initialise a new instance of Tombola"""
		self.id = id
		self.title = title
		Tombola.__init__(self, bolas)
	manage_options = (
		{'label': 'Edit',		'action': 'manage_main'		},
		{'label': 'Security',	'action': 'manage_access'	},
		{'label': 'Sortear',	'action': 'sortear'			},
	)
	__ac_permissions__=(
		('View management screens',	('manage_tabs','manage_main')	),
		('Change permissions',		('manage_access',)				),
		('Change Tômbola',			('manage_edit',)				),
		('View Tômbola',			('',)							),
		('Use Tômbola',				('sortear',)					),
	)
	def manage_edit(self, ti
    repository_branches_item_mimetype
@six.add_metaclass(BasicTestsMetaclass)
class ResourceTests(BaseWebAPITestCase):
    """Testing the RepositoryBranchesResource list APIs."""
    fixtures = ['test_users', 'test_scmtools']
    sample_api_url = 'repositories/<id>/branches/'
    resource = resources.repository_branches
    def setup_http_not_allowed_list_test(self, user):
        repository = self.create_repository(tool_name='Test')
        return get_repository_branches_url(repository)
    def setup_http_not_allowed_item_test(self, user):
        repository = self.create_repository(tool_name='Test')
        return get_repository_branches_url(repository)
    def compare_item(self, item_rsp, branch):
        self.assertEqual(item_rsp, branch)
    def setup_basic_get_test(self, user, with_local_site, local_site_name):
        repository = self.create_repository(tool_name='Test',
                                            with_local_site=with_local_site)
        return (get_repository_b

                repository_branches_item_mimetype,
                [
                    {
                        'id': 'trunk',
                        'name': 'trunk',
                        'commit': '5',
                        'default': True
                    },
                    {
                        'id': 'branch1',
                        'name': 'branch1',
                        'commit': '7',
                        'default': False
                    },
                ])
    def test_get_with_no_support(self):
        """Testing the GET repositories/<id>/branches/ API
        with a repository that does not implement it
        """
        repository = self.create_repository(tool_name='CVS')
        try:
            rsp = self.api_get(get_repository_branches_url(repository),
                               expected_status=501)
        except ImportError:
            raise nose.SkipTest("cvs binary not found")
        self.assertEqual(rsp['stat'], 'fail')
      
logger = logging.getLogger(__name__)
def trigger(method):
    method.is_trigger = True
    return method
def every_minute(method):
    method.every_minute = True
    return method
class ChatBot(object):
    def __init__(self, broker=None):
        self.schedule = Scheduler()
        self.triggers = {}
        self.pollers = []
        self.introspect()
        self.setup_pollers()
        self.broker = broker
        if self.broker is not None:
            self.username = self.broker.username
            self.messages = self.broker.messages
    def on_message(self, iteration_nbr, message):
        self.iteration_nbr = iteration_nbr
        text = message['text'].lower()
        for trigger in self.triggers:
            if trigger in text:
                response = self.triggers[trigger]()
                if response is not None:
                    self.on_posted(self.broker.post(response)['message'])
                return response
    def on_posted(self, message):
        """Called 
urlpatterns = patterns(
                       '',
                       url(r'^$',manage_home_view),
                       url(r'^ad/add/$',manage_ad_add_view),
                       url(r'^ad/del/$',manage_ad_del_view),
                       url(r'^ad/del/adtypeselect/$',manage_ad_select_view),
                       url(r'^ad/picadd/upload/$',manage_ad_pic_upload_view),
                       url(r'^ad/picadd/preupload/$',manage_ad_picpre_view),
                       url(r'^supplie/add/$',manage_supplie_add_view),
                       url(r'^supplie/mod/$',manage_supplie_mod_view),
                       url(r'^petfarm/add/$',manage_pet_farm_add_view),
                       url(r'^petfarm/address/',address_handle_view),
                       url(r'^knowledge/mod/',manage_knowledge_mode_view),
                       url(r'^verify/',manage_verify_view),
                       url(r'^verifyinfo/',manage_verifyinfo_view),
                       url(r'^config/(?P<who>[^/]*)/$',m
app_name = 'controller'
urlpatterns = [
    url(r'^user/login', UserController.login),
    url(r'^user/logout', UserController.logout),
    url(r'^user/isLogin', UserController.isLogin),
    url(r'^user/current', UserController.getCurrentUser),
    url(r'^user/addUser', UserController.addUser),
    url(r'^user/deleteUser', UserController.deleteUser),
    url(r'^user/editUser', UserController.editUser),
    url(r'^user/getAllUser', UserController.getAllUser),
    url(r'^user/assignProject', UserController.assignProject),
    url(r'^vehicle/addVehicle', VehicleController.addVehicle),
    url(r'^vehicle/deleteVehicle', VehicleController.deleteVehicle),
    url(r'^vehicle/editVehicle', VehicleController.editVehicle),
    url(r'^vehicle/getAllVehicle', VehicleController.getAllVehicle),
    url(r'^vehicle/assignTask', VehicleController.assignTask),
    url(r'^vehicle/assignProject', VehicleController.assignProject),
    url(r'^project/addProject', ProjectController.addProject),
    url(r'^pr
"""
Example JSON data for dispatch process.
-- request from client --
    "netid" : "xxxxxxxx",
    "crn" : "xxxxx",
    "mode" : "x"
"""
class Dispatch(object):
    
    _TIMEOUT = 600
    
    def __init__(self, conn, address):
        self.conn = conn
        self.address = address
        self.db = database.DatabaseCommunicator()
        self.logger = logging.getLogger('Dispatch')
        logging.basicConfig(level=logging.DEBUG)
        
        self.logger.debug('dispatch launched')
    
    def _monitorLauncher(self, crn):
        monitor = Monitor(crn)
    
    def listen(self):
        try:
            while True:
                dispatchRequest = self.conn.recv(2048)
                if dispatchRequest == '':
                    self.logger.debug('Socket closed from client')
                    return
                if dispatchRequest == '\n':
                    continue
                self.logger.info('Dispatch request received.')
                self.logger.debug(dispatchR

                
                dispatchRequestJSON = json.loads(dispatchRequest)
                requestType = dispatchRequestJSON['request_type']
                netid = dispatchRequestJSON['netid']
                crn = dispatchRequestJSON['crn']
                mode = dispatchRequestJSON['mode']
                
                if requestType == 'add_monitor_entry':
                    notificationInterval = dispatchRequestJSON['notification_interval']
                    self.logger.debug('parse interval = ' + str(notificationInterval))
                    self.db.addMonitorEntry(netid, crn, mode, notificationInterval)
                    self.logger.debug('add entry')
                    if self.db.newMonitorRequired(crn):
                        process = multiprocessing.Process(target=self._monitorLauncher, args=(crn))
                        process.daemon = True
                        process.start()
                    dispatchResponse = dict(request_type='add_monitor_ent
env.abort_on_prompts = True
def s(template, **kwargs):
    '''Usage: s(string, **locals())'''
    if not kwargs:
        frame = inspect.currentframe()
        try:
            kwargs = frame.f_back.f_locals
        finally:
            del frame
        if not kwargs:
            kwargs = globals()
    return template.format(**kwargs)
def colorize(message, color='blue'):
  color_codes = dict(black=30, red=31, green=32, yellow=33, blue=34, magenta=35, cyan=36, white=37)
  code = color_codes.get(color, 34)
  msg =  s('\033[{code}m{message}\033[0m')
  return msg
def run_on_virtual_env(command, env='env'):
  run(s('source {env}/bin/activate && {command}'))
@task
def bootstrap():
    local("virtualenv env -p pypy")
    run_on_virtual_env("pip install -r requirements.txt", "env")
    run_on_virtual_env("pip freeze > requirements.txt.lock", "env")
    run_on_virtual_env("pip install -r requirements-dev.txt", "env")
    run_on_virtual_env("python manage.py migrate", "env")
    run_on_virtual_
def model_mock(model_name):
    model = type(model_name, (object,), dict(id=lambda s: s.__dict__['id']))
    instance = model()
    instance.id = None
    return instance
def test_repository_shared_state():
    repository1 = Repository()
    repository2 = Repository()
    assert id(repository1.__dict__) == id(repository2.__dict__)
def test_repository_clean():
    repository = Repository()
    repository.clean()
    model_name = 'ModelName'
    instance = model_mock(model_name)
    update = repository.save(model_name, instance)
    assert update == False
    assert repository.__dict__['data'][model_name] == [instance]
    assert type(repository.__dict__['data'][model_name]) == list
    assert repository.__dict__['data'][model_name][0].id == 1
    repository.clean()
    assert repository.__dict__['data'] == {}
def test_repository_save():
    repository = Repository()
    repository.clean()
    model_name = 'ModelName'
    instance = model_mock(model_name)
    update = repository.save(mod

    assert update == False
    assert repository.__dict__['data'][model_name] == [instance]
    assert type(repository.__dict__['data'][model_name]) == list
    assert repository.__dict__['data'][model_name][0].id == 1
def test_repository_save_more():
    repository = Repository()
    repository.clean()
    model_name = 'ModelName'
    instance = model_mock(model_name)
    update1 = repository.save(model_name, instance)
    instance2 = model_mock(model_name)
    update2 = repository.save(model_name, instance2)
    assert update1 == False
    assert update2 == False
    assert repository.__dict__['data'][model_name] == [instance, instance2]
    assert type(repository.__dict__['data'][model_name]) == list
    assert repository.__dict__['data'][model_name][0].id == 1
    assert repository.__dict__['data'][model_name][1].id == 2
def test_repository_save_update():
    repository = Repository()
    model_name = 'ModelName'
    instance = model_mock(model_name)
    update = repository.save(m

    assert update == False
    assert repository.__dict__['data'][model_name] == [instance]
    assert type(repository.__dict__['data'][model_name]) == list
    assert repository.__dict__['data'][model_name][0].id == 1
    instance.__dict__['id'] = 2
    update = repository.save(model_name, instance)
    assert repository.__dict__['data'][model_name][0].id == 2
    assert update == True
def test_repository_get_models():
    repository = Repository()
    repository.clean()
    model_name = 'ModelName'
    instance = model_mock(model_name)
    update1 = repository.save(model_name, instance)
    instance2 = model_mock(model_name)
    update2 = repository.save(model_name, instance2)
    assert update1 == False
    assert update2 == False
    assert repository.get_models(model_name) == [instance, instance2]
def test_repository_delete():
    repository = Repository()
    repository.clean()
    model_name = 'ModelName'
    instance = model_mock(model_name)
    update1 = repository.save(model
@receiver(SubmitRequest.command_signal)
def submit_request(_aggregate_repository=None, **kwargs):
  if not _aggregate_repository: _aggregate_repository = aggregate_repository
  command = kwargs['command']
  request = Request.submit(**command.data)
  _aggregate_repository.save(request, -1)
@receiver(SubmitArtistToRequest.command_signal)
def add_artist_request(_aggregate_repository=None, **kwargs):
  if not _aggregate_repository: _aggregate_repository = aggregate_repository
  command = kwargs['command']
  ag = _aggregate_repository.get(Request, kwargs['aggregate_id'])
  version = ag.version
  ag.submit_potential_artist(**command.data)
  _aggregate_repository.save(ag, version)
@receiver(RefreshPlaylist.command_signal)
def refresh_album_request(_aggregate_repository=None, **kwargs):
  if not _aggregate_repository: _aggregate_repository = aggregate_repository
  command = kwargs['command']
  ag = _aggregate_repository.get(Request, kwargs['aggregate_id'])
  if not ag.playlist.track_ids:
    v
g = Genre(genre='Alternative Music').save()
g = Genre(genre='Blues').save()
g = Genre(genre='Classical Music').save()
g = Genre(genre='Country Music').save()
g = Genre(genre='Dance Music').save()
g = Genre(genre='Easy Listening').save()
g = Genre(genre='Electronic Music').save()
g = Genre(genre='European Music (Folk / Pop)').save()
g = Genre(genre='Hip Hop / Rap').save()
g = Genre(genre='Indie Pop').save()
g = Genre(genre='Inspirational (incl. Gospel)').save()
g = Genre(genre='Asian Pop (J-Pop, K-pop)').save()
g = Genre(genre='Jazz').save()
g = Genre(genre='Latin Music').save()
g = Genre(genre='New Age').save()
g = Genre(genre='Opera').save()
g = Genre(genre='Pop (Popular music)').save()
g = Genre(genre='R&B / Soul').save()
g = Genre(genre='Reggae').save()
g = Genre(genre='Rock').save()
g = Genre(genre='Singer / Songwriter (inc; Folk)').save()
g = Genre(genre='World Music / Beats').save()
    
venue = Venue(name="Oran Mor", address="Byres Rd  Glasgow G12 8QX",website="http://oran-mor.c
class TestNSArrayControler (TestCase):
    def testMethods(self):
        self.failUnlessResultIsBOOL(NSArrayController.automaticallyRearrangesObjects)
        self.failUnlessResultIsBOOL(NSArrayController.clearsFilterPredicateOnInsertion)
        self.failUnlessArgIsBOOL(NSArrayController.setClearsFilterPredicateOnInsertion_, 0)
        self.failUnlessResultIsBOOL(NSArrayController.avoidsEmptySelection)
        self.failUnlessArgIsBOOL(NSArrayController.setAvoidsEmptySelection_, 0)
        self.failUnlessResultIsBOOL(NSArrayController.preservesSelection)
        self.failUnlessArgIsBOOL(NSArrayController.setPreservesSelection_, 0)
        self.failUnlessResultIsBOOL(NSArrayController.selectsInsertedObjects)
        self.failUnlessArgIsBOOL(NSArrayController.setSelectsInsertedObjects_, 0)
        self.failUnlessResultIsBOOL(NSArrayController.alwaysUsesMultipleValuesMarker)
        self.failUnlessArgIsBOOL(NSArrayController.setAlwaysUsesMultipleValuesMarker_, 0)
        self.failUnlessR
repository = load_repository("repository/")
if len(sys.argv) == 4:
	releaseKeyFile = sys.argv[1]
	f = open(releaseKeyFile)
	releasePassword = f.readline()
	timestampKeyFile = sys.argv[2]
	f = open(timestampKeyFile)
	timestampPassword = f.readline()
	nightlyKeyFile = sys.argv[3]
	f = open(nightlyKeyFile)
	nightlyPassword = f.readline()
	repository.release.load_signing_key(private_release_key)
	repository.timestamp.load_signing_key(private_timestamp_key)
	repository.targets.nightly.load_signing_key(private_nightly_key)
	for target in repository.targets.nightly.target_files:
		repository.targets.nightly.remove_target("repository/targets/"+target)
	nightly_targets = repository.get_filepaths_in_directory("repository/targets/pub/mozilla.org/firefox/nightly/",recursive_walk=True, followlinks=True) 
	repository.targets.nightly.add_targets(nightly_targets)
	repository.write()
	stagedMetadata = "repository/metadata.staged"
	metadata = "repository/metadata"
	distutils.dir_util.copy_tree(stagedMet
logger = Logger(level=logging.INFO)
class SyncControllerSitePrivileges(OpenStackSyncStep):
    provides=[SitePrivilege]
    requested_interval=0
    observes=ControllerSitePrivilege
    def fetch_pending(self, deleted):
        if (deleted):
            return ControllerSitePrivilege.deleted_objects.all()
        else:
            return ControllerSitePrivilege.objects.filter(Q(enacted__lt=F('updated')) | Q(enacted=None)) 
    def sync_record(self, controller_site_privilege):
        logger.info("sync'ing controler_site_privilege %s at controller %s" % (controller_site_privilege, controller_site_privilege.controller))
        if not controller_site_privilege.controller.admin_user:
            logger.info("controller %r has no admin_user, skipping" % controller_site_privilege.controller)
            return
	template = os_template_env.get_template('sync_controller_users.yaml')
        roles = [controller_site_privilege.site_privilege.role.role]
        if not controller_site_privilege.si

            raise Exception('Siteless user %s'%controller_site_privilege.site_privilege.user.email)
        else:
            user_fields = {
                       'endpoint':controller_site_privilege.controller.auth_url,
		       'name': controller_site_privilege.site_privilege.user.email,
                       'email': controller_site_privilege.site_privilege.user.email,
                       'password': controller_site_privilege.site_privilege.user.remote_password,
                       'admin_user': controller_site_privilege.controller.admin_user,
		       'admin_password': controller_site_privilege.controller.admin_password,
	               'ansible_tag':'%s@%s'%(controller_site_privilege.site_privilege.user.email.replace('@','-at-'),controller_site_privilege.controller.name),
		       'admin_tenant': controller_site_privilege.controller.admin_tenant,
		       'roles':roles,
		       'tenant':controller_site_privilege.site_privilege.site.login_base}    
	    rendered = templa

	    expected_length = len(roles) + 1
	    res = run_template('sync_controller_users.yaml', user_fields,path='controller_site_privileges', expected_num=expected_length)
            controller_site_privilege.role_id = res[0]['id']
            controller_site_privilege.save()
    def delete_record(self, controller_site_privilege):
        if controller_site_privilege.role_id:
            driver = self.driver.admin_driver(controller=controller_site_privilege.controller)
            user = ControllerUser.objects.get(
                controller=controller_site_privilege.controller, 
                user=controller_site_privilege.site_privilege.user
            )
            site = ControllerSite.objects.get(
                controller=controller_site_privilege.controller, 
                user=controller_site_privilege.site_privilege.user
            )
            driver.delete_user_role(
                user.kuser_id, 
                site.tenant_id, 
                controller_site_privi
__version__ = '0.1'
FLG_CLIENT = 'ZOCLIENT_' + __version__
FLG_SERVICE = 'ZOSERVICE_' + __version__
M_READY         = '\x01'
M_REQUEST       = '\x02'
M_REPLY         = '\x03'
class ZOClient(object):
    broker = None
    ctx = None
    client = None
    poller = None
    timout = 2500
    retry = 3
    verbose = False
    def __init__(self, broker, verbose = False):
        self.broker = broker
        self.verbose = verbose
        self.ctx = zmq.Context()
        self.poller = zmq.Poller()
        logging.basicConfig(format="%(asctime)s %(message)s", datefmt="%Y-%m-%d %H:%M:%S", level = logging.INFO)
        self.connect_to_broker()
    def connect_to_broker(self):
        if self.client:
            self.poller.unregister(self.client)
            self.client.close()
        self.client = self.ctx.socket(zmq.REQ)
        self.client.connect(self.broker)
        self.poller.register(self.client, zmq.POLLIN)
        if self.verbose:
            logging.info('connecting to broker : ' + 

    """Sync call"""
    def send(self, service, msg):
        if not isinstance(msg,list):
            msg = [msg]
        request = [FLG_CLIENT, service] + msg
        if self.verbose:
            logging.info('sending request to broker :' +  self.broker +' ' +service)
        reply = None
        retry = self.retry
        while retry > 0:
            self.client.send_multipart(request)
            try:
                socks = self.poller.poll(self.timout)
            except:
                break
            if socks:
                msg = self.client.recv_multipart()
                if self.verbose:
                    logging.info("received reply: " + str(msg))
                
                header = msg.pop(0)
                assert header == FLG_CLIENT
                reply_service = msg.pop(0)
                assert reply_service == service
                reply = msg
                break
            else:
                if retry > 0:
                    logging.warn("no r

                    self.connect_to_broker()
                else:
                    logging.warn("server down...")
                    break
                retry -= 1
        return reply
    def destroy(self):
        self.ctx.destroy()
class ZOSerivce(object):
    broker = None
    ctx = None
    poller = None
    timeout = 2500
    verbose = False
    service = None
    worker = None
    def __init__(self, broker, service, verbose=False):
        self.broker = broker
        self.service = service
        self.verbose = verbose
        self.ctx = zmq.Context()
        self.poller = zmq.Poller()
        logging.basicConfig(format="%(asctime)s %(message)s", datefmt="%Y-%m-%d %H:%M:%S",
                level=logging.INFO)
        self.connect_to_broker()
    def connect_to_broker(self):
        if self.worker:
            self.poller.unregister(self.worker)
            self.worker.close()
        self.worker = self.ctx.socket(zmq.DEALER)
        self.worker.connect(self.broker)
  
urlpatterns = patterns('lfc.manage.views',
    url(r'^applications$', "applications", name="lfc_applications"),
    url(r'^install-application/(?P<name>\w+)$', "install_application", name="lfc_install_application"),
    url(r'^uninstall-application/(?P<name>\w+)$', "uninstall_application", name="lfc_uninstall_application"),
    url(r'^reinstall-application/(?P<name>\w+)$', "reinstall_application", name="lfc_reinstall_application"),
    url(r'^copy/(?P<id>\d+)$', "lfc_copy", name="lfc_copy"),
    url(r'^cut/(?P<id>\d+)$', "cut", name="lfc_cut"),
    url(r'^paste/(?P<id>\d+)$', "paste", name="lfc_paste"),
    url(r'^paste$', "paste", name="lfc_paste"),
    url(r'^content-types$', "content_types", name="lfc_content_types"),
    url(r'^content-type/(?P<id>\d+)$', "content_type", name="lfc_content_type"),
    url(r'^imagebrowser$', "imagebrowser", name="lfc_imagebrowser"),
    url(r'^filebrowser$', "filebrowser", name="lfc_filebrowser"),
    url(r'^fb-upload-image$', "fb_upload_image", name

    url(r'^fb-upload-file$', "fb_upload_file", name="lfc_fb_upload_file"),
    url(r'^add-object/(?P<id>\w+)$', "add_object", name="lfc_add_object"),
    url(r'^add-object$', "add_object", name="lfc_add_top_object"),
    url(r'^add-object/(?P<language>\w+)/(?P<id>\w+)$', "add_object", name="lfc_add_object"),
    url(r'^delete-object/(?P<id>\d+)$', "delete_object", name="lfc_delete_object"),
    url(r'^save-core-data/(?P<id>\d+)$', "object_core_data", name="lfc_save_object_core_data"),
    url(r'^save-meta-data/(?P<id>\d+)$', "object_meta_data", name="lfc_save_meta_data"),
    url(r'^save-seo/(?P<id>\d+)$', "object_seo_data", name="lfc_save_seo"),
    url(r'^load-object-images/(?P<id>\d+)$', "load_object_images", name="lfc_load_object_images"),
    url(r'^add-images/(?P<id>\d+)$', "add_object_images", name="lfc_add_images"),
    url(r'^update-images/(?P<id>\d+)$', "update_object_images", name="lfc_update_images"),
    url(r'^edit-image/(?P<id>\d+)$', "edit_image", name="lfc_edit_image"

    url(r'^move-image/(?P<id>\d+)$', "move_image", name="lfc_move_image"),
    url(r'^load-portal-images$', "load_portal_images", name="lfc_load_portal_images"),
    url(r'^add-portal-images$', "add_portal_images", name="lfc_add_portal_images"),
    url(r'^update-portal-images$', "update_portal_images", name="lfc_update_portal_images"),
    url(r'^load-object-files/(?P<id>\d+)$', "load_object_files", name="lfc_load_object_files"),
    url(r'^add-object-files/(?P<id>\d+)$', "add_object_files", name="lfc_add_files"),
    url(r'^update-object-files/(?P<id>\d+)$', "update_object_files", name="lfc_update_files"),
    url(r'^load-portal-files$', "load_portal_files", name="lfc_load_portal_files"),
    url(r'^add-portal-files$', "add_portal_files", name="lfc_add_portal_files"),
    url(r'^update-portal-files$', "update_portal_files", name="lfc_update_portal_files"),
    url(r'^edit-file/(?P<id>\d+)$', "edit_file", name="lfc_edit_file"),
    url(r'^move-file/(?P<id>\d+)$', "move_file", name="l
"""
module handing the attributes pages
Created: Aug, 2013
"""
__author__ = 'Weber Jean-Paul'
__email__ = 'jean-paul.weber@govcert.etat.lu'
__copyright__ = 'Copyright 2013, GOVCERT Luxembourg'
__license__ = 'GPL v3+'
def gen_attr_chksum(attribute):
  key = '{0}{1}{2}{3}'.format(attribute.name,
                              attribute.regex,
                              attribute.table_id,
                              attribute.attributehandler_id)
  return hashSHA1(key)
class AttributeDefinitionController(BaseController):
  """Controller handling all the requests for attributes"""
  def __init__(self, config, session=None):
    BaseController.__init__(self, config, session)
    self.attr_def_broker = self.broker_factory(AttributeDefinitionBroker)
    self.handler_broker = self.broker_factory(AttributeHandlerBroker)
    self.type_broker = self.broker_factory(AttributeTypeBroker)
  def get_defintion_by_name(self, name):
    try:
      return self.attr_def_broker.get_defintion_by_name(na

    except NothingFoundException as error:
      raise ControllerNothingFoundException(error)
    except BrokerException as error:
      raise ControllerException(error)
  def get_all_attribute_definitions(self):
    """
    Returns all attribute definitions
    """
    try:
      return self.attr_def_broker.get_all(AttributeDefinition.name.asc())
    except BrokerException as error:
      raise ControllerException(error)
  def get_attribute_definitions_by_id(self, object_id):
    """
    Returns the attribute definition by the given id
    """
    try:
      return self.attr_def_broker.get_by_id(object_id)
    except NothingFoundException as error:
      raise ControllerNothingFoundException(error)
    except BrokerException as error:
      raise ControllerException(error)
  def get_attribute_definitions_by_uuid(self, uuid):
    """
    Returns the attribute definition by the given id
    """
    try:
      return self.attr_def_broker.get_by_uuid(uuid)
    except NothingFoundExceptio

      raise ControllerNothingFoundException(error)
    except BrokerException as error:
      raise ControllerException(error)
  def insert_attribute_definition(self, attribute, user, commit=True):
    try:
      attribute.chksum = gen_attr_chksum(attribute)
      user = self.user_broker.get_by_id(user.identifier)
      if not attribute.attribute_handler:
        handler = self.handler_broker.get_by_id(attribute.attributehandler_id)
        attribute.attribute_handler = handler
      self.set_simple_logging(attribute, user, insert=True)
      attribute = self.attr_def_broker.insert(attribute, False)
      self.attr_def_broker.do_commit(commit)
      return attribute
    except ValidationException as error:
      message = ObjectValidator.getFirstValidationError(attribute)
      raise ControllerException(u'Could not update object definition due to: {0}'.format(message))
    except BrokerException as error:
      raise ControllerException(error)
  def update_attribute_definition(self, a
freebayes_repository_name = 'freebayes_0040'
freebayes_repository_description = "Galaxy's freebayes tool for test 0040"
freebayes_repository_long_description = "Long description of Galaxy's freebayes tool for test 0040"
filtering_repository_name = 'filtering_0040'
filtering_repository_description = "Galaxy's filtering tool for test 0040"
filtering_repository_long_description = "Long description of Galaxy's filtering tool for test 0040"
class TestRepositoryCircularDependencies( ShedTwillTestCase ):
    '''Verify that the code correctly displays repositories with circular repository dependencies.'''
    def test_0000_initiate_users( self ):
        """Create necessary user accounts."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % test_user_1_email
   

        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
  
    def test_0005_create_category( self ):
        """Create a category for this test suite"""
        self.create_category( name='test_0040_repository_circular_dependencies', description='Testing handling of circular repository dependencies.' )
    def test_0010_create_freebayes_repository( self ):
        '''Create and populate freebayes_0040.'''
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        repository = self.get_or_create_repository( name=freebayes_repository_name, 
                                                    description=freebayes_repository_d

                                                    long_description=freebayes_repository_long_description, 
                                                    owner=common.test_user_1_name,
                                                    categories=[ 'test_0040_repository_circular_dependencies' ], 
                                                    strings_displayed=[] )
        self.upload_file( repository, 
                          filename='freebayes/freebayes.tar', 
                          filepath=None,
                          valid_tools_only=True,
                          uncompress_file=True,
                          remove_repo_files_not_in_tar=False,
                          commit_message='Uploaded the tool tarball.',
                          strings_displayed=[], 
                          strings_not_displayed=[] )
    def test_0015_create_filtering_repository( self ):
        '''Create and populate filtering_0040.'''
        self.logout()
        self.log
_BROKER_HOST=os.environ.get('NLPIPE_BROKER_HOST', '127.0.0.1')
_BROKER_USERNAME=os.environ.get('NLPIPE_BROKER_USERNAME', 'guest')
_BROKER_PASSWORD=os.environ.get('NLPIPE_BROKER_PASSWORD', 'guest')
_BROKER_PORT=int(os.environ.get('NLPIPE_BROKER_PORT', 5672))
BROKER_URL = 'amqp://{user}:{passwd}@{host}:{port}//'.format(
    user=_BROKER_USERNAME, passwd=_BROKER_PASSWORD, host=_BROKER_HOST, port=_BROKER_PORT)
CELERY_RESULT_BACKEND = 'rpc'
CELERY_QNAME = os.environ.get('NLPIPE_CELERY_QUEUE', 'nlpipe')
CELERY_DEFAULT_QUEUE = CELERY_QNAME
CELERY_DEFAULT_EXCHANGE_TYPE = 'direct'
CELERY_QUEUES = (
    Queue(CELERY_QNAME, Exchange('default'), routing_key=CELERY_QNAME),
    Queue('background', durable=False, routing_key='background'),
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_ACCEPT_CONTENT=['json']
CELERY_TIMEZONE = 'Europe/Amsterdam'
CELERY_ENABLE_UTC = True
CELERY_TASK_RESULT_EXPIRES = 3600
CELERY_ALWAYS_EAGER = os.environ.get('NLPIPE_EAGER', 'N').upper().starts
class  TestGameControllerTestCase(unittest.TestCase):
    
    def test_canary(self):
        self.assertTrue(True)
        
    def setUp(self):
        self.gameController = GameController()
    def test_expose_cell(self):
        self.assertTrue(self.gameController.exposeCell(7, 8))
    
    def test_expose_exposed_cell(self):
        self.gameController.exposeCell(2, 8) 
        self.assertFalse(self.gameController.exposeCell(2, 8))
        
    def test_seal_cell(self):
        self.assertTrue(self.gameController.toggleSeal(2, 3)) 
		
    def test_expose_sealed_cell(self): 
        self.gameController.toggleSeal(1, 2)
        self.assertFalse(self.gameController.exposeCell(1, 2))
        
    def test_unseal_sealed_cell(self):
        self.gameController.toggleSeal(2, 3)
        self.assertTrue(self.gameController.toggleSeal(2, 3))
    
    def test_seal_exposed_cell(self):
        self.gameController.exposeCell(3, 7)
        self.assertFalse(self.gameController.toggleSeal(3, 7)) 

    
    def test_count_mines_next_to_empty_cell(self):
        self.assertEquals(0, self.gameController.countMines(8, 9))
        
    def test_count_mines_for_cell_next_to_1_mine(self):
        self.gameController.setMine(5, 4)
        self.assertEquals(1, self.gameController.countMines(5, 5))
    
    def test_count_mines_for_cell_next_to_2_mines(self):
        self.gameController.setMine(5, 4)
        self.gameController.setMine(5, 6)
        self.assertEquals(2, self.gameController.countMines(5, 5))
        
    def test_count_mines_for_cell_next_to_3_mines(self):
        self.gameController.setMine(5, 4)
        self.gameController.setMine(5, 6)
        self.gameController.setMine(4, 4)
        self.assertEquals(3, self.gameController.countMines(5, 5))
        
    def test_count_mines_for_cell_next_to_4_mines(self):
        self.gameController.setMine(5, 4)
        self.gameController.setMine(5, 6)
        self.gameController.setMine(4, 4)
        self.gameController.setMine(4,

        self.assertEquals(4, self.gameController.countMines(5, 5))
        
    def test_count_mines_for_cell_next_to_5_mines(self):
        self.gameController.setMine(5, 4)
        self.gameController.setMine(5, 6)
        self.gameController.setMine(4, 4)
        self.gameController.setMine(4, 5)
        self.gameController.setMine(4, 6)
        self.assertEquals(5, self.gameController.countMines(5, 5))
        
    def test_count_mines_for_cell_next_to_6_mines(self):
        self.gameController.setMine(5, 4)
        self.gameController.setMine(5, 6)
        self.gameController.setMine(4, 4)
        self.gameController.setMine(4, 5)
        self.gameController.setMine(4, 6)
        self.gameController.setMine(6, 4)
        self.assertEquals(6, self.gameController.countMines(5, 5))
        
    def test_count_mines_for_cell_next_to_7_mines(self):
        self.gameController.setMine(5, 4)
        self.gameController.setMine(5, 6)
        self.gameController.setMine(4, 4)
        self
constants.CHECK_NEIGHBOURS_TIMEOUT = 1
class TestServerThread(threading.Thread):
    def __init__(self, manage_neighbours):
        threading.Thread.__init__(self)
        self.manage_neighbours = manage_neighbours
    def run(self):
        for i in xrange(100):
            operation = ['append', 'remove'][random.randint(0, 1)]
            node = ['127.0.0.1:1987', '127.0.0.1:1988', '127.0.0.1:1989'][random.randint(0, 2)]
            n_type = random.randint(1, 2)
            if random.randint(0, 1):
                d = {"sender": node, "parameters": {"operator_type":"DHT", "node_address": node, "operation": operation, "neighbour_type": n_type}, "method": "ManageNeighbour"}
                packet = FabnetPacketRequest(**d)
            else:
                d_append = [True, False][random.randint(0, 1)]
                d_remove = [True, False][random.randint(0, 1)]
                d = {"sender": node, "ret_parameters": {"operator_type":"DHT", "node_address": node, "operation": operation
							AnswerV2Resource, CandidateV2Resource, PersonalDataCandidateV2Resource,\
							BackgroundsCandidateV2Resource, PersonalDataV2Resource, BackgroundCategoryV2Resource,\
							BackgroundV2Resource, LinkV2Resource, MediaNaranjaResource, InformationSourceResource
v1_api = Api(api_name='v1')
v1_api.register(ElectionResource())
v1_api.register(CandidateResource())
v2_api = Api(api_name='v2')
v2_api.register(ElectionV2Resource())
v2_api.register(CategoryV2Resource())
v2_api.register(QuestionV2Resource())
v2_api.register(AnswerV2Resource())
v2_api.register(CandidateV2Resource())
v2_api.register(PersonalDataCandidateV2Resource())
v2_api.register(BackgroundsCandidateV2Resource())
v2_api.register(PersonalDataV2Resource())
v2_api.register(BackgroundCategoryV2Resource())
v2_api.register(BackgroundV2Resource())
v2_api.register(LinkV2Resource())
v2_api.register(MediaNaranjaResource())
v2_api.register(InformationSourceResource())
urlpatterns = patterns('',
    (r'^', include(v1_api.urls),),
   
with open(r'c:\ProgramData\QualiSystems\Shells.log', 'a') as f:
    f.write(time.strftime('%Y-%m-%d %H:%M:%S') + ': ' + __file__.split('\\')[-1].replace('.py', '') + ': ' + str(os.environ) + '\r\n')
resource = json.loads(os.environ['RESOURCECONTEXT'])
resource_name = resource['name']
attrs = resource['attributes']
datastore = attrs['Versa Datastore']
thick_thin = attrs['Versa Disk Mode']
vcenter_user = attrs['vCenter Administrator User']
vcenter_password = attrs['vCenter Administrator Password']
vcenter_ip = attrs['vCenter IP']
datacenter = attrs['Versa Datacenter']
cluster = attrs['Versa Cluster']
controller_portgroup = attrs['Versa Controller NB Portgroup Name']
controller_vmname = attrs['Versa Controller VM Name']
controller_ova_path = attrs['Versa Controller Path']
controller_ip = attrs['Versa Controller NB IP']
controller_dns = attrs['Versa Controller NB DNS']
controller_mask = attrs['Versa Controller NB Mask']
controller_gateway = attrs['Versa Controller NB Gateway']
controller_e

controller_1_portgroup = attrs['Versa Controller SB Portgroup Name']
controller_1_ip = ''
controller_1_dns = ''
controller_1_mask = ''
controller_1_gateway = ''
controller_1_eth = 'eth1'
controller_2_portgroup = attrs['Versa Controller SDWAN Portgroup Name']
controller_2_ip = ''
controller_2_dns = ''
controller_2_mask = ''
controller_2_gateway = ''
controller_2_eth = 'eth2'
controller = {
    controller_eth: (controller_ip,controller_portgroup,controller_mask,controller_gateway,controller_dns),
    controller_1_eth: (controller_1_ip,controller_1_portgroup,controller_1_mask,controller_1_gateway,controller_1_dns),
    controller_2_eth: (controller_2_ip,controller_2_portgroup,controller_2_mask,controller_2_gateway,controller_2_dns)
dv_switch = str(attrs['Versa SB VDS'])
dv_switchsdwan = str(attrs['Versa SDWAN VDS'])
vds1_num_ports = '128'
vds1_vlanmode = 'none'
vds1_vlan_ids = '0'
try:
    vcenterparams = {
        'IP': vcenter_ip,
        'user': vcenter_user,
        'password': vcent

    session = Vcenter(vcenterparams)
    session.add_dvPort_group(dv_switch, controller_1_portgroup, int(vds1_num_ports), vds1_vlanmode, vds1_vlan_ids)
    session.add_dvPort_group(dv_switchsdwan, controller_2_portgroup, int(vds1_num_ports), vds1_vlanmode, vds1_vlan_ids)
except:
    pass
try:
    command = '--skipManifestCheck --noSSLVerify  --allowExtraConfig --datastore=' + '"' + datastore + '"' + ' --acceptAllEulas --diskMode=' + thick_thin + ' --net:"VM Network"="' + controller_portgroup + '" --name="' + controller_vmname + '" "' + controller_ova_path + '" "vi://' + vcenter_user + ':"' + vcenter_password + '"@' + vcenter_ip + '/' + datacenter + '/host/' + cluster + '/Resources"'
    deployVM(command, controller_vmname, vcenter_ip, vcenter_user, vcenter_password, False)
    time.sleep(5)
    vmPower(controller_vmname, 'start', vcenter_ip, vcenter_user, vcenter_password)
except Exception, e:
    print '\r\n' + str(e)
    sys.exit(1)
loop = 10
script = '\'cat /etc/network/interfaces\
"""
Tests for Repositories app.
"""
def create_repository():
    repository = Repository(name="TestRepository",
                            manager="DSpace",
                            endpoint="http://dstools.hpsrepository.asu.edu/rest/")
    repository.save()
    return repository
def create_credential(repo):
    credential = Credential(repository_id = repo.id,
                            private_key = PRIVATE_KEY,
                            public_key = PUBLIC_KEY )
    credential.save()
    return credential
class DSpaceRepositoryTests(TestCase):
    """
    tests for repositories.repository.dspace
    """
    def setUp(self):
    def test_dspace_get_manager(self):
        manager = self.repo.get_manager()
        self.assertEqual(manager, DSpace)
class RepositoryManagerTests(TestCase):
    """
    tests for repositories.models.RepositoryManager
    """
    def setUp(self):
        self.repo = create_repository()
        self.cred = create_credential(self.repo)
        self.Repos
class Config(object):
    base_url = 'http://www.theplace.ru'
    settings_dir = 'settings'
    photos = 'photos'
    cache_dir = os.path.join('.', 'cache')
    _save_dir = {
        'unix': 'output',
        'win32': 'output',
    }
    icons_cache_dir = os.path.join(cache_dir, 'icons')
    rows_count = 3
    columns_count = 3
    utls = UrlUtils()
    utls.referer = base_url
    utls.encoding = 'cp1251'
    @property
    def save_dir(self):
        if platform == 'linux' or platform == 'linux2':
            return self._save_dir['unix']
        elif platform == 'win32':
            return self._save_dir['win32']
    @save_dir.setter
    def save_dir(self, value):
        if platform == 'linux' or platform == 'linux2':
            self._save_dir['unix'] = value
        elif platform == 'win32':
            self._save_dir['win32'] = value
    def save_config(self, d):
        assert isinstance(d, dict)
        d['config'] = {
            'save_dir': {
                'unix': self._save
class RoostClient(object):
    def __init__(self, client_id, client_secret):
        self.Name = "Roost"
        self.User = User()
        self.client_id = client_id
        self.client_secret = client_secret
        self._load_state()
    def _load_state(self):
        settings = shelve.open("roost.settings.%s" % self.client_id)
        if "user" in settings:
            self.User = settings["user"]
        settings.close()
    def _save_state(self):
        settings = shelve.open("roost.settings.%s" % self.client_id)
        settings["user"] = self.User
        settings.close()
    def login(self, pincode):
        broker = Broker(self.client_id, self.client_secret)
        try:
            token = broker.request_access_token(pincode)
            self.User = User(token)
            self._save_state()
        except NestAccessTokenError as token_error:
            print ("Access Token Request Error: %s" % token_error.description)
    def get_status(self):
        broker = Broker(self
def make_map(config):
	map = Mapper(directory=config['pylons.paths']['controllers'], always_scan=config['debug'])
	map.minimization = False
	map.explicit = False
	map.connect('/error/{action}', controller='error')
	map.connect('/error/{action}/{id}', controller='error')
	map.connect('/', controller="main", action="index")
	map.connect('/about', controller="help", action="about")
	map.connect('/contact', controller="help", action="contact")
	map.connect('/license', controller="help", action="license")
	map.connect('/policy', controller="help", action="policy")
	map.connect('/help', controller="help", action="help")
	map.connect('/achievements', controller="help", action="achievements")
	map.connect('/login', controller="users", action="login")
	map.connect('/logout', controller="users", action="logout")
	map.connect('/register', controller="users", action="register")
	map.connect('/unregister', controller="users", action="unregister")
	map.connect('/preferences', controller="users", act
print(sys.version)
docker_registry_url = 'http://example.com:5000'
catalog_url = docker_registry_url + '/v2/_catalog'
tag_url = docker_registry_url + '/v2/<REPOSITORY>/tags/list'
manifest_url = docker_registry_url + '/v2/<REPOSITORY>/manifests/<TAG>'
delete_fslayer_url = docker_registry_url + '/v2/<REPOSITORY>/blobs/<FSLAYER>'
delete_tag_url = docker_registry_url + '/v2/<REPOSITORY>/manifests/<DIGEST>'
r = requests.get(catalog_url)
catalog = r.json()
repositories = {}
for repository in catalog['repositories']:
    url = tag_url.replace('<REPOSITORY>', repository)
    r = requests.get(url)
    repository = r.json()
    tags = repository['tags']
    repository = repository['name']
    repositories[repository] = {}
    if tags is not None:
        for tag in tags:
            url = manifest_url.replace('<REPOSITORY>', repository)
            url = url.replace('<TAG>', tag)
            r = requests.get(url)
            docker_content_digest = r.headers['Docker-Content-Digest']
            

            manifest = r.json()
            for fslayer in manifest['fsLayers']:
                repositories[repository][tag]['layerDigests'].append(fslayer['blobSum'])
def print_menu(repositories):
    for repository_name, repository in repositories.iteritems():
        length = len(repository_name) + 2;
        print(repository_name + ': ', end='')
        first_line = True
        for tag_name, tag in repository.iteritems():
            fs_layers_count = str(len(tag['layerDigests']))
            if first_line:
                print(tag_name + ' (' + fs_layers_count + ')')
                first_line = False
            else:
                print(" "*length + tag_name + ' (' + fs_layers_count + ')')
        print()
def delete_image(repositories, repository, tag):
    for fslayer in reversed(repositories[repository][tag]['layerDigests']):
        url = delete_fslayer_url.replace('<REPOSITORY>', repository)
        url = url.replace('<FSLAYER>', fslayer)
        r = requests.delete(u
  'targets': [
    {
      'target_name': 'ceee_ie_all',
      'type': 'none',
      'dependencies': [
        'common/common.gyp:*',
        'broker/broker.gyp:*',
        'plugin/bho/bho.gyp:*',
        'plugin/scripting/scripting.gyp:*',
        'plugin/toolband/toolband.gyp:*',
        'ie_unittests',
        'mediumtest_ie',
      ]
    },
    {
      'target_name': 'testing_invoke_executor',
      'type': 'executable',
      'sources': [
        'plugin/bho/testing_invoke_executor.cc',
      ],
      'dependencies': [
        '../../base/base.gyp:base',
        '../common/common.gyp:ceee_common',
        'common/common.gyp:ie_guids',
        'plugin/toolband/toolband.gyp:toolband_idl',
        'plugin/toolband/toolband.gyp:toolband_proxy_lib',
      ],
      'libraries': [
        'rpcrt4.lib',
      ],
    },
    {
      'target_name': 'ie_unittests',
      'type': 'executable',
      'sources': [
        'broker/api_dispatcher_unittest.cc',
        'broker/broker_rpc_unittest.c

        'broker/broker_unittest.cc',
        'broker/cookie_api_module_unittest.cc',
        'broker/executors_manager_unittest.cc',
        'broker/infobar_api_module_unittest.cc',
        'broker/tab_api_module_unittest.cc',
        'broker/window_api_module_unittest.cc',
        'broker/window_events_funnel_unittest.cc',
        'common/ceee_module_util_unittest.cc',
        'common/ceee_util_unittest.cc',
        'common/chrome_frame_host_unittest.cc',
        'common/crash_reporter_unittest.cc',
        'common/extension_manifest_unittest.cc',
        'common/ie_util_unittest.cc',
        'common/metrics_util_unittest.cc',
        'common/rgs_helper.h',
        'plugin/bho/browser_helper_object_unittest.cc',
        'plugin/bho/cookie_accountant_unittest.cc',
        'plugin/bho/cookie_events_funnel_unittest.cc',
        'plugin/bho/dom_utils_unittest.cc',
        'plugin/bho/events_funnel_unittest.cc',
        'plugin/bho/executor_unittest.cc',
        'plugin/bho/executor_com_u

        'plugin/bho/extension_port_manager.cc',
        'plugin/bho/frame_event_handler_unittest.cc',
        'plugin/bho/infobar_events_funnel_unittest.cc',
        'plugin/bho/infobar_manager_unittest.cc',
        'plugin/bho/infobar_window_unittest.cc',
        'plugin/bho/tab_events_funnel_unittest.cc',
        'plugin/bho/tool_band_visibility_unittest.cc',
        'plugin/bho/webnavigation_events_funnel_unittest.cc',
        'plugin/bho/webrequest_events_funnel_unittest.cc',
        'plugin/bho/webrequest_notifier_unittest.cc',
        'plugin/bho/web_progress_notifier_unittest.cc',
        'plugin/scripting/content_script_manager.rc',
        'plugin/scripting/content_script_manager_unittest.cc',
        'plugin/scripting/content_script_native_api_unittest.cc',
        'plugin/scripting/renderer_extension_bindings_unittest.cc',
        'plugin/scripting/renderer_extension_bindings_unittest.rc',
        'plugin/scripting/script_host_unittest.cc',
        'plugin/scripting/userscr
DEBUG_LEVEL_CRITICAL = logging.CRITICAL
DEBUG_LEVEL_ERROR = logging.ERROR
DEBUG_LEVEL_WARNING = logging.WARNING
DEBUG_LEVEL_INFO = logging.INFO
DEBUG_LEVEL_DEBUG = logging.DEBUG
def list_brokers():
    return [f[1] for f in pkgutil.iter_modules([os.path.dirname(__file__)])]
def test(broker_name=None, driver_name=None):
    report = {}
    if broker_name:
        report[broker_name] = _test(broker_name, driver_name)
    else:
        for broker_name in list_brokers():
            report[broker_name] = _test(broker_name, driver_name)
    return report
def _test(broker_name, driver_name):
    report = {}
    try:
        broker = create(broker_name)
    except Exception as e:
        report['status'] = 'Fail'
        report['error'] = str(e)
        report['drivers'] = {}
    else:
        report['status'] = 'Succeed'
        report['error'] = 'None'
        report['drivers'] = broker.test(driver_name)
    return report
def create(broker_name):
    if broker_name not in list_brokers():
  
def create_cloud_server_api(access_key, secret_key):
    cloud_server_api = CloudServerAPI(access_key, secret_key)
    return cloud_server_api
def create_cloud_volume_api(access_key, secret_key):
    cloud_volume_api = CloudVolumeAPI(access_key, secret_key)
    return cloud_volume_api
def create_network_api(access_key, secret_key):
    network_api = NetworkAPI(access_key, secret_key)
    return network_api
def create_cdn_api(access_key, secret_key):
    cdn_api = CDNAPI(access_key, secret_key)
    return cdn_api
def create_video_api(access_key, secret_key):
    video_api = VideoAPI(access_key, secret_key)
    return video_api
def create_load_balancer_api(access_key, secret_key):
    load_balancer_api = LoadBalancerAPI(access_key, secret_key)
    return load_balancer_api
def create_database_api(access_key, secret_key):
    database_api = DatabaseAPI(access_key, secret_key)
    return database_api
def create_cache_api(access_key, secret_key):
    cache_api = CacheAPI(access_key, secret_k
datatypes_repository_name = 'blast_datatypes_0120'
datatypes_repository_description = 'Galaxy applicable datatypes for BLAST'
datatypes_repository_long_description = 'Galaxy datatypes for the BLAST top hit descriptons tool'
tool_repository_name = 'blastxml_to_top_descr_0120'
tool_repository_description = 'BLAST top hit descriptions'
tool_repository_long_description = 'Make a table from BLAST XML'
'''
Tool shed side:
1) Create and populate blast_datatypes_0120.
1a) Check for appropriate strings.
2) Create and populate blastxml_to_top_descr_0120.
2a) Check for appropriate strings.
3) Upload repository_dependencies.xml to blastxml_to_top_descr_0120 that defines a relationship to blast_datatypes_0120.
3a) Check for appropriate strings.
'''
base_datatypes_count = 0
repository_datatypes_count = 0
class TestRepositoryMultipleOwners( ShedTwillTestCase ):
    def test_0000_initiate_users( self ):
        """Create necessary user accounts and login as an admin user."""
        """
        Create

        Previously created accounts will not be re-created.
        """
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_1_email
        test_user_1_private_role = self.test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.test_user_2_email, username=common.test_user_2_name )
        test_user_2 = self.test_db_util.get_user( common.test_user_1_email )
        assert test_user_2 is not None, 'Problem retrieving user with email %s from the database' % common.test_user_2_email
        test_user_2_private_role = self.test_db_util.get_private_role( test_user_2 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = self.test_db_

        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % common.admin_email
        admin_user_private_role = self.test_db_util.get_private_role( admin_user )
    def test_0005_create_datatypes_repository( self ):
        """Create and populate the blast_datatypes_0120 repository"""
        """
        We are at step 1.
        Create and populate blast_datatypes.
        """
        category = self.create_category( name='Test 0120', description='Description of test 0120' )
        self.logout()
        self.login( email=common.test_user_2_email, username=common.test_user_2_name )
        strings_displayed = [ 'Repository %s' % "'%s'" % datatypes_repository_name, 
                              'Repository %s has been created' % "<b>%s</b>" % datatypes_repository_name ]
        repository = self.get_or_create_repository( name=datatypes_repository_name, 
                                                    description=datatypes_repository_descrip
"""Routes configuration
The more specific and detailed routes should be defined first so they
may take precedent over the more generic routes. For more information
refer to the routes manual at http://routes.groovie.org/docs/
"""
def make_map():
    """Create, configure and return the routes Mapper"""
    map = Mapper(directory=config['pylons.paths']['controllers'],
                 always_scan=config['debug'])
    map.minimization = False
    
    map.connect('/error/{action}', controller='error')
    map.connect('/error/{action}/{id}', controller='error')
    map.connect('/',controller='main',action='index')
    map.connect('/artists',controller='main',action='artists')
    map.connect('/config',controller='main',action='config')
    map.connect('/saveconfig',controller='main',action='saveconfig')
    map.connect('/albums',controller='main',action='albums')
    map.connect('/stats',controller='main',action='stats')
    map.connect('/tracks',controller='main',action='tracks')
    map.

    map.connect('/randomizer',controller='main',action='randomizer')
    map.connect('/genres',controller='main',action='genres')
    map.connect('/genre',controller='main',action='genre')
    map.connect('/add_random',controller='main',action='add_random')
    map.connect('/filesystem',controller='main',action='filesystem')
    map.connect('/search',controller='main',action='search')
    map.connect('/streams',controller='main',action='streams')
    map.connect('/savestream',controller='main',action='savestream')
    map.connect('/deletestream',controller='main',action='deletestream')
    map.connect('/playlist',controller='playlist',action='index')
    map.connect('/playlist/save',controller='playlist',action='save')
    map.connect('/playlist/load',controller='playlist',action='load')
    map.connect('/playlist/delete',controller='playlist',action='delete')
    map.connect('/fetchart',controller='main',action='fetchart')
    map.connect('/{controller}/{action}')
    map.connect('/{
urlpatterns = patterns('',
                       url(
                           r'^(?P<course_year_1>\d{2})-(?P<course_year_2>\d{2})/(?P<term>\d)/ce(?P<course_num>\d+)-(?P<course_group>\d+)/',
                           include(patterns('',
                                            url(r'^$', views.manage_home, name='manage_home'),
                                            url(r'^syllabus$', views.manage_course_syllabus, name='manage_course_syllabus'),
                                            url(r'^calendar$', views.manage_course_calendar, name='manage_course_calendar'),
                                            url(r'^assignments$', views.manage_course_assignments,
                                                name='manage_course_assignments'),
                                            url(r'^grades$', views.manage_course_grades, name='manage_course_grades'),
                                            url(r'^videolectures$', views.manage_course_videolectures,
        
manage_add_timelimit_form = PageTemplateFile('browser/add_plugin',
                            globals(), __name__='manage_add_timelimit_form' )
def manage_add_timelimit_helper( dispatcher, id, title=None, REQUEST=None ):
    """Add an timelimit Helper to the PluggableAuthentication Service."""
    sp = plugin.TimelimitHelper( id, title )
    dispatcher._setObject( sp.getId(), sp )
    if REQUEST is not None:
        REQUEST['RESPONSE'].redirect( '%s/manage_workspace'
                                      '?manage_tabs_message='
                                      'timelimitHelper+added.'
                                      % dispatcher.absolute_url() )
def register_timelimit_plugin():
    try:
        registerMultiPlugin(plugin.TimelimitHelper.meta_type)
    except RuntimeError:
        pass
def register_timelimit_plugin_class(context):
    context.registerClass(plugin.TimelimitHelper,
                          permission = manage_users,
                          constructors = (m
DB_SHARED_THREAD = """\
DatabaseWrapper objects created in a thread can only \
be used in that same thread.  The object with alias '%s' \
was created in thread id %s and this is thread id %s.\
"""
def patch_thread_ident():
    if getattr(patch_thread_ident, 'called', False):
        return
    try:
        if 'validate_thread_sharing' in BaseDatabaseWrapper.__dict__:
            _get_ident = thread.get_ident
            __old__init__ = BaseDatabaseWrapper.__init__
            def _init(self, *args, **kwargs):
                __old__init__(self, *args, **kwargs)
                self._thread_ident = _get_ident()
            def _validate_thread_sharing(self):
                if (not self.allow_thread_sharing
                        and self._thread_ident != _get_ident()):
                    raise DatabaseError(
                        DB_SHARED_THREAD % (
                            self.alias, self._thread_ident, _get_ident()),
                    )
            BaseDatabaseWrapper.__in

            BaseDatabaseWrapper.validate_thread_sharing = \
                _validate_thread_sharing
        patch_thread_ident.called = True
    except ImportError:
        pass
patch_thread_ident()
class CeleryCommand(BaseCommand):
    options = BaseCommand.option_list
    skip_opts = ['--app', '--loader', '--config']
    keep_base_opts = False
    def get_version(self):
        return 'celery %s\ndjango-celery %s' % (celery.__version__,
                                                djcelery.__version__)
    def execute(self, *args, **options):
        broker = options.get('broker')
        if broker:
            self.set_broker(broker)
        super(CeleryCommand, self).execute(*args, **options)
    def set_broker(self, broker):
        os.environ['CELERY_BROKER_URL'] = broker
    def run_from_argv(self, argv):
        self.handle_default_options(argv[2:])
        return super(CeleryCommand, self).run_from_argv(argv)
    def handle_default_options(self, argv):
        acc = []
  
"""
    inyoka.core.celery_support
    ~~~~~~~~~~~~~~~~~~~~~~~~~~
    Support module for celery.
    :copyright: 2009-2011 by the Inyoka Team, see AUTHORS for more details.
    :license: GNU GPL, see LICENSE for more details.
"""
    BooleanConfigField
celery_result_backend = TextConfigField('celery.result_backend', default=u'database')
celery_result_dburi = TextConfigField('celery.result_dburi', default='sqlite:///celery.db')
celery_task_serializer = TextConfigField('celery.task_serializer', default='pickle')
celery_send_task_error_emails = BooleanConfigField('celery.send_task_error_emails', default=False)
celery_eager_propagates_exceptions = BooleanConfigField('celery.eager_propagates_exceptions', default=True)
celery_track_started = BooleanConfigField('celery.track_started', default=True)
broker_backend = TextConfigField('broker.backend', u'sqlakombu.transport.Transport')
broker_host = TextConfigField('broker.host', 'sqlite:///kombu.db')
broker_port = IntegerConfigField('broker.port

broker_user = TextConfigField('broker.user', u'inyoka')
broker_password = TextConfigField('broker.password', u'default')
broker_vhost = TextConfigField('broker.vhost', u'inyoka')
class CeleryLoader(BaseLoader):
    """A customized celery configuration loader that implements a bridge
    between :mod:`inyoka.core.config` and the celery configuration system.
    """
    def read_configuration(self):
        """Read the configuration from configuration file and convert values
        to celery processable values."""
        celeryd_vars = list(ctx.cfg.itersection('celeryd'))
        celery_vars = list(ctx.cfg.itersection('celery'))
        broker_vars = list(ctx.cfg.itersection('broker'))
        conv = lambda x: (x[0].upper().replace('.','_'), x[1])
        settings = map(conv, celeryd_vars + celery_vars + broker_vars)
        settings.append(('DEBUG', ctx.cfg['debug']))
        settings.append(('CELERY_ALWAYS_EAGER', ctx.cfg['testing']))
        schedule = {}
        for task in tasks.
def patched_resource__init__(self, api_name=None):
    self.fields = {k: copy(v) for k, v in self.base_fields.iteritems()}
    if not api_name is None:
        self._meta.api_name = api_name
Resource.__init__ = patched_resource__init__
dev_api = Api(api_name='dev')
v1_api = Api(api_name='v1')
dev_api.register(collection.api.CollectionResource())
dev_api.register(catamidb.api.CampaignResource())
dev_api.register(catamidb.api.DeploymentResource())
dev_api.register(catamidb.api.PoseResource())
dev_api.register(catamidb.api.SimplePoseResource())
dev_api.register(catamidb.api.ImageResource())
dev_api.register(catamidb.api.ScientificImageMeasurementResource())
dev_api.register(catamidb.api.ScientificPoseMeasurementResource())
dev_api.register(catamidb.api.ScientificMeasurementTypeResource())
dev_api.register(jsonapi.api.UserResource())
dev_api.register(staging.api.StagingFilesResource())
dev_api.register(annotations.api.AnnotationCodeResource())
dev_api.register(annotations.api.QualifierCode
def broker_node(test, broker_type):
    """ Discover node of requested type. For leader type, discovers leader for our topic and partition 0
    """
    if broker_type == "leader":
        node = test.kafka.leader(test.topic, partition=0)
    elif broker_type == "controller":
        node = test.kafka.controller()
    else:
        raise Exception("Unexpected broker type %s." % (broker_type))
    return node
def clean_shutdown(test, broker_type):
    """Discover broker node of requested type and shut it down cleanly.
    """
    node = broker_node(test, broker_type)
    test.kafka.signal_node(node, sig=signal.SIGTERM)
def hard_shutdown(test, broker_type):
    """Discover broker node of requested type and shut it down with a hard kill."""
    node = broker_node(test, broker_type)
    test.kafka.signal_node(node, sig=signal.SIGKILL)
def clean_bounce(test, broker_type):
    """Chase the leader of one partition and restart it cleanly."""
    for i in range(5):
        prev_broker_node = br

        test.kafka.restart_node(prev_broker_node, clean_shutdown=True)
def hard_bounce(test, broker_type):
    """Chase the leader and restart it with a hard kill."""
    for i in range(5):
        prev_broker_node = broker_node(test, broker_type)
        test.kafka.signal_node(prev_broker_node, sig=signal.SIGKILL)
        wait_until(lambda: len(test.kafka.pids(prev_broker_node)) == 0 and not test.kafka.is_registered(prev_broker_node),
                   timeout_sec=test.kafka.zk_session_timeout + 5,
                   err_msg="Failed to see timely deregistration of hard-killed broker %s" % str(prev_broker_node.account))
        test.kafka.start_node(prev_broker_node)
failures = {
    "clean_shutdown": clean_shutdown,
    "hard_shutdown": hard_shutdown,
    "clean_bounce": clean_bounce,
    "hard_bounce": hard_bounce
class ReplicationTest(ProduceConsumeValidateTest):
    """
    Note that consuming is a bit tricky, at least with console consumer. The goal is to consume all messages
  

    too soon since console consumer is consuming multiple partitions from a single thread and therefore we lose
    ordering guarantees.
    Waiting on a count of consumed messages can be unreliable: if we stop consuming when num_consumed == num_acked,
    we might exit early if some messages are duplicated (though not an issue here since producer retries==0)
    Therefore rely here on the consumer.timeout.ms setting which times out on the interval between successively
    consumed messages. Since we run the producer to completion before running the consumer, this is a reliable
    indicator that nothing is left to consume.
    """
    def __init__(self, test_context):
        """:type test_context: ducktape.tests.test.TestContext"""
        super(ReplicationTest, self).__init__(test_context=test_context)
        self.topic = "test_topic"
        self.zk = ZookeeperService(test_context, num_nodes=1)
        self.kafka = KafkaService(test_context, num_nodes=3, zk=self.zk, topics={self.
'''
Created on Sep 14, 2014
Modified on Sep 15, 2014
Tests verifying a repository containing zero or more components.
@author: Clay Miller
'''
class RepositoryTest(unittest.TestCase):
    '''
    Test Repository class.
    '''
    def testInit(self):
        '''
        Test init method.
        '''
        self.assertRaises(ValueError, Repository.Repository, 0)
        rep1 = Repository.Repository(1)
        self.assertEqual(rep1.capacity, 1)
        rep2 = Repository.Repository()
        self.assertEqual(rep2.capacity, 100)
    def testAddComponent(self):
        '''
        Test addComponent method.
        '''
        com1 = Component.Component("a", 0, 1)
        rep1 = Repository.Repository(1)
        self.assertEqual(rep1.addComponent(com1), 1)
        self.assertEqual(rep1.queue[0].methodCount, 0)
        com2 = Component.Component("a", 1, 1)
        self.assertEqual(rep1.addComponent(com2), 1)
        self.assertEqual(rep1.queue[0].methodCount, 1)
    def testCount(self):
     

        Test count method.
        '''
        rep1 = Repository.Repository()
        self.assertEqual(rep1.count(), 0)
        self.assertEqual(len(rep1.queue), 0)
        rep2 = Repository.Repository()
        com1 = Component.Component("a", 1, 1)
        rep2.addComponent(com1)
        self.assertEqual(rep2.count(), 1)
        self.assertEqual(len(rep2.queue), 1)
    def testValidCount(self):
        '''
        Test validCount method.
        '''
        rep1 = Repository.Repository()
        self.assertEqual(rep1.validCount(), 0)
        com1 = Component.Component("a", 0, 1)
        rep2 = Repository.Repository(1)
        rep2.addComponent(com1)
        self.assertEqual(rep2.validCount(), 0)
        com2 = Component.Component("a", 1, 1)
        rep3 = Repository.Repository(1)
        rep3.addComponent(com2)
        self.assertEqual(rep3.validCount(), 1)
    def testDetermineRelativeSizes(self):
        '''
        Test determineRelativeSizes method.
        '''
        rep1 = Rep

        self.assertRaises(ValueError, rep1.determineRelativeSizes)
        com1 = Component.Component("a", 0, 1)
        rep2 = Repository.Repository(1)
        rep2.addComponent(com1)
        self.assertRaises(ValueError, rep2.determineRelativeSizes)
        com2 = Component.Component("a", 1, 1)
        rep3 = Repository.Repository(1)
        rep3.addComponent(com2)
        self.assertRaises(ValueError, rep3.determineRelativeSizes)
        rep4 = Repository.Repository()
        com3 = Component.Component("a", 1, 5)
        com4 = Component.Component("b", 1, 10)
        com5 = Component.Component("c", 1, 15)
        rep4.addComponent(com3)
        rep4.addComponent(com4)
        rep4.addComponent(com5)
        relativeSizes = rep4.determineRelativeSizes()
        self.assertEqual(relativeSizes[0], 3.0)
        self.assertEqual(relativeSizes[1], 6.0)
        self.assertEqual(relativeSizes[2], 10.0)
        self.assertEqual(relativeSizes[3], 16.0)
        self.assertEqual(relativeSizes[
"""
=============================================================
pikachewie.helpers -- Helpers for creating brokers and agents
=============================================================
"""
def consumer_from_config(config):
    """
    Create a :class:`pikachewie.consumer.Consumer` from the given `config`.
    """
    kwargs = config.get('arguments', {})
    return consumer_class(**kwargs)
def broker_from_config(config):
    """Create a :class:`pikachewie.broker.Broker` from the given `config`."""
    options = config.copy()
    nodes = options.pop('nodes')
    return Broker(nodes, options)
def consumer_agent_from_config(config, name, broker='default',
                               section='rabbitmq'):
    """
    Create a :class:`pikachewie.agent.ConsumerAgent` from the given `config`.
    The `config` dict should have a structure similar to the following
    example::
        {
            'rabbitmq': {
                'brokers': {
                    'default': {
              

                            'rabbit1': {
                                'host': 'rabbit1.example.com',
                                'port': 5672,
                            },
                            'rabbit2': {
                                'host': 'rabbit2.example.com',
                                'port': 5672,
                            },
                        },
                        'virtual_host': '/integration',
                        'heartbeat_interval': 60,
                    },
                },
                'consumers': {
                    'message_logger': {
                        'class': 'my.consumers.LoggingConsumer',
                        'arguments': {
                            'level': 'debug',
                        },
                        'bindings': [
                            {
                                'exchange': 'message',
                                'queue': 'text',
                            },
           

                    },
                },
                'exchanges': {
                    'message': {
                        'exchange_type': 'topic',
                        'durable': True,
                        'auto_delete': False,
                    },
                },
                'queues': {
                    'text': {
                        'durable': True,
                        'exclusive': False,
                        'arguments': {
                            'x-dead-letter-exchange': 'dead.letters',
                            'x-dead-letter-routing-key': 'omg.such.rejection',
                            'x-ha-policy': 'all',
                            'x-message-ttl': 1800000
                        },
                    },
                },
            },
        }
    """
    consumer_config = config[section]['consumers'][name]
    consumer = consumer_from_config(consumer_config)
    broker = broker_from_config(config[section]['brokers'][broker])

def createApp():
    """Set up the application."""
    try :
        app = Flask(__name__, instance_path=CONFIG_PATH)
        local = CONFIG_BROKER['local']
        app.config.from_object(__name__)
        app.config['LOCAL'] = local
        app.config['REST_TRACE'] = CONFIG_SERVICES['rest_trace']
        app.config['SYSTEM_EMAIL'] = CONFIG_BROKER['reply_to_email']
        app.config.from_envvar('BROKER_SETTINGS', silent=True)
        broker_file_path = CONFIG_BROKER['broker_files']
        AccountHandler.FRONT_END = CONFIG_BROKER['full_url']
        sesEmail.SIGNING_KEY =  CONFIG_BROKER['email_token_key']
        sesEmail.isLocal = local
        if sesEmail.isLocal:
            sesEmail.emailLog = os.path.join(broker_file_path, 'email.log')
        if local and not os.path.exists(broker_file_path):
            os.makedirs(broker_file_path)
        JsonResponse.debugMode = app.config['REST_TRACE']
        if CONFIG_SERVICES['cross_origin_url'] ==  "*":
            cors = CORS(app, supp

        else:
            cors = CORS(app, supports_credentials=True,
                origins=CONFIG_SERVICES['cross_origin_url'])
        app.session_interface = DynamoInterface()
        bcrypt = Bcrypt(app)
        @app.route("/", methods=["GET"])
        def root():
            return "Broker is running"
        if local:
            localFiles = os.path.join(broker_file_path, "<path:filename>")
            @app.route(localFiles)
            def sendFile(filename):
                if(config["local"]) :
                    return send_from_directory(broker_file_path, filename)
        else:
            SessionTable.DYNAMO_REGION = CONFIG_BROKER['aws_region']
        add_login_routes(app, bcrypt)
        add_file_routes(app, CONFIG_BROKER['aws_create_temp_credentials'],
            local, broker_file_path)
        add_user_routes(app, app.config['SYSTEM_EMAIL'], bcrypt)
        SessionTable.LOCAL_PORT = CONFIG_DB['dynamo_port']
        SessionTable.setup(app, local)
        return a
def pstSettings(controller):
    settingsDlg = gui.Dlg(title="PST")
    settingsDlg.addText('Set Parameters')
    settingsDlg.addField('Duration', controller.settings['PST: Duration'])
    if settingsDlg.OK:
        response = settingsDlg.data
        return response[0]
    else:
        return -1
def pst(controller, outfile):
    duration = pstSettings(controller)
    if duration == -1:
        print 'PST Cancelled'
        return
    display.text(controller.experWin, 'Running PST')
    testWin = controller.testWin
    display.countdown(controller)
    display.fill_screen(testWin, [-1, -1, -1])
    if not controller.testing:
        controller.tobii_cont.setDataFile(outfile)
        controller.tobii_cont.startTracking()
        controller.tobii_cont.setEventsAndParams(['task','duration'])
        controller.tobii_cont.setParam('task', 'pst')
        controller.tobii_cont.setParam('duration', duration)
    core.wait(duration)
    if not controller.testing:
        controller.tobii_cont
"""
osnap.stories.tests.test_models
===============================
These test our industry-standard `utils.py` file full of random stuff.
:copyright: (C) 2013 Matthew Frazier
:license:   GNU GPL version 2 or later, see LICENSE for details
"""
def stringify_inputs(f):
    @wraps(f)
    def stringify(arg):
        return f(text_type(arg))
    return stringify
class BaseDispatcher(object):
    "An artificial example, to be sure."
    def dispatch(self, v):
        return self.delegated_method(v)
class UtilityTests(SimpleTestCase):
    def test_decorated_view(self):
        @decorated_view(stringify_inputs)
        class DispatchTo(object):
            def dispatch(self, v):
                return v
        dispatch = DispatchTo()
        self.assertEquals(dispatch.dispatch(32), "32")
        self.assertEquals(DispatchTo.dispatch(dispatch, 32), "32")
    def test_decorated_view_subclass(self):
        @decorated_view(stringify_inputs)
        class PrefixDispatcher(BaseDispatcher):
      
column_repository_name = 'column_maker_0150'
column_repository_description = "Add column"
column_repository_long_description = "Compute an expression on every row"
convert_repository_name = 'convert_chars_0150'
convert_repository_description = "Convert delimiters"
convert_repository_long_description = "Convert delimiters to tab"
category_name = 'Test 0150 Simple Prior Installation'
category_description = 'Test 0150 Simple Prior Installation'
'''
Create column_maker and convert_chars.
Column maker repository dependency:
<repository toolshed="self.url" name="convert_chars" owner="test" changeset_revision="c3041382815c" prior_installation_required="True" />
Verify display.
Galaxy side:
Install column_maker.
Verify that convert_chars was installed first, contrary to the ordering that would be present without prior_installation_required.
'''
class TestSimplePriorInstallation( ShedTwillTestCase ):
    '''Test features related to datatype converters.'''
    
    def test_0000_initiate_users( 

        """Create necessary user accounts."""
        self.logout()
        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        test_user_1 = test_db_util.get_user( common.test_user_1_email )
        assert test_user_1 is not None, 'Problem retrieving user with email %s from the database' % test_user_1_email
        test_user_1_private_role = test_db_util.get_private_role( test_user_1 )
        self.logout()
        self.login( email=common.admin_email, username=common.admin_username )
        admin_user = test_db_util.get_user( common.admin_email )
        assert admin_user is not None, 'Problem retrieving user with email %s from the database' % admin_email
        admin_user_private_role = test_db_util.get_private_role( admin_user )
        
    def test_0005_create_convert_repository( self ):
        '''Create and populate convert_chars_0150.'''
        category = self.create_category( name=category_name, description=category_description )
       

        self.login( email=common.test_user_1_email, username=common.test_user_1_name )
        repository = self.get_or_create_repository( name=convert_repository_name, 
                                                    description=convert_repository_description, 
                                                    long_description=convert_repository_long_description, 
                                                    owner=common.test_user_1_name,
                                                    category_id=self.security.encode_id( category.id ), 
                                                    strings_displayed=[] )
        self.upload_file( repository, 
                          filename='convert_chars/convert_chars.tar', 
                          filepath=None,
                          valid_tools_only=True,
                          uncompress_file=True,
                          remove_repo_files_not_in_tar=False, 
                          commit_message='Uploaded 
base_url = 'https://www.filemail.com'
api_urls = {
    'login': ['get', 'api/authentication/login'],
    'logout': ['get', 'api/authentication/logout'],
    'init': ['get', 'api/transfer/initialize'],
    'get': ['get', 'api/transfer/get'],
    'get_sent': ['get', 'api/transfer/sent/get'],
    'complete': ['get', 'api/transfer/complete'],
    'forward': ['get', 'api/transfer/forward'],
    'share': ['get', 'api/transfer/share'],
    'cancel': ['get', 'api/transfer/cancel'],
    'delete': ['get', 'api/transfer/delete'],
    'compress': ['get', 'api/transfer/compress'],
    'file_rename': ['get', 'api/transfer/file/rename'],
    'file_delete': ['get', 'api/transfer/file/delete'],
    'update': ['get', 'api/transfer/update'],
    'received_get': ['get', 'api/transfer/received/get'],
    'user_get': ['get', 'api/user/get'],
    'user_update': ['get', 'api/user/update'],
    'contacts_get': ['get', 'api/contacts/get'],
    'contacts_add': ['get', 'api/contacts/add'],
    'contacts_update': 
class MockConnection(dict):
    def __setattr__(self, key, value):
        self[key] = value
class test_amqplib(unittest.TestCase):
    def test_conninfo(self):
        c = BrokerConnection(userid=None, transport="amqplib")
        self.assertRaises(KeyError, c.connect)
        c = BrokerConnection(hostname=None, transport="amqplib")
        self.assertRaises(KeyError, c.connect)
        c = BrokerConnection(password=None, transport="amqplib")
        self.assertRaises(KeyError, c.connect)
    def test_default_port(self):
        class Transport(pyamqplib.Transport):
            Connection = MockConnection
        c = BrokerConnection(port=None, transport=Transport).connect()
        self.assertEqual(c["host"],
                         "localhost:%s" % (Transport.default_port, ))
    def test_custom_port(self):
        class Transport(pyamqplib.Transport):
            Connection = MockConnection
        c = BrokerConnection(port=1337, transport=Transport).connect()
        self.assertE
urlpatterns = patterns('kpi.views',
    url(r'^sector/(?P<sector_ref_no>\d+)/kpi/$', 'view_sector_kpi', name='view_sector_kpi'),
    url(r'^master_plan/(?P<master_plan_ref_no>\d+)/kpi/$', 'view_master_plan_kpi', name='view_master_plan_kpi'),
    url(r'^program/(?P<program_id>\d+)/kpi/$', 'view_program_kpi', name='view_program_kpi'),
    
    url(r'^master_plan/manage/program/(?P<program_id>\d+)/kpi/$', 'view_master_plan_manage_program_kpi', {'quarter_year':0}, name='view_master_plan_manage_program_kpi'),
    url(r'^master_plan/manage/program/(?P<program_id>\d+)/kpi/(?P<quarter_year>\d+)/$', 'view_master_plan_manage_program_kpi', name='view_master_plan_manage_program_kpi_year'),
    
    url(r'^master_plan/(?P<master_plan_ref_no>\d+)/manage/kpi/$', 'view_master_plan_manage_kpi', {'kpi_year':''}, name='view_master_plan_manage_kpi'),
    url(r'^master_plan/(?P<master_plan_ref_no>\d+)/manage/kpi/(?P<kpi_year>\d+)/$', 'view_master_plan_manage_kpi', name='view_master_plan_manage_kpi_year'),


    url(r'^master_plan/manage/kpi/(?P<kpi_id>\d+)/edit/$', 'view_master_plan_manage_kpi_edit_kpi', name='view_master_plan_manage_kpi_edit_kpi'),
    url(r'^master_plan/manage/kpi/(?P<kpi_id>\d+)/delete/$', 'view_master_plan_manage_kpi_delete_kpi', name='view_master_plan_manage_kpi_delete_kpi'),
    
    url(r'^master_plan/(?P<master_plan_ref_no>\d+)/manage/kpi/categoty/$', 'view_master_plan_manage_kpi_category', name='view_master_plan_manage_kpi_category'),
    url(r'^master_plan/(?P<master_plan_ref_no>\d+)/manage/kpi/category/add/$', 'view_master_plan_manage_kpi_add_category', name='view_master_plan_manage_kpi_add_category'),
    url(r'^master_plan/manage/kpi/category/(?P<kpi_category_id>\d+)/edit/$', 'view_master_plan_manage_kpi_edit_category', name='view_master_plan_manage_kpi_edit_category'),
    url(r'^master_plan/manage/kpi/category/(?P<kpi_category_id>\d+)/delete/$', 'view_master_plan_manage_kpi_delete_category', name='view_master_plan_manage_kpi_delete_category'),
    
    url
urlpatterns = patterns('',
	url(r'^$', views.home, name='home'),
	url(r'^profile/$', views.profile, name='profile'),
	url(r'^contact/$', views.contact, name='contact'),
	url(r'^login/$', views.applyLogin, name='login'),
	url(r'^logout/$', views.applyLogout, name='logout'),
	url(r'^change-password/$', auth_views.password_change, name='change'),
	url(r'^change-password/done/$', auth_views.password_change_done, name='password_change_done'),
	url(r'^reset-password/$', auth_views.password_reset, name='reset'),
	url(r'^reset-password/done/$', auth_views.password_reset_done, name='password_reset_done'),
	url(r'^reset-password/confirm/(?P<uidb64>[0-9A-Za-z_\-]+)/(?P<token>[0-9A-Za-z]{1,13}-[0-9A-Za-z]{1,20})/$', auth_views.password_reset_confirm, name='resetconfirm'),
	url(r'^reset-password/complete/$', auth_views.password_reset_complete, name='password_reset_complete'),
	url(r'^register/$', views.applyRegister, name='register'),
	url(r'^manage/data/entries/$', views.entriesJson, name='entries

	url(r'^manage/people/$', views.managePeople, name='managepeople'),
	url(r'^manage/people/(?P<id>\d+)/$', views.managePerson, name='manageperson'),
	url(r'^manage/news/$', views.manageNews, name='managenews'),
	url(r'^manage/publication/$', views.managePublication, name='managepublication'),
	url(r'^manage/position/$', views.managePosition, name='manageposition'),
	url(r'^manage/entries/$', views.manageEntries, name='manageentries'),
	url(r'^manage/entries/(?P<id>\d+)/$', views.manageEntry, name='manageentry'),
	url(r'^manage/application/(?P<pos>\d+)/(?P<quarter>\w+)/(?P<year>\d+)/$', views.manageApplication, name='manageapp'),
	url(r'^manage/application/delete/$', views.manageDeleteApp, name='managedeleteapp'),
	url(r'^applications/$', views.publications, name='applications'),
	url(r'^applications/(?P<slug>[-\w]+)/$', views.publication, name='publication'),
	url(r'^applications/(?P<pub>[-\w]+)/(?P<pos>[-\w]+)/$', views.position, name='position'),
	url(r'^applications/(?P<pub>[-\w]+)/
if sys.getdefaultencoding() != 'utf-8':
    reload(sys)
    sys.setdefaultencoding('utf-8')
app_root = os.path.dirname(__file__)
sys.path.append(app_root)
class route:
    def run(self,path):
        if not path:
            arrPath = []
        else:
            arrPath = path.split('/')
        controller = self.createController(arrPath)
        controller.setUrlPath(path)
        
        renderObject = render.Render.Render()
        return controller.run(renderObject)
        
    def GET(self,path):
        return self.run(path)
        
    def POST(self,path):
        return self.run(path)
        
    def createController(self,arrPath):
        if not arrPath :
            controller = self.createIndexController()
        else:
            if controllerClass != None:
                controller = controllerClass()
            else:
                controller = self.createNotFoundController()
        return controller
        
        modPath = 'app.controller.' + ".".join(arrPat
"""
Common routines functions
"""
django.settings_module('weblines.settings.dev')
app_paths = filter(lambda x: x.startswith('weblines'), settings.INSTALLED_APPS)
apps = map(lambda x: x.split('.')[-1], app_paths)
def _manage(command, settings='weblines.settings.dev'):
    """
    Runs manage.py with given parameters
    Arguments:
    - `command`: command to execute
    - `settings`: settings to use (defaults to development)
    """
    local('python manage.py %s --settings=%s' % (command, settings))
def dev_initdb():
    """
    Initializes development database and performs initial migrations
    """
    for app in apps:
        _manage('schemamigration --initial %s' % app)
    _manage('syncdb --migrate')
def dev_migrate(*apps):
    """
    Migrates given applications (development)
    Arguments:
    - `apps`: applications to migrate
    """
    for app in apps:
        try:
            _manage('schemamigration --auto %s' % app)
            _manage('migrate %s' % app)
        except:
 

