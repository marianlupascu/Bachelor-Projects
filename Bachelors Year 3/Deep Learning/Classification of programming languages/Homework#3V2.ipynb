{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework#3V2.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"iNyPs7XfTbBW","colab_type":"text"},"cell_type":"markdown","source":["# Homework 3\n","\n","\n","You will train a recurrent neural network that takes a code snippet and predicts which programming language it is written in. \n","\n","The dataset contains 11103 snippets for train and 2995 snippets for test from 6 programming languages: C++, C#, Python, JavaScript, HTML and SQL. Each programming language is almost equaly represented in the dataset.  The dataset is found in the course Google Drive folder lab03-tema03/\\*-data-split, each snippets in a separate file and the labels are stored as dictionary in  lab03-tema03/code-\\*-gt.json using filename as identifier. The dataset is a subset of the dataset used in [deep-learning-lang-detection](https://github.com/aliostad/deep-learning-lang-detection), that we cut in chunks of length 1000.\n","\n","Your task is to investigate the best network architecture for this problem tuning RNN's hyperparameters (temperature, hidden_size) and  the maximum length of sequences used for training (you don't have to use the entire sequence of 1000 characters given in dataset).\n","\n","For your models you have to report: \\\\\n","1.  Accuracy of the model on test set computed as: $\\frac{\\#correct\\ predictions}{\\#total\\ predictions}$\n","2.   Confusion matrix: a matrix of $6 \\times 6$ where $M_{i,j}$ is the number of examples from class $i$ classified by your model as $j$. How do you interpret these results?\n","\n","\n","\n","\n"," \n","\n","\n","\n","\n","\n"]},{"metadata":{"id":"LvYF5IlFMZX1","colab_type":"code","outputId":"3ab41762-4d4a-4dd0-85aa-f5679c8f6d74","executionInfo":{"status":"ok","timestamp":1554885684128,"user_tz":-180,"elapsed":1457,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import files, auth, drive\n","from urllib.request import urlopen\n","from typing import List, Dict, Callable\n","from collections import Counter\n","from os import path\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.optim import SGD, Adam\n","from matplotlib import pyplot as plt\n","import glob\n","import unicodedata\n","import string\n","\n","############################## CONSTANTS #######################################\n","def findFiles(path): return glob.glob(path)\n","\n","def readfile(filepath: str) -> str:\n","    \"\"\"\n","    Reads file and returns its content as a string.\n","    \"\"\"\n","    #response = urlopen(url)\n","    #body = response.read().decode('utf-8')\n","    with open(filepath, \"r\") as f:\n","        body = f.read()\n","    \n","    return body.encode('ascii', 'ignore').decode(\"utf-8\")\n","\n","ROOT_COLAB_FOLDER = \"/content\"\n","filename = \"*.txt\" #modify filename here\n","filepath = path.join(ROOT_COLAB_FOLDER, filename)\n","print(findFiles(filepath))\n","\n","category_code = {}\n","all_categories = []\n","  \n","for filename in findFiles(filepath):\n","    category = filename[len(ROOT_COLAB_FOLDER) + 1:filename.find('.txt')]\n","    print(category)\n","    all_categories.append(category)\n","    code = readfile(filename)\n","    category_code[category] = code\n","\n","n_categories = len(all_categories)\n","\n","#make sure the text is properly read\n","for i in all_categories:\n","  print()\n","  print(\"Size of text \" + i + \" characters: \" + str(len(category_code[i])))\n","  print(\"First 300 characters: \\n\", category_code[i][0:300])"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[]\n"],"name":"stdout"}]},{"metadata":{"id":"-M_wxSZHWvA1","colab_type":"code","outputId":"42a48072-27e2-4c30-cddf-2d98a192e2cb","executionInfo":{"status":"ok","timestamp":1554835904057,"user_tz":-180,"elapsed":1067,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["class Vocabulary:\n","    \"\"\"\n","    Helper class that maps characters to unique indices and the other way around\n","    \"\"\"\n","    def __init__(self, text: str):\n","        #special character for padding shorter sequences in a mini-batch\n","        characters_set = set(\"<PAD>\") \n","        characters_set.update(text)\n","        \n","        self.char_to_idx = {char:idx for (idx, char) \n","                            in enumerate(characters_set)}\n","        self.idx_to_char = {idx:char for (idx, char) \n","                            in enumerate(characters_set)}\n","   \n","    def size(self):\n","        return len(self.char_to_idx)\n","      \n","    def __str__(self):\n","        return str(self.char_to_idx)\n","\n","text = \"\"\n","for i in all_categories:\n","  text = text + category_code[i]\n","\n","vocab = Vocabulary(text)\n","print(\"Vocabulary size: \", vocab.size())\n","print(\"Vocabulary: \\n\", vocab)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Vocabulary size:  98\n","Vocabulary: \n"," {'?': 0, '_': 1, 'J': 2, 'n': 3, '}': 4, '^': 5, 'C': 6, 'w': 7, 'j': 8, 'E': 9, 'D': 10, 'o': 11, '$': 12, '6': 13, 'p': 14, '3': 15, '(': 16, '5': 17, 'f': 18, '\\x01': 19, 'b': 20, '`': 21, '#': 22, '&': 23, 'Y': 24, 'y': 25, '4': 26, ')': 27, ' ': 28, ']': 29, '[': 30, '|': 31, 'I': 32, '!': 33, 't': 34, 'i': 35, 'B': 36, 'A': 37, 'O': 38, '1': 39, '@': 40, '.': 41, 'e': 42, 'z': 43, 'a': 44, '\\n': 45, 'g': 46, 'r': 47, '-': 48, 'R': 49, 'h': 50, 'l': 51, 'H': 52, 'Z': 53, 'W': 54, 'Q': 55, '7': 56, 'd': 57, '\\\\': 58, 's': 59, '*': 60, ',': 61, '<': 62, ';': 63, \"'\": 64, 'N': 65, 'U': 66, 'k': 67, '2': 68, 'T': 69, 'V': 70, 'K': 71, '{': 72, 'P': 73, 'F': 74, 'G': 75, '%': 76, '~': 77, 'S': 78, '0': 79, '\"': 80, '>': 81, '+': 82, '9': 83, 'M': 84, '=': 85, 'c': 86, 'u': 87, '8': 88, ':': 89, 'X': 90, 'L': 91, 'x': 92, 'q': 93, 'm': 94, 'v': 95, '\\t': 96, '/': 97}\n"],"name":"stdout"}]},{"metadata":{"id":"ytdlQeRNXDh4","colab_type":"code","outputId":"becc4f74-2033-4b4c-ab5f-69ad21886f36","executionInfo":{"status":"ok","timestamp":1554836315212,"user_tz":-180,"elapsed":2201,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"cell_type":"code","source":["def text_to_tensor(text: str, vocab: Vocabulary) -> torch.LongTensor:\n","    \"\"\"\n","    Convert a string to a Tensor with corresponding character indices\n","    e.g. \"We have\" -> [12, 6, 20, 13, 1, 25, 6] \n","    \"\"\"\n","    text_indices = [vocab.char_to_idx[c] for c in text]\n","    \n","    return torch.tensor(text_indices)\n","  \n","def tensor_to_text(x: torch.LongTensor, vocab: Vocabulary) -> str:\n","    \"\"\"\n","    Convert a Tensor of character indices to its string representation\n","    e.g. [12, 6, 20, 13, 1, 25, 6] -> \"We have\"\n","    \"\"\"\n","    return \"\".join(vocab.idx_to_char[idx.item()] for idx in x)\n","\n","def batch_tensor_to_text(x: torch.LongTensor, vocab: Vocabulary) -> List[str]:\n","    \"\"\"\n","    The batched version of tensor_to_text\n","    E.g. [[2, 1, 3, 0, 0], [3, 1, 20]] -> [bac, cat]\n","    :param x: Tensor of size (batch_size x time_steps)\n","    :return: a list of corresponding strings \n","    \"\"\"\n","    assert len(x.size()) == 2, \"wrong number of dimensions (should be 2)\"\n","    outputs = []\n","    for batch_idx in range(len(x)):\n","        outputs.append(tensor_to_text(x[batch_idx], vocab))\n","            \n","    return outputs \n","  \n","#check that a random text is correctly converted to numbers and back to text\n","random_text = \"I have apples\"\n","encoded_text = text_to_tensor(random_text, vocab)\n","decoded_text = tensor_to_text(encoded_text, vocab)\n","assert random_text == decoded_text, \"Not the same text as the original\"\n","print(encoded_text)\n","print(decoded_text)\n","\n","#convert input text to numbers\n","data = {}\n","for i in all_categories:\n","  print(i)\n","  data[i] = text_to_tensor(category_code[i], vocab)\n","  print(\"Size of input tensor is: \", data[i].size(0))\n","  print()\n","\n","#setup device (CPU/GPU)\n","if torch.cuda.is_available():\n","    device = torch.device('cuda:0')\n","else:\n","    device = torch.device('cpu')\n","\n","    \n","print(device)\n","#move tensor to CUDA if available\n","for i in all_categories:\n","  data[i] = data[i].to(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([32, 28, 50, 44, 95, 42, 28, 44, 14, 14, 51, 42, 59])\n","I have apples\n","c++\n","Size of input tensor is:  2197116\n","\n","Python\n","Size of input tensor is:  1632935\n","\n","Java\n","Size of input tensor is:  1549090\n","\n","JavaScript\n","Size of input tensor is:  1201462\n","\n","c#\n","Size of input tensor is:  2094366\n","\n","SQL\n","Size of input tensor is:  2623772\n","\n","cuda:0\n"],"name":"stdout"}]},{"metadata":{"id":"KryfCCvwYorH","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_batches(x: torch.LongTensor, batch_size: int, max_len: int) -> \\\n","            (List[torch.LongTensor], List[torch.LongTensor]):\n","    \"\"\"\n","    Returns a list of Tensors of size (batch_size x max_len), that represent\n","    the inputs and outputs for each feedforward call through the network\n","    :param x: Tensor of size textsize\n","    :param batch_size: number of examples 'seen' at a time\n","    :param max_len: number of steps to unroll the RNN\n","    \"\"\"\n","    #ensure full batches (trim extra-content)\n","    text_size = len(x)\n","    num_iterations = text_size // (batch_size * max_len)\n","    assert num_iterations > 0, \"large batch_size/max_len or short text\"\n","    trimmed_size = num_iterations * batch_size * max_len\n","    x_trim = x[:trimmed_size]   \n","    #B x (T x num_iter)\n","    x_trim = x_trim.reshape((batch_size, -1))\n","       \n","    #we'll use T=0 (shifted upwards) as the last prediction\n","    first_column = x_trim[:, 0].clone()\n","    first_column[:-1] = first_column[1:]\n","    \n","    x_batches = [] #inputs\n","    y_batches = [] #outputs (inputs shifted to the left by one)\n","    for iter in range(0, (num_iterations-1) * max_len, max_len):\n","        #Tensors of size (batch_size x max_len)\n","        current_x = x_trim[:, iter: iter + max_len]\n","        current_y = torch.zeros_like(current_x)\n","        current_y[:,:] = x_trim[:, iter + 1: iter + max_len + 1]\n","        yield current_x, current_y\n","        \n","    iter += max_len\n","    current_x = x_trim[:, iter: iter + max_len]\n","    current_y = torch.zeros_like(current_x)\n","    current_y[:,:-1] = x_trim[:, iter + 1: iter + max_len]\n","    current_y[:,-1] = first_column\n","    print(current_x.shape)\n","    print(current_y)\n","    \n","    yield current_x, current_y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HmgZaXEpYv7M","colab_type":"code","outputId":"325e538d-ccaa-448b-8387-7b4ba004cba1","executionInfo":{"status":"ok","timestamp":1554836371782,"user_tz":-180,"elapsed":765,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"cell_type":"code","source":["#split corpus into training/eval set\n","train_data = {}\n","dev_data = {}\n","\n","for i in all_categories:\n","  train_dev_cutoff = int(len(data[i]) * 0.8)\n","  train_data[i], dev_data[i] = data[i][:train_dev_cutoff], data[i][train_dev_cutoff:]\n","  print(i)\n","  print(\"Training set size = \", len(train_data[i]))\n","  print(\"Evaluation set size = \", len(dev_data[i]))\n","  print()\n","  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["c++\n","Training set size =  1757692\n","Evaluation set size =  439424\n","\n","Python\n","Training set size =  1306348\n","Evaluation set size =  326587\n","\n","Java\n","Training set size =  1239272\n","Evaluation set size =  309818\n","\n","JavaScript\n","Training set size =  961169\n","Evaluation set size =  240293\n","\n","c#\n","Training set size =  1675492\n","Evaluation set size =  418874\n","\n","SQL\n","Training set size =  2099017\n","Evaluation set size =  524755\n","\n"],"name":"stdout"}]},{"metadata":{"id":"3DVAvvIda-PK","colab_type":"code","outputId":"cc6f2fda-4a43-44b9-d112-be32def49695","executionInfo":{"status":"ok","timestamp":1554836590729,"user_tz":-180,"elapsed":807,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"cell_type":"code","source":["def print_sep(s: str, max_string_len: int):\n","    num_rows = len(s) // max_string_len\n","    for i in range(0, len(s), max_string_len):\n","        print(\"|\" + s[i:i+max_string_len] + \"|\")\n","\n","print(\"First 250 characters: \\n\")\n","print_sep(tensor_to_text(train_data['c++'][:250], vocab), 15)\n","\n","#CHECKPOINT: verify the batches are correctly split\n","it = make_batches(train_data['c++'][0:250], 2, 15)\n","xb, yb = next(it)\n","print(\"First batch input: \", batch_tensor_to_text(xb, vocab))\n","print(\"First batch output: \", batch_tensor_to_text(yb, vocab))\n","\n","xb2, yb2 = next(it)\n","print(\"Second batch input: \", batch_tensor_to_text(xb2, vocab))\n","print(\"Second batch output: \", batch_tensor_to_text(yb2, vocab))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["First 250 characters: \n","\n","|namespace grace|\n","| {\n","\tFormattedSt|\n","|ream& operator<|\n","|<(FormattedStre|\n","|am& stream, con|\n","|st char *cstr) |\n","|{\n","\t\tstream.writ|\n","|e((const byte*)|\n","|cstr, strlen(cs|\n","|tr));\n","\t\treturn |\n","|stream;\n","\t}\n","\tFor|\n","|mattedStream& o|\n","|perator<<(Forma|\n","|ttedStream& str|\n","|eam, const Stri|\n","|ng& str) {\n","\t\tst|\n","|ream.write|\n","First batch input:  ['namespace grace', 'cstr, strlen(cs']\n","First batch output:  ['amespace grace ', 'str, strlen(cst']\n","Second batch input:  [' {\\n\\tFormattedSt', 'tr));\\n\\t\\treturn ']\n","Second batch output:  ['{\\n\\tFormattedStr', 'r));\\n\\t\\treturn s']\n"],"name":"stdout"}]},{"metadata":{"id":"PUW6DZkFesW4","colab_type":"code","outputId":"7e883dfe-1cc3-4f26-b9f5-3c1bbec2927d","executionInfo":{"status":"ok","timestamp":1554836566570,"user_tz":-180,"elapsed":814,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":445}},"cell_type":"code","source":["char_idx = torch.LongTensor([7])\n","\n","#create one-hot representation for 7\n","#this is a vector of zeroes, except for the 7th position, where it has a one\n","char_one_hot = torch.zeros(vocab.size())\n","char_one_hot[char_idx] = 1\n","print(\"One-hot representation for 7th caracter: \", char_one_hot)\n","print(\"Lungimea: \", len(char_one_hot))\n","#create an Embedding layer that outputs vectors of size 100; \n","#behind the scenes, this is just a weight matrix of size vocab_size x 100\n","emb_layer = nn.Embedding(vocab.size(), 100)\n","W = emb_layer.weight #this is the actual weight matrix \n","print(\"Embedding matrix size: \", W.size())\n","\n","#multiplying the one-hot vector for 7 by the weight matrix results in a vector \n","#equal to the 7th row of the matrix\n","emb_one_hot = char_one_hot @ W\n","print(\"emb_one_hot size: \", emb_one_hot.size())\n","\n","#the emb_layer receives an index and returns the corresponding row at that index\n","#in the weight matrix\n","emb_idx = emb_layer(char_idx).squeeze()\n","print(\"emb_idx size: \", emb_idx.size())\n","\n","if emb_one_hot.equal(emb_idx):\n","    print(\"Same embedding\")\n","print(\"Linia de la embeding: \",emb_one_hot)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["One-hot representation for 7th caracter:  tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.])\n","Lungimea:  98\n","Embedding matrix size:  torch.Size([98, 100])\n","emb_one_hot size:  torch.Size([100])\n","emb_idx size:  torch.Size([100])\n","Same embedding\n","Linia de la embeding:  tensor([-0.4652, -0.3383, -0.2366, -0.9458, -0.0673,  0.0742,  1.8724, -1.7292,\n","         3.0229,  0.2072, -0.0639, -0.6216,  1.4046,  1.9400, -1.1855, -0.3109,\n","        -0.2615, -1.7154, -0.6424,  2.0074, -0.5707, -1.5453, -1.2147, -0.1858,\n","         2.0269, -1.5341, -0.3681, -1.1851,  0.6836,  1.4045,  0.7220,  0.3528,\n","        -0.0235, -1.0681, -0.7607,  0.6801,  0.7401, -0.1554,  2.3022,  1.3138,\n","        -0.3417,  0.5316, -1.2903, -0.1666,  0.2045, -0.1489,  0.7947, -0.0787,\n","         0.8506, -0.0447,  1.4510,  0.0378,  1.3405, -0.2988,  0.9277,  0.7758,\n","         1.0297, -0.3727,  1.3900, -0.6460, -2.2195, -0.5202,  0.6283, -0.8852,\n","         1.3630, -0.5934, -1.9258, -0.7169,  0.0156, -0.9813, -1.5402, -0.1608,\n","        -0.0039,  1.5928,  0.9317,  0.2927, -1.1144, -1.3896,  1.2279, -1.2715,\n","         0.9508,  1.4971, -1.2693, -0.8059,  1.3479, -1.6772,  0.1456,  2.4553,\n","         0.4275, -1.6204, -0.6523,  0.1985,  0.1867,  0.5894, -0.2852, -0.2466,\n","        -0.8889, -0.1091, -0.1378,  1.8690], grad_fn=<SqueezeBackward3>)\n"],"name":"stdout"}]},{"metadata":{"id":"scOocLEefASr","colab_type":"code","colab":{}},"cell_type":"code","source":["############################## PARAMETERS ######################################\n","_hyperparameters_dict = {\n","    \"batch_size\": 32,\n","    \"num_epochs\": 10,\n","    \"max_len\": 250,\n","    \"embedding_size\": 100, \n","    \"rnn_size\": 512,\n","    \"learning_algo\": \"adam\",\n","    \"learning_rate\": 0.001,\n","    \"max_grad_norm\": 5.0\n","}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LjaWrqwRfCrY","colab_type":"code","colab":{}},"cell_type":"code","source":["class RNNLM(nn.Module):\n","    def __init__(self, vocab_size: int, char_embedding_size: int, \n","                 rnn_size: int):\n","        super().__init__()\n","        #TODO\n","        self.vocab_size = vocab_size\n","        self.char_embedding_size = char_embedding_size\n","        self.rnn_size = rnn_size\n","        \n","        self.embedding = nn.Embedding(num_embeddings = vocab_size, \n","                                      embedding_dim = char_embedding_size)\n","\n","        self.rnn_cell = nn.GRUCell(input_size = char_embedding_size,\n","                                   hidden_size = rnn_size)\n","        self.logits = nn.Linear(in_features=rnn_size, out_features=vocab_size)\n","        self.softmax = nn.Softmax(dim = 2)\n","        \n","        self.loss = nn.CrossEntropyLoss()\n","    \n","    def get_loss(self, logits: torch.FloatTensor, y: torch.FloatTensor):\n","        \"\"\"\n","        Computes loss for a batch of sequences. The sequence loss is the \n","        average of the individual losses at each timestep. The batch loss is\n","        the average of sequence losses across all batches.\n","\n","        :param logits: unnormalized probabilities for T timesteps, size\n","                       batch_size x max_timesteps x vocab_size\n","        :param y: ground truth values (index of correct characters), size\n","                  batch_size x max_timesteps\n","        :returns: loss as a scalar\n","        \"\"\"\n","\n","        return self.loss(logits.permute(0, 2, 1), y)\n","        \n","    \n","    def get_logits(self, hidden_states: torch.FloatTensor, \n","                   temperature: float = 1.0):\n","        \"\"\"\n","        Computes the unnormalized probabilities from hidden states. Optionally\n","        divide logits by a temperature, in order to influence predictions at \n","        test time (https://www.quora.com/What-is-Temperature-in-LSTM)\n","        \n","        :param hidden_states: tensor of size batch_size x timesteps x rnn_size\n","        :param temperature: coefficient that scales outputs before turning them \n","        to probabilities. A low temperature (0.1) results in more conservative \n","        predictions, while a higher temperature (0.9) results in more diverse\n","        predictions\n","        \n","        :return: tensor of size batch_size x timesteps x vocab_size\n","        \"\"\"\n","        return self.logits(hidden_states) / temperature\n","        \n","    def forward(self, x: torch.LongTensor, \n","                hidden_start: torch.FloatTensor = None) -> torch.FloatTensor:\n","        \"\"\"\n","        Computes the hidden states\n","        for the current batch (x, y). \n","        :param x: input of size batch_size x max_len\n","        :param hidden_start: hidden state at time step t = 0, \n","                             size batch_size x rnn_size\n","        :return: hidden states at all timesteps, \n","                 size batch_size x timesteps x rnn_size\n","        \"\"\"\n","        max_len = x.size(1)\n","        \n","        #batch_size x max_len x embedding_dim\n","        x_embedded = self.embedding(x)\n","        \n","        #compute hidden states and logits for each time step\n","        hidden_states_list = []\n","        prev_hidden = hidden_start\n","        for t in range(max_len):\n","            hidden_state = self.rnn_cell(x_embedded[:,t,:], prev_hidden)\n","            hidden_states_list.append(hidden_state)\n","            prev_hidden = hidden_state\n","        \n","        #batch_size x max_len x rnn_size\n","        hidden_states = torch.stack(hidden_states_list, dim=1)\n","        \n","        return hidden_states"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d8eOB4EAfScU","colab_type":"code","colab":{}},"cell_type":"code","source":["#instantiate the RNNLM module\n","network = RNNLM(vocab.size(), \n","            _hyperparameters_dict['embedding_size'], \n","            _hyperparameters_dict['rnn_size'])\n","\n","# move network to GPU if available\n","network = network.to(device)\n","\n","optimizer = Adam(params = network.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"73BbSqu_fVOR","colab_type":"code","outputId":"8b93d59a-a8ea-4000-a993-a0bd42031696","executionInfo":{"status":"ok","timestamp":1554838770883,"user_tz":-180,"elapsed":574,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["# CHECKPOINT: make sure you understand each parameter size\n","print(\"Neural network parameters: \")\n","for param_name, param in network.named_parameters():\n","    print(\"\\t\" + param_name, \" size: \", param.size())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Neural network parameters: \n","\tembedding.weight  size:  torch.Size([98, 100])\n","\trnn_cell.weight_ih  size:  torch.Size([1536, 100])\n","\trnn_cell.weight_hh  size:  torch.Size([1536, 512])\n","\trnn_cell.bias_ih  size:  torch.Size([1536])\n","\trnn_cell.bias_hh  size:  torch.Size([1536])\n","\tlogits.weight  size:  torch.Size([98, 512])\n","\tlogits.bias  size:  torch.Size([98])\n"],"name":"stdout"}]},{"metadata":{"id":"lAPpim6yfZDi","colab_type":"code","colab":{}},"cell_type":"code","source":["# CHECKPOINT: make sure you can feedforward and backpropagate through network\n","iterator = make_batches(train_data['c++'], 32, 20)\n","xb, yb = next(iterator)\n","\n","hidden_start = torch.zeros(_hyperparameters_dict[\"batch_size\"],\n","                            _hyperparameters_dict[\"rnn_size\"]).to(device)\n","hidden_states = network(xb, hidden_start)\n","logits = network.get_logits(hidden_states)\n","loss = network.get_loss(logits, yb)\n","loss.backward()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dShA4DnInQvT","colab_type":"code","outputId":"75c19234-b727-476d-bdeb-aae1652c2a1a","executionInfo":{"status":"ok","timestamp":1554838824734,"user_tz":-180,"elapsed":12279,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["#train the network for 60 iterations and save save hidden states (one slice of \n","#the batch) every 30 iterations\n","iterator = make_batches(train_data['c++'], 32, 50)\n","\n","hidden_states_it = [] #list of tensors of size timesteps x rnn_size\n","prev_hidden = torch.zeros(_hyperparameters_dict[\"batch_size\"],\n","                           _hyperparameters_dict[\"rnn_size\"]).to(device)\n","for it in range(300):\n","    xb, yb = next(iterator)\n","    \n","    #gradients are set to zero every new batch\n","    optimizer.zero_grad()\n","    \n","    #feedforward\n","    hidden_states = network(xb, prev_hidden)\n","    logits = network.get_logits(hidden_states)\n","    loss = network.get_loss(logits, yb)\n","    \n","    #backpropagation -> compute gradient of loss with respect to all weights\n","    loss.backward()\n","    \n","    #clip gradients if they get have norm > 5.0\n","    torch.nn.utils.clip_grad_norm_(list(network.parameters()), 5.0)\n","    \n","    #update weights \n","    optimizer.step()\n","    \n","    #the hidden states from iteration it should no longer be linked to \n","    #the hidden states from iteration (it+1)\n","    hidden_states.detach_()\n","    \n","    if it % 60 == 0:\n","        print(\"Iteration %d, loss = %f\" %(it, loss))\n","        hidden_states_it.append(hidden_states[0,:,:].cpu())\n","        \n","    prev_hidden = hidden_states[:,-1,:]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Iteration 0, loss = 4.585721\n","Iteration 60, loss = 2.626531\n","Iteration 120, loss = 2.180661\n","Iteration 180, loss = 1.848908\n","Iteration 240, loss = 1.647804\n"],"name":"stdout"}]},{"metadata":{"id":"06fj1HFWo8Ku","colab_type":"code","colab":{}},"cell_type":"code","source":["class Trainer:\n","    def __init__(self, model: nn.Module, \n","                 train_data: torch.LongTensor, \n","                 dev_data: torch.LongTensor,\n","                 vocab: Vocabulary, \n","                 hyperparams: Dict):\n","        self.model = model\n","        self.train_data = train_data\n","        self.dev_data = dev_data\n","        self.vocab = vocab\n","        if hyperparams['learning_algo'] == 'adam':\n","            self.optimizer = Adam(params = self.model.parameters(),\n","                                  lr = hyperparams['learning_rate'])\n","        else:\n","            self.optimizer = SGD(params = self.model.parameters(), \n","                                 lr = hyperparams['learning_rate'])\n","        self.num_epochs = hyperparams['num_epochs']\n","        self.max_len = hyperparams['max_len']\n","        self.batch_size = hyperparams['batch_size']\n","        self.rnn_size = hyperparams['rnn_size']\n","        self.max_grad_norm = hyperparams['max_grad_norm']\n","        \n","        #number of characters in training/dev data\n","        self.train_size = len(train_data)\n","        self.dev_size = len(dev_data)\n","        \n","        #number of sequences (X, Y) used for training\n","        self.num_train_examples = \\\n","          self.train_size // (self.batch_size * self.max_len) * self.batch_size\n","        \n","    def get_l(self):\n","        return self.num_train_examples\n","    def train_epoch(self, epoch_num: int) -> float:\n","        \"\"\"\n","        Compute the loss on the training set\n","        :param epoch_num: number of current epoch\n","        \"\"\"\n","        self.model.train()\n","        epoch_loss = 0.0\n","        hidden_start = torch.zeros(self.batch_size, self.rnn_size).to(device)\n","        for batch_num, (x, y) in enumerate(make_batches(self.train_data, \n","                                                       self.batch_size, \n","                                                       self.max_len)):\n","            # reset gradients\n","            self.optimizer.zero_grad()\n","          \n","            # compute hidden states\n","            # batch x timesteps x hidden_size\n","            hidden_states = self.model(x, hidden_start)\n","            \n","            # compute unnormalized probabilities\n","            # batch x timesteps x vocab_size\n","            logits = self.model.get_logits(hidden_states)\n","            \n","            # compute loss\n","            # scalar\n","            batch_loss = self.model.get_loss(logits, y)\n","            epoch_loss += batch_loss.item()\n","                       \n","            # backpropagate loss\n","            batch_loss.backward()\n","            \n","            # clip gradients if they get too large\n","            torch.nn.utils.clip_grad_norm_(list(self.model.parameters()), \n","                                           self.max_grad_norm)\n","            \n","            # update parameters\n","            self.optimizer.step()\n","            \n","            # we use a stateful RNN, which means the first hidden state for the\n","            # next batch is the last hidden state of the current batch\n","            hidden_states.detach_()\n","            hidden_start = hidden_states[:,-1,:]\n","            \n","            if batch_num % 100 == 0:\n","                print(\"epoch %d, %d/%d examples, batch loss = %f\"\n","                      % (epoch_num, (batch_num + 1) * self.batch_size, \n","                         self.num_train_examples, batch_loss.item()))\n","        epoch_loss /= (batch_num + 1)\n","        \n","        return epoch_loss\n","\n","    def eval_epoch(self, epoch_num: int) -> float:\n","        \"\"\"\n","        Compute the loss on the validation set\n","        :param epoch_num: number of current epoch\n","        \"\"\"\n","        epoch_loss = 0.0\n","        hidden_start = torch.zeros(self.batch_size, self.rnn_size).to(device)\n","        with torch.no_grad():\n","            for batch_num, (x, y) in enumerate(make_batches(self.dev_data, \n","                                                            self.batch_size, \n","                                                            self.max_len)):    \n","                #batch x timesteps x hidden_size\n","                hidden_states = self.model(x, hidden_start)\n","            \n","                #batch x timesteps x vocab_size\n","                logits = self.model.get_logits(hidden_states)\n","            \n","                batch_loss = self.model.get_loss(logits, y)\n","                epoch_loss += batch_loss.item()\n","                \n","                # we use a stateful RNN, which means the first hidden state for \n","                # the next batch is the last hidden state of the current batch\n","                hidden_states.detach_()\n","                hidden_start = hidden_states[:,-1,:]\n","                \n","            epoch_loss /= (batch_num + 1)\n","        \n","        return epoch_loss    \n","            \n","    def train(self) -> Dict:\n","        train_losses, dev_losses = [], []\n","        for epoch in range(self.num_epochs):\n","            epoch_train_loss = self.train_epoch(epoch)\n","            epoch_dev_loss = self.eval_epoch(epoch)\n","            train_losses.append(epoch_train_loss)\n","            dev_losses.append(epoch_dev_loss)\n","        return {\"train_losses\": train_losses,\n","                \"dev_losses\": dev_losses}\n","\n","def plot_losses(metrics: Dict):\n","    \"\"\"\n","    Plots training/validation losses.\n","    :param metrics: dictionar\n","    \"\"\"\n","    plt.figure()\n","    plt.plot(metrics['train_losses'], c='b', label='Train')\n","    plt.plot(metrics['dev_losses'], c='g', label='Valid')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Iteration')\n","    plt.legend()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fD_iPw6xpI8s","colab_type":"code","outputId":"12dac807-c516-43a1-ab4f-b0d3832a22c2","executionInfo":{"status":"ok","timestamp":1554839782397,"user_tz":-180,"elapsed":481964,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":3247}},"cell_type":"code","source":["#train network for some epoch\n","trainer = Trainer(network, train_data['c++'], dev_data['c++'], vocab, _hyperparameters_dict)\n","\n","metrics = trainer.train()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch 0, 32/7008 examples, batch loss = 1.963238\n","epoch 0, 3232/7008 examples, batch loss = 1.579723\n","epoch 0, 6432/7008 examples, batch loss = 1.492762\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 1, 32/7008 examples, batch loss = 1.479077\n","epoch 1, 3232/7008 examples, batch loss = 1.281863\n","epoch 1, 6432/7008 examples, batch loss = 1.261931\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 2, 32/7008 examples, batch loss = 1.283405\n","epoch 2, 3232/7008 examples, batch loss = 1.113307\n","epoch 2, 6432/7008 examples, batch loss = 1.104397\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 3, 32/7008 examples, batch loss = 1.151888\n","epoch 3, 3232/7008 examples, batch loss = 0.998722\n","epoch 3, 6432/7008 examples, batch loss = 0.989291\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 4, 32/7008 examples, batch loss = 1.046733\n","epoch 4, 3232/7008 examples, batch loss = 0.909238\n","epoch 4, 6432/7008 examples, batch loss = 0.901118\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 5, 32/7008 examples, batch loss = 0.962064\n","epoch 5, 3232/7008 examples, batch loss = 0.838322\n","epoch 5, 6432/7008 examples, batch loss = 0.834367\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 6, 32/7008 examples, batch loss = 0.891728\n","epoch 6, 3232/7008 examples, batch loss = 0.781938\n","epoch 6, 6432/7008 examples, batch loss = 0.781867\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 7, 32/7008 examples, batch loss = 0.839478\n","epoch 7, 3232/7008 examples, batch loss = 0.732640\n","epoch 7, 6432/7008 examples, batch loss = 0.736320\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 8, 32/7008 examples, batch loss = 0.796679\n","epoch 8, 3232/7008 examples, batch loss = 0.696761\n","epoch 8, 6432/7008 examples, batch loss = 0.709305\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n","epoch 9, 32/7008 examples, batch loss = 0.765916\n","epoch 9, 3232/7008 examples, batch loss = 0.670130\n","epoch 9, 6432/7008 examples, batch loss = 0.676485\n","torch.Size([32, 250])\n","tensor([[ 6, 50, 87,  ..., 28, 72, 45],\n","        [72, 45, 28,  ..., 45, 28, 28],\n","        [18, 11, 47,  ..., 27, 63, 45],\n","        ...,\n","        [94, 14,  1,  ...,  1, 35,  3],\n","        [42, 47, 47,  ..., 28, 28, 28],\n","        [45, 28, 28,  ..., 34, 23, 28]], device='cuda:0')\n","torch.Size([32, 250])\n","tensor([[67, 60, 81,  ..., 50, 87,  3],\n","        [44,  3, 44,  ...,  7, 84, 11],\n","        [35,  3, 46,  ..., 31, 45, 28],\n","        ...,\n","        [60, 61, 28,  ..., 57, 73, 34],\n","        [28, 82, 28,  ..., 42,  3, 46],\n","        [34, 67, 38,  ..., 34, 30, 46]], device='cuda:0')\n"],"name":"stdout"}]},{"metadata":{"id":"-zRpLf5xpTyX","colab_type":"code","outputId":"285b2f24-5284-4169-dba9-d69a4d9b9209","executionInfo":{"status":"ok","timestamp":1554839782398,"user_tz":-180,"elapsed":455959,"user":{"displayName":"Maryan Lupascu","photoUrl":"https://lh4.googleusercontent.com/-5cPPRrZPzqk/AAAAAAAAAAI/AAAAAAAADv0/dOdZVhgPdXM/s64/photo.jpg","userId":"12443654402315242790"}},"colab":{"base_uri":"https://localhost:8080/","height":361}},"cell_type":"code","source":["#plot training and validations losses each epoch\n","plot_losses(metrics)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8U2X7BvArexZooZMhQ0BklYrI\nKDLLRoZIq0zhRRRBRfyJIAgKCrgFUZAXVDayFF7ZS5myymgREVSQli4ohSZp5vn9EWgptKVAcrKu\nr59+0pGe3twmufKc55znSARBEEBEREQ+Q+rpAoiIiOjeMLyJiIh8DMObiIjIxzC8iYiIfAzDm4iI\nyMcwvImIiHyM3NMFlFZm5nWXbi84WIvsbKNLt0lFY6/FwT6Lg30WB/vsFBoaVOT3A3bkLZfLPF1C\nwGCvxcE+i4N9Fgf7XLKADW8iIiJfxfAmIiLyMQxvIiIiH8PwJiIi8jEMbyIiIh/D8CYiIvIxDG8i\nIiIf4zOLtBAREYlt1qzP8Mcfv+PKlcvIy8tDVFRFlClTFh988FGJv7dhw3rodHq0atXGLXUxvImI\niIoxatRoAM4w/uuvcxg58rVS/V6XLt3dWZZ7w/vMmTMYMWIEBg8ejP79+xf62aVLl/D666/DarXi\n0UcfxXvvvefOUoiIiFzi6NHDWL58MYxGI0aOHI3ExCPYtWs7HA4HmjVrgSFDXsD8+XNRrlw5VKtW\nA2vW/ACJRIrz5/9G69btMGTICw9cg9vC22g0YsqUKWjWrFmRP58+fTqGDBmCuLg4vPvuu0hNTUVU\nVJS7yinEYDVg4/G1aFG+LcqoyoryN4mI6MFMnqzC+vWuja3u3W2YPNl8z7937txZLFu2BkqlEomJ\nR/DVV/+FVCpF3749EB//XKH7njqVjKVLV8PhcOCZZ7q7JLzddsCaUqnEvHnzEBYWdsfPHA4Hjhw5\ngrZt2wIAJk2aJFpwA8Bvl/Zj0I+D0HF1G5y58odof5eIiPzDww/XhFKpBACo1WqMHPkCRo0ajqtX\nr+LatWuF7lu79iNQq9XQarUu+/tuG3nL5XLI5UVv/sqVK9DpdJg2bRqSk5PRuHFjjBkzpsTtBQdr\nXbZQfZ/yT+H/rvwfPtr3ETqvaYuFvRai5yM9XbJtKlpxV8Yh12KfxcE+i+P2Ps+e7fxwLeWNj5IF\nBamh1SoRGhqEcuW00Ou1CA0NQkpKClatWoa1a9dCp9OhW7duCAnRQadTQa9Xo1w5LbRadf6/RSKR\nuOTx45ED1gRBQHp6OgYOHIiKFSvihRdewK5du9C6detif8fVl4b7MO5DPKyrg9d2voxeK3rh9cZv\n4s3Hx0Mq4dlzrhYaGuTyS7rSndhncbDP4vC2Pl+/ngej0YLMzOu4etUIs9mKzMzr+OuvFJQpUxZG\nowOJiYdw8WIK0tOvwmAwQ6HIK3RfwJl/9/Lv8qpLggYHByMqKgpVqlSBTCZDs2bN8Oeff4r29+12\n4NdfgR41+uDn3ttQJeghfHr4QwzckIBr5hzR6iAiIt9Ws2YtaDRavPTSEGzfvgU9evTGJ5/McPvf\n9cjIWy6Xo3Llyvjnn39QtWpVJCcno2vXrqL9/Z07ZXjuOWDiRCVGjaqPLc/swgtbhmDL+U3otLot\nvu+8DDWDa4lWDxERebdbT/2KiWmMmJjGAACZTIZPP/2yxN+9eV8A+Pnn7S6pRyIIguCSLd0mKSkJ\nM2bMQEpKCuRyOcLDw9G2bVtUqlQJcXFxOH/+PN566y0IgoBatWph8uTJkEqL3xHgyt0nOTnAE08E\nwWYTcPBgLkJCAJvDhvcPvIvZx76AXhGE2e2/Qedq4r2h8GfetvvLX7HP4mCfxcE+OxW329xt4e1q\nrv6fuGRJEEaPBoYPt2DKlILTBNb+uQqv7XwZJpsJYxqPxf89Po7z4A+IT0JxsM/iYJ/FwT47edWc\ntzd46SWgShUHFixQ4Px5Sf73e9UsmAf/5PAMDNr4LOfBiYjIqwRseKtUwPjxZlitEkybpir0s3oV\nnPPgT1Zqg83/bESn1W3xZ/YZD1VKRERUWMCGNwD07GlDw4Z2rFmjwPHjhVsRoi6P5d1WY0T0Kzh7\n9U90XNUGG//+2UOVEhERFQjo8JZKgXfecc53v/eeCrfP/sulckxuPhVz4ubDLtgwaOOzmHHwfTgE\nhweqJSIicgro8AaAli3taNfOht275di5s+gV3HrXfAb/672V8+BERAFm+PDncfr074W+N2fOl1i2\nbPEd9z169DAmTHgTAPDWW6/f8fPVq1dg/vy5Lqkr4MMbACZONEMiEfDuuyrY7UXfp36FBtjyzC60\nrNSa8+BERAEiLq4jduzYWuh7u3btQPv2HUr8venTP3VnWQxvAHj0UQfi4234/XcZVq4sft2aEHV5\nrOi2ptA8+Ka/N4hYKRERialduw749ded+V+fPv07QkND8c8/f2P48OcxcuQLGDduDKxWa6Hf69q1\nHQDg8OGDGDgwHq+9NgKnTiW7rC6PrLDmjcaONePHH+WYPl2FHj1s0GiKvt/NefAGoQ0xeudIDNyY\ngDcav4U3Hn+L54MTEbnR5H0TsP7cjy7dZvcaPTG5+dRifx4cHIKoqIo4dSoJjz5aDzt2bEVcXCdc\nv34dkyZNRVRURUyZ8g5++21/kVcNmzv3S0ycOAU1a9bCG2+8gqioii6pm2lzQ8WKAl54wYLUVCnm\nzbv7FWZunQf/+PB0DN74HOfBiYj8UFxcJ2zf7tx1vnfvr2jduh3KlSuHGTOmYuTIF5CYeATXrhX9\n+n/p0iXUrOlcbjs6OsZlNXHkfYtRoyxYtEiJmTOV6N/fgpCQku9/cx582JbnsemfDVwXnYjIjSY3\nn1riKNldWrVqg4ULFyAuriMqV66CMmXKYNq0Kfjoo89RtWo1fPpp8RciuXXZb1cuaMqR9y3KlgVe\nf92Ma9ck+Owz1d1/AZwHJyLyd1qtDjVq1MTChd8iLq4TAMBgyEV4eASuX7+Oo0eP3DHnfVOFCqG4\ncOEfCIKAxMQjLquJ4X2bwYOtRS6bWpKb8+Bft/8v7IINAzcm4MODH/B8cCIiPxEX1wmHDv2G2Ngn\nAQC9ez+Dl14aig8/fB/9+g3E4sXf4fLlrDt+74UXRmDChLEYO3Y0wsLCXVZPwF6YpKRF79eskePF\nFzXo3duKOXPy7mm7J7NOYPDG5/Dv9QvoVLULvmw3F2VUZV1Rss/iBQbEwT6Lg30WB/vsxAuT3IOS\nlk29m/oVGmBLn1/QslLr/Hlwng9ORESuxPAuwt2WTb2b8hrnPPhLDUdxHpyIiFyO4V2M0iybWhK5\nVI53W7xfaB78o0PTOA9OREQPjOFdgtIsm3o3T9fqi//13orKQVXw0aFpGLzxOVy3XHNtoUREFFAY\n3iUo7bKpd3P7PHjHVW04D05ERPeN4X0XY8eaoVYLmD5dBZPp/rfDeXAiInIVhvdd3OuyqSXhPDgR\nEbkCw7sURo2yIDhYwMyZSly58uDbe7pWX/yv1xbOgxMR0X1heJfC/Sybejf1Qxs658ErtuI8OBER\n3ROGdyndz7Kpd1NeUx4ruq/Fiw1H5s+Db/5no0u2TURE/ovhXUoqFTB+vBlWqwTTprlm9A0458Hf\na/FB/jz4gA3x+PjQdM6DExFRsRje9+BBlk29m1vnwT889AEGb+rHeXAiIioSw/seSKXApEn3v2zq\n3RSaB//7Z3Ra1RZns/907R8hIiKfx/C+R7GxD7Zs6t3cOg/+59Uz6Lia8+BERFQYw/s+uGLZ1JLc\nnAf/qv08WO0WzoMTEVEhDO/74KplU++mT614/HxjXfSb8+DphjS3/T0iIvINDO/75KplU+/m9nnw\n6IV18Pym/tj17w6OxImIAhTD+z65ctnUu7k5D/5xqy9Qp3xd/PzXOvRd3xNPLInGzKOfIdOY6da/\nT0RE3kUiCK4+Zto9MjOvu3R7oaFBD7zNnBygSRM97Hbg4MFchIS4qLgSCIKAxIwj+D55AX48uxom\nmwkKqQJdq3fHoLpD0TwqFhKJaxaRcRVX9Jrujn0WB/ssDvbZKTQ0qMjvc+T9ANyxbOrdSCQSxIQ3\nxhdtv8KJQX/gg9gPUaPcw/jx7Br0+qkrWixrjDnHv0R2ngsWYSciIq/EkfcDMpuBFi10uHRJgn37\nDHjoIfHbKQgCfks7gO+T5uN/f/0Es90MlUyFp2r0wsC6Q9Ak4gmPjsb5Dloc7LM42GdxsM9OHHm7\nibuWTb0XEokETSOb4eu4/+LYwNOY3Px9VNRXwsozy9F9bQe0XtEM80/OxTVzjkfqIyIi1+LI2wUc\nDqBjRy2OH5dh61YDGjb0/FHggiBgT8qvWJj8LTb8vR5WhxVauRY9H34ag+oOQXRYjGijcb6DFgf7\nLA72WRzssxNH3m5067Kp777r+mVT74dEIkHLSq0wr+N3SBz4OyY0nYwK2jAsPb0IHVe3QfuVT2Jh\n8rfItfDJQUTkaxjeLnJz2dQ9e+TYscP1y6Y+iDBtGF6JeR0H+x3D8m5r0KVad5y6nIQ3fnkV9b+v\njf/7ZTROZp3wdJlERFRK3G3uQqdOSdGmjRaPPOLAjh1GyLwrwwu5lJuKJb8vxOJT3yPVkAIAeCy8\nMQY+OgQ9Hu4NrULrsr/F3V/iYJ/FwT6Lg3124m5zETz6qAMJCe5fNtUVIvVReOPxt3B4wEks6rIC\ncQ91xNH0I3h15wg0+L42xu/+P5y+8runyyQioiJw5O1iqakSNG2qQ0iIgP37DdBoXP4n3Obf6xew\n5NT3WPz7QmQY0wEAT0Q2w6C6Q9Cteg+o5er72i7fQYuDfRYH+ywO9tmJI2+RREWJt2yqq1UOqoK3\nnpiIxAGnsKDjYrSq1Aa/XdqPEduGIXrhI5i0922cu8rrixMReRpH3m5wc9lUmw04eNCA8uV9osVF\n+jvnLyw+9T2WnV6ELFMWAKBlxVYYWPd5dK7WDUrZ3d+g8B20ONhncbDP4mCfnYobecsmT548WdxS\n7o/RaHHp9nQ6lcu3eZNaDSiVAjZtUsBmA9q2dcNFv0USrA5Gq8pt8J8GL6JOyKO4kncFe1J/xfpz\nP2LhqW+RnZeNKmUeQjl1cLHbcGevqQD7LA72WRy+1Gez3YyU3IswWHJRRlXGpdvW6Ype/Isjbzfx\nhmVT3eXP7DNYeOpbrDi9BFfNVyGBBK0rt8WgukPRoWonyKWFD9bjO2hxsM/iYJ/F4S19NlqNuGRI\nQWpuKi4ZUnEpNxWphpQbt6lIzU1Blsl5ZUeZRIaTg/9EBU0Fl/394kbeDG83WrNGjhdf1KB3byvm\nzMlz69/yBJPNhPXnfsT3yQtwKO03AECELhL96gxE/zqDUDGoEgDveRL6O/ZZHOyzONzdZ0EQcN1y\nDak3AvnSjSC+eesM6xRcNV8tdhtqmRqR+ihE6SoiUh+FuuXr46XokZBKXHc4GcP7NmI8Ab1x2VR3\nOXU5GQuTF2DlmRW4brkGqUSK9lU6YFDdIXi60VO4lu0bu798GUNFHOyzOB6kz4Ig4ErelRsj5ZQb\nAZ1yY6Rc8LnBmlvsNoKUZRCpi0SkLgpR+or5IR2lj0LkjdtyqmC3LzPN8L6NWE/APXtk6N1bi9hY\nG1avNsHLLrXtcgarAT/+uRoLTy1AYsZRAIBCqkDd8vUQHRaDRmGPITosBrWCa0Mm9eJVbHwQQ0Uc\n7LM4iuuzQ3Ag05TpDOAbo+PU3MKj5jTDJeTZi9/bGaIOQYQuClG6KETqnUF8c/TsvI1EkNK1c9f3\ni+F9GzGfgM8+q8H27XIsW2ZEu3a+e/DavTqReQw//LEMxy4fwbFLx2BxFIy+tXIdGoZFIzo0Bo3C\nYtAo/DFUCXrIo5cu9XUMFXGwz+5jtpuRbkhDmiENRlk2Tl86e2OkXDDPnGa8BJvDVuw2QjVht4yU\nb4yabxk9R+qioJH7zgIcHgnvM2fOYMSIERg8eDD69+9f5H0++eQTHDt2DIsWLSpxW74c3r60bKo7\nhIYGISXtMk5dTkJixlEcyziKxIwj+OPKaQgoePiFqEMQHRaD6LAYxIQ9huiwxxCmDfNg5b6FoSIO\n9vne2R12ZOVlIS03FWnGNKQZLuGSIfVGUF/CJcMlpBsu4XLe5WK3IZPIEK6NcIayvmLBqPmW0XO4\nNqJUp6/6kuLC221reBqNRkyZMgXNmjUr9j5nz57FoUOHoFAo3FWGV7i5bOqyZQqsXClHQkLx7xr9\nlVKmzA/mm3KtuTiZeRxH0484Az3zKHZc2IYdF7bl36eivlL+7vZGYTFoGBqNMqqynvgnENFtBEFA\njvkq0oxpuJSbivRbgjnNkIb0G8GcYUyHXSh+r6NeEYQIXQTqlK+LCF0kInSReDisKsqggnOXtr4i\nQjVhnGq7hdtG3jabDTabDfPmzUNwcHCRI+///Oc/GDZsGL788ku/HnkDvr1s6oO6l15fNl3G8cyj\nBYGecRSZpoxC93m4XM38MI8Oi0G9Cg3ue+lWf8IRoTgCpc9GqxFpxkuFRsdpN0bI+Z8b02CymYrd\nhlKqRIQuEuG6CEToIhGpi0S4LhIRN0bQEdpIROgioFfeOboMlD7fjegjb7lcDrm8+M2vWbMGTZo0\nQcWKFd1Vgle5uWzqzJkqzJunxCuv8OjropTXlEfbKnFoWyUOgPOdfWpuCo5mOMP8WMZRHMtMxMoz\ny7HyzHIAgFwqR52QuoUCvXbII3ecb05EgNVuRaYpI390nHYjiAt9GNOQU8IpUhJIEKoNQ63gRxCh\ni0C4NhKR+sj8MI7QRSFCF4kQdQiPY3ETtx+wNmvWrDtG3levXsXIkSPx7bffIj09HePGjbvryNtm\ns0Mu9+1dJjk5QI0agNUKnDsHVHDdefwBxSE4cObyGRxKOYRDqc6PxEuJMNvN+ffRKrSIiYzB41GP\nOz8qPo4awTX4QkJ+SRAE5FpykZabhnRDuvM2Nz3/60u5l5B6PRWp11ORnpte6FiT2wWrgxEVFIWo\noChULHPjSOybnwdFoWJQRYTrw/nm2MM8Et6bNm3CzJkzodfrYbFYcOHCBfTp0wfjx48vdju+vtv8\nprlzFZg4UY3hwy2YMsV891/wA2L02mK34PSVU/kHxB1NP4I/sn+HQyg4t76cqtyN+fMYRN8YpUfo\nIt1al5i4m1EcYvbZYDUg05iBDGMGMk0ZyDCm3/m1KROZxvQSd18DgEauyZ9PjtAWjI4jdBGI1EUh\nXBeBcG0EtAqtKP+2u+Hj2cljp4oVFd63unjxYqlG3v4S3v68bGpxPNVrg9WAk1kncCzjCBLTjyAx\n4yj+ufZ3oftE6qJuCfQYRIc2KnGddm/GFztxPGifTTYTMvPDN+NGGKcX8XVmiYuIAM4po1BNGEK1\nYQi7easNR6gm1Hl7y9dlVeV8as8TH89Oos95JyUlYcaMGUhJSYFcLsfmzZvRtm1bVKpUCXFxce76\ns15PpQLeftuM4cM1mDZN5ZfLpnoLnUKHppHN0DSy4IyH7LwrOJaRiMSMggPiNv79P2z8+3/596le\ntgYqB1VBsDoY5VTBN25DUE5VDuXUwQhWBRe6VcmKvnAABQ6z3YwsY+adIWxKR+Zt379uuVbitqQS\nKSpoQlGtbPXbQjgMoZqwQl+XUwW7dClO8h1cpMUDbl02dcsWA6Kj/XfZVMD730Ffyk3NPyAuMeMo\nTmQmlrie8e20ci3K3RboN28Lwv+W2xs/08q1Lh0JeXufvZUgCDDbzTDaDDBYb37k5n9utBb+vllq\nwPnL/xYK5bs9XiSQoLymwo3wvXWEfOfXIeoQnhIFPp5v4gprt/H0AyOQlk31dK/vR54tDznmq8g2\nZ+NqXnbJt7d8frdR1a2UUmXxgV/Mm4FgVTCClGWKDH1f7PO9sjlsd4SpwWoodfAabAYYrcZC9zFY\nc0s8B7kkIeqQ/NAN1Ra/27q8ujwP8LpHgfB4Lg3Rd5tTyWJj7WjXzobt2+XYsUMWUMum+gK1XA21\nPALhuoh7+j2r3YocSw5yzNnIznMGe3G3Nz/PNGXgz6tnCh1cVxKZRJa/C/9m0JdVlUM5fRDMebYb\nwS5x/ieRQALcuJUU3N7yOYr4XlH3k0hwj/e/UcctP5NKpPnbkUACi8N6R5AarQYYbEYYb/u+wWoo\ndEbB/dLKddApnB/B6pD8z3UKff7nBffRF/q5VqFF1fAoKMx6VNCEQiHz7wWmyHtx5O1BgbJsqjf0\n2ts5BAeuW67dGfS3jfSLehNgdVg9Xb5bqGQqaOXaOwJUp9BBq9DeCNPbvl/o/reEcX4oax94jpiP\nZ3Gwz04ceXshLptKN0klUpRVlUNZVTkA1Ur9e4IgwGAz4GpeNvRlFbh85ToEARAgQBAE5P8nCHd8\nD7d/r8j7o/j7F/W7N25R5HZR6HsOwQGVTJk/or195MtRLVHxGN4eNnasGWvXyjFtmgo9etgCatlU\nenASiQR6hR56hR6h5YNQzsGRClEg4DkGHnZz2dRLl6SYN8+/roZDRETuwfD2Aq+8YkFIiANffKHE\n5ct+fNg5ERG5BMPbC5QpA4webcH16xJ8/jlH30REVDKGt5cYPNiKKlUcWLBAgfPnOfomIqLiMby9\nxM1lU61WCaZN43KbRERUPIa3F+nRw4aGDe1Ys0aBY8f4v4aIiIrGhPAiUikwaZJzBan33lPBN5bP\nISIisTG8vUxsrB3t29uwZ49z2VQiIqLbMby90IQJZkgkAt57TwU7lzwnIqLbMLy90M1lU3//XYaV\nK7kIHhERFcbw9lJjx5qhVguYNk0Fk8nT1RARkTdheHspLptKRETFYXh7MS6bSkRERWF4ezEum0pE\nREVheHu5W5dN/ecfjr6JiIjh7fVuXTZ1+nQum0pERAxvn3DrsqmHD/N/GRFRoGMS+ACpFHj3XefC\nLYMHa3DhAnefExEFMoa3j2je3I6pU83IyJAiPl7Lo8+JiAIYw9uHDBtmxciRZpw7J0X//hoYjZ6u\niIiIPIHh7WMmTLCgTx8rjhyR4YUXNLDZPF0RERGJjeHtY6RS4PPP89C6tQ1btsjx5pu8dCgRUaBh\nePsgpRJYsMCEhg3tWLxYiQ8/5AIuRESBhOHto/R6YMkSEx56yIFPPlHh++8Vni6JiIhEwvD2YWFh\nAlasMKJ8eQfGjlVh40ZePpSIKBAwvH1c9eoCli41Qa0Ghg9X4+BB/i8lIvJ3fKX3A40aOTB/vglW\nK9C/vxZnzvB/KxGRP+OrvJ9o186Ozz7Lw9WrEiQkaJCWxkVciIj8FcPbjyQk2DB+vBkXL0qRkKDB\ntWueroiIiNyB4e1nXn3VgiFDLDh1SoZBgzQwmz1dERERuRrD289IJMD775vRrZsVe/fKMXKkGg6H\np6siIiJX4rlFfkgmA776Kg9ZWRL89JMC4eECpkwxQ8JpcCIiv8CRt59Sq4GFC0145BE7vvlGidmz\nuYgLEZG/YHj7sXLlgGXLTIiKcuC999RYuZI7WoiI/AHD289VrChg+XITypYV8OqrauzcKfN0SURE\n9IAY3gHgkUccWLTIBJkMGDJEgxMn+L+diMiX8VU8QDRtasfXX+fBaAQSEjT45x8evUZE5KsY3gGk\nWzcbpk0zIytLivh4LTIzGeBERL6I4R1ghgyx4rXXzPj7byn699cgN9fTFRER0b1ieAegceMsSEiw\nIjFRhmHDNLBaPV0RERHdC4Z3AJJIgE8+yUO7djZs3y7HmDFqCIKnqyIiotJieAcohQKYN8+ERo3s\nWL5cgenTlZ4uiYiISonhHcD0emDJEhOqVXPgs89UWLCAq7AREfkChneAq1BBwIoVRlSo4MC4cSr8\n739chY2IyNsxvAlVqwpYtswErRZ46SU1DhzgKmxERN7MreF95swZtG/fHosXL77jZwcOHEDfvn2R\nkJCAcePGwcHrVnpUw4YOLFhggt0ODBigwenTfF9HROSt3PYKbTQaMWXKFDRr1qzIn7/zzjuYOXMm\nli9fDoPBgN27d7urFCqlNm3s+OKLPOTkSJCQoEFKChdxISLyRm4Lb6VSiXnz5iEsLKzIn69ZswYR\nEREAgJCQEGRnZ7urFLoHzzxjw8SJZqSmSvHssxpcverpioiI6HZuC2+5XA61Wl3sz/V6PQAgIyMD\ne/fuRatWrdxVCt2jkSMtGDbMgtOnZRg0SIO8PE9XREREt/LoocWXL1/Giy++iEmTJiE4OLjE+wYH\nayGXu/ZAqtDQIJduz5/MmQPk5AA//CDH6NFBWLECkD1A+9lrcbDP4mCfxcE+F89j4Z2bm4thw4bh\ntddeQ2xs7F3vn51tdOnfDw0NQmbmdZdu09988gmQkqLB6tVyvPCCBdOmmSG5j2lw9loc7LM42Gdx\nsM9Oxb2B8dghxdOnT8egQYPw5JNPeqoEuguVCvj+exPq1LFjwQIlZs7kKmxERN7AbSPvpKQkzJgx\nAykpKZDL5di8eTPatm2LSpUqITY2Fj/++CPOnz+PVatWAQC6deuG+Ph4d5VD96lMGWD5chO6dtXi\n/fdVCA93ICHB5umyiIgCmkQQfOOSFK7efcJdMvfmzBkpunXT4vp1YPFiE9q1s5f6d9lrcbDP4mCf\nxcE+O3ndbnPyLbVqObB4sREKBTB0qAaJiXzoEBF5Cl+BqdSaNHFg7tw85OUB/fpp8NdfXMSFiMgT\nGN50Tzp3tmHGDDOysqSIj9ciI4MBTkQktlKFd1JSEnbu3AkA+OyzzzBo0CAcPnzYrYWR9xo0yIox\nY8w4f16K557TIDfX0xUREQWWUoX31KlTUa1aNRw+fBgnT57ExIkTMXPmTHfXRl7szTct6N/fghMn\nZBgyRAOLxdMVEREFjlKFt0qlQtWqVbF9+3b07dsXDz/8MKRS7nEPZBIJ8OGHZnToYMOuXXKMHq2G\nb5y3QETk+0qVwCaTCRs3bsS2bdsQGxuLq1ev4tq1a+6ujbycXA7MnWvCY4/ZsXKlAlOnchEXIiIx\nlCq8X3/9daxfvx6jR4+GXq/HokWLMHjwYDeXRr5Ap3Oe912jhgOzZqkwb57C0yUREfm9Uq2w1rRp\nU9SrVw96vR5ZWVlo1qwZYmJi3F0b+Yjy5QWsWGFEly5aTJigQliYgB49uAobEZG7lGrkPWXKFGzc\nuBFXr15FQkICFi9ejMmTJ7uyeGu9AAAgAElEQVS5NPIlVaoIWLbMBJ0OePllNfbude0V4IiIqECp\nwvvUqVN45plnsHHjRvTq1Quff/45zp8/7+7ayMfUr+/Ad9+ZIAjAwIEaJCfzoEYiInco1avrzeXP\nd+3ahbZt2wIALDw3iIrw5JN2zJqVh+vXJXj2WQ0uXuQiLkRErlaq8K5WrRq6dOkCg8GAOnXq4Mcf\nf0TZsmXdXRv5qN69bXj33TykpUkRH6/B5cueroiIyL+U6qpidrsdZ86cQY0aNaBUKpGUlIQqVaqg\nTJkyYtQIgFcV80XvvKPCnDlK1KwJ/Pe/BtSp4/B0SX6Nj2lxsM/iYJ+diruqWKmONs/Ly8OOHTvw\nxRdfQCKRIDo6Gg8//LBLCyT/M3myGSqVgC++UKFzZy2++CKPR6ETEblAqXabT5w4Ebm5uUhISEDf\nvn2RlZWFCRMmuLs28nFSKfD22xasXu1ckW3YMA0mTVLBxvwmInogpRp5Z2Vl4dNPP83/uk2bNhgw\nYIDbiiL/0rs3EBFhxODBanz9tRInTkjxzTd5CA3leqpERPej1Mujmkym/K+NRiPMZrPbiiL/U7Om\nA5s2GdGlixV798oRF6fF0aM8lYyI6H6UauQdHx+Pzp07o169egCA5ORkvPrqq24tjPxPUBDw7bd5\nmDXLgQ8+UOKpp7SYPt2M/v2tni6NiMinlGro06dPHyxbtgw9e/ZEr169sHz5cpw9e9bdtZEfkkiA\nV16xYPly52psr7+uxpgxKnBHDhFR6ZVq5A0AkZGRiIyMzP/6xIkTbimIAkPr1nZs3WrAkCEaLFqk\nRFKSDAsWmFCxIufBiYju5r4nHUtxejhRiapUEbB+vRHx8VYkJsoQF6fFnj1cE52I6G7uO7wlEi57\nSQ9OowFmzszDjBl5yMmR4JlnNPjqKwX43pCIqHgl7jZv1apVkSEtCAKys7PdVhQFFokEeP55K+rW\ntWPoUA0mT1YjMVGGzz7Lg17v6eqIiLxPieG9dOlSseogQpMmDmzbZsR//qPGTz8p8McfUnz3nQnV\nq3MYTkR0qxLDu2LFimLVQQQACA8XsGaNCZMnqzBvnhJxcTp89ZUJHTvaPV0aEZHX4CoZ5HUUCuD9\n982YPdsEmw0YMECL6dOVsDO/iYgAMLzJiz3zjA0//2xElSoOfPqpCv37a3D1qqerIiLyPIY3ebV6\n9RzYutWAtm1t2L5djrg4HZKS+LAlosDGV0HyesHBwJIlJrz+uhnnz0vRtasWq1eXen0hIiK/w/Am\nnyCTAW+9ZcHChUbI5cBLL2kwYYIKVi6LTkQBiOFNPqVTJzu2bDGgdm07vvlGiaef1iA9nQsGEVFg\nYXiTz6lRQ8DGjUY89ZQVBw44Ly966BAfykQUOPiKRz5JrwfmzcvDpEl5yMiQoGdPLb79lsuqElFg\nYHiTz5JIgJdftmLlShPKlBEwdqwar76qhsnk6cqIiNyL4U0+r2VLO7ZuNSI62o7lyxXo3l2Lf//l\nPDgR+S+GN/mFSpUErFtnRL9+Fpw44by86K5dvLwoEfknhjf5DbUa+OwzMz7+OA/Xr0uQkKDBzJlK\nzoMTkd9heJPfGTjQinXrjAgPFzB1qgpDhqiRm+vpqoiIXIfhTX7psccc2LrViObNbfj5ZwU6dtTi\nzz/5cCci/8BXM/JbYWECVq0y4cUXLfjzTxk6dtTi55+5rCoR+T6GN/k1uRx47z0z5s41weEAnn9e\ng/ff5+VFici3MbwpIPTqZcOGDUZUrerAF1+okJCgwZUrnq6KiOj+MLwpYDz6qPPyonFxNvzyi/Py\noidO8ClARL6Hr1wUUMqWBRYtMuHNN824eFGCbt20WL6c8+BE5FsY3hRwpFLgjTcsWLzYBKUSeOUV\nDcaOVcFi8XRlRESlw/CmgBUX57y8aJ06dnz7rRI9e2qRlsZlVYnI+zG8KaBVry5gwwYjevWy4vBh\nGdq31+LAAS6rSkTejeFNAU+nA+bMycOUKXm4fFmC3r01+OwzJcxmT1dGRFQ0hjcRnJcXHT7citWr\nTQgOFjBtmgqtWumwYwdH4UTkfdwa3mfOnEH79u2xePHiO362b98+9OnTB/Hx8Zg9e7Y7yyAqtebN\n7di3z4Bhwyz45x8JEhK0GDxYzUuMEpFXcVt4G41GTJkyBc2aNSvy51OnTsWsWbOwbNky7N27F2fP\nnnVXKUT3pGxZ4P33zdi+3YgnnrBhwwYFYmN1+PRTJfLyPF0dEZEbw1upVGLevHkICwu742f//vsv\nypYti8jISEilUrRq1Qr79+93VylE96VuXQfWrTNh9mwTgoIETJ+uwpNP6rB1K3elE5FnuW11Crlc\nDrm86M1nZmYiJCQk/+uQkBD8+++/JW4vOFgLudy1L5qhoUEu3R4Vz5d7PWIE0L8/MHkyMHOmFP36\nadG9O/D550D16p6urjBf7rMvYZ/FwT4Xz2eWlsrONrp0e6GhQcjMvO7SbVLR/KXX48YBPXtKMW6c\nCuvXy7Fli4BRoywYNcoCjcbT1flPn70d+ywO9tmpuDcwHjnaPCwsDFlZWflfp6enF7l7ncjb1Knj\nwNq1Jsyd6zwq/eOPVWjZUodNm2QQBE9XR0SBwiPhXalSJeTm5uLixYuw2WzYuXMnWrRo4YlSiO6Z\nROK8Stm+fQa8/LIFqakSDByoRb9+Gvz1F49KJyL3kwiCe8YLSUlJmDFjBlJSUiCXyxEeHo62bdui\nUqVKiIuLw6FDh/Dxxx8DADp06IChQ4eWuD1X7z7hLhnx+Huvz5xx7krfvVsOpVLAyJEWvPKKBVqt\nuHX4e5+9BfssDvbZqbjd5m4Lb1djePuuQOi1IADr18vxzjsqpKZKUbmyA++9Z0aXLjZIRBqMB0Kf\nvQH7LA722cmr5ryJ/I1EAjz1lA179hjwyitmpKVJ8PzzGsTHa3DuHHelE5FrMbyJXEivByZMsOCX\nXwxo3dqGXbvkePJJHaZOVcJg8HR1ROQvGN5EbvDwwwJWrDBhwQITwsMFzJypQosWOqxbJ+dR6UT0\nwBjeRG4ikQDdujl3pY8ebUZWlgT/+Y8GffpocOYMn3pEdP/4CkLkZlotMG6cBb/+akC7djbs3i1H\n69ZavPuuCrm5nq6OiHwRw5tIJNWrC1i61ISFC42IihIwe7YSzZvrsHYtd6UT0b1heBOJSCIBOnWy\nY/duA954w4zsbAmGD9fg6ac1OH2aT0ciKh2+WhB5gEYDvPmmBbt3G9Cxow179sjRpo0W77yjwnWe\n2kpEd8HwJvKgqlUFLFpkwpIlRlSqJGDOHCWaNdNh5UruSiei4jG8ibxAXJxzV/rYsWZcuybByy9r\n0KOHBsnJfIoS0Z34ykDkJdRqYMwYC/bsMaBzZysOHJCjfXst3n5bhZwcT1dHRN6E4U3kZapUEfD9\n93lYvtyIhx4SMG+ec1f68uVyOByero6IvAHDm8hLtW1rxy+/GPD222YYjRK88ooG3btrcfIkn7ZE\ngY6vAkReTKUCXn3VuSu9e3crDh2SIS5Oi7feUuHqVU9XR0SewvAm8gGVKgmYPz8PP/xgRPXqDixY\n4NyVvnQpd6UTBSKGN5EPad3ajl27jJg40QyTSYLXXtOga1ctjh/nU5kokPAZT+RjlEpg1CgL9u0z\noGdPK44ckaFDBy0GDQIveEIUIPhMJ/JRUVECvvkmD2vWGPHIIw4sXAjExuowaJAaR47wqU3kz/gM\nJ/JxsbF27NxpxNq1QEyMHRs3KtC5sw69emmwY4eMK7UR+SGGN5EfkEqBnj2BjRuNWLvWiDZtbNi7\nV46EBC3at9fip5/ksNs9XSURuQrDm8iPSCRAixZ2rFhhwvbtzjnx5GQphg3ToFkzHRYuVCAvz9NV\nEtGDYngT+an69R345ps87NtnwIABFqSmSvDGG2o0bqzDrFlKXr2MyIcxvIn8XPXqAj75xIwjRwwY\nOdK5WtuUKSo0aqTH++8rkZEh8XSJRHSPGN5EASI8XMA771iQmJiLt982Q6kU8MUXKjz2mA5vvqnC\n+fMMcSJfwfAmCjBlyzqXXD1yxIAZM/IQHi7gu++UaNpUhxdfVPMypEQ+gM9SogCl0QDPP2/FgQMG\nfP21CbVqObBmjQJt2ujw3HMaHDjA08yIvBXDmyjAyeXA00/bsGuXEUuXGtG0qQ3btsnx1FNadOum\nxebNMq6fTuRlGN5EBMB5mln79nasW2fC+vVGdOxow6FDMgwYoEWbNlqsXCmH1erpKokIYHgTURGe\neMKORYtM+OUXA/r0seLMGSleflmDpk11mD9fAaPR0xUSBTaGNxEVq04dB776Kg+//WbA0KEWZGZK\nMG6cGo89psOnnyp5TXEiD2F4E9FdVakiYNo057nir79uhs0mwfTpznPFJ01S4dIlnmZGJCaGNxGV\nWmiogLfecp4rPnlyHoKCBHz9tRKNG+swerQK584xxInEwPAmonum1wMjRlhx6JABn32Wh8qVBSxZ\nokTz5joMHarGsWN8aSFyJz7DiOi+qVRAv35W7N1rwPz5JjRo4MD69Qp06KBDnz4a/PorzxUncgeG\nNxE9MJkM6N7dhi1bjFi50oiWLW349Vc5+vTRomNHLdav5yVJiVyJ4U1ELiORAK1a2bF6tQmbNxvQ\nrZsVx49LMXSoBrGxOixZooDZ7OkqiXwfw5uI3KJRIwcWLMjDnj1GPPecBRcuSDB6tBpNmujw9dcK\n5OZ6ukIi38XwJiK3qlnTgc8/N+PQIQNefNGCnBwJJk1SIyZGjylTlDxCneg+MLyJSBRRUQLee8+M\nxMRcjB1rhlQqYNYsFZo106NbNw2WLOFonKi0GN5EJKrgYGDMGAsSEw2YM8eEVq2ca6iPHq1GvXp6\njBqlxr59PEqdqCQMbyLyCI0G6N3bhpUrTThyxICxY82oUEHAihUK9OypxRNPOJdgTUnhbnWi2zG8\nicjjKlUSMGaMBQcPGrB2rRF9+1qRnu5cgjUmRoe+fTVYu1aOvDxPV0rkHeSeLoCI6CapFGjRwo4W\nLeyYNg346ScFli5VYNcuOXbtkqNsWQG9e1vx7LNWNGzogISDcgpQHHkTkVcKCgL697diwwYj9u41\nYNQoM1QqAd9+q0SHDjq0bq3FnDkKZGUxwSnwMLyJyOvVrOnAxIkWHDtmwJIlRnTtasXZs1K8844a\nDRroMHiwGps3y2CzebpSInFwtzkR+Qy5HIiLsyMuzo7LlyVYvVqOpUsV2LDB+REa6kDfvjY8+6wV\ntWo5PF0ukdtw5E1EPql8eQEvvGDFzp1GbNtmwNChFlitEsyerURsrA6dO2uxcKEC1655ulIi12N4\nE5FPk0iABg0cmDbNjBMncjFvnglt2thw9KgUb7yhRv36eowYocbu3TI4OBgnP8HwJiK/oVYDPXrY\nsGKFCYmJBowfb0ZEhIBVqxR4+mktmjTR4aOPlLhwgQe5kW+TCIL71jH64IMPcPz4cUgkEowfPx4N\nGjTI/9mSJUuwbt06SKVS1KtXD2+//XaJ28rMvO7S2kJDg1y+TSoaey0O9rloggD89psMy5Yp8NNP\nchiNzuBu2dI5N961qw0aTem3xz6Lg312Cg0NKvL7bjtg7eDBgzh//jxWrFiBc+fOYfz48VixYgUA\nIDc3F/Pnz8eWLVsgl8sxZMgQHDt2DNHR0e4qh4gClEQCNG1qR9Omdrz/PrB+vfMgt9275di9W46g\nIAG9ejnPHY+J4bnj5Bvcttt8//79aN++PQCgRo0ayMnJQe6Nqw4oFAooFAoYjUbYbDaYTCaULVvW\nXaUQEQEA9Hrg2WdtWL/ehAMHcvHaa2bo9QIWLlSic2cdnnxSi9mzFcjIYIKTd3NbeGdlZSE4ODj/\n65CQEGRmZgIAVCoVXn75ZbRv3x5t2rRBw4YNUa1aNXeVQkR0h+rVBYwfb8HRowYsX25Ejx5W/P23\nFO++q0bDhjoMHKjGhg1yWK2erpToTqKd533r1Hpubi7mzp2LTZs2Qa/XY9CgQTh9+jQeeeSRYn8/\nOFgLuVzm0pqKm0sg12OvxcE+35/4eOfHlSvA0qXAt99KsGmTAps2KRAaCgwYADz/PFCvnvP+7LM4\n2OfiuS28w8LCkJWVlf91RkYGQkNDAQDnzp1D5cqVERISAgBo3LgxkpKSSgzv7GyjS+vjwRDiYa/F\nwT67xs0gT0qSYvlyBVatkuPTT6X49FMgOtqOIUNkaNkyFxUr8pql7sTHs1Nxb2Dcttu8RYsW2Lx5\nMwAgOTkZYWFh0Ov1AICKFSvi3LlzyLtxiaCkpCRUrVrVXaUQEd2zevUcmDrVjBMnDJg/34S4OBtO\nnJDilVeARo30aN9ei48/ViI5Wcprj5Po3Hqq2Mcff4zDhw9DIpFg0qRJOHXqFIKCghAXF4fly5dj\nzZo1kMlkaNSoEd58880St8VTxXwXey0O9tn90tMl2L1bjx9+sGHvXhmsVueBbVWqONC5sw2dOtnw\nxBN2yLnw9APj49mpuJG3W8PblRjevou9Fgf7LI6bfb52Ddi+XY6NG+XYtk2O3FxnkAcHC4iLs6Fz\nZxtat7ZBp/NwwT6Kj2cnhvdt+MAQD3stDvZZHEX12WwG9u6VYdMmOTZtkiMtzTkjqVYLaNXKjk6d\nbOjQwYbQUJ94ufUKfDw7MbxvwweGeNhrcbDP4rhbnx0O4PhxKTZudAb56dPOs2QkEgGPP25H587O\nUXn16j7x0usxfDw7MbxvwweGeNhrcbDP4rjXPv/1lwSbNjl3rx88KIMgOHev167tHJF37mxDdLQD\nUl5pohA+np0Y3rfhA0M87LU42GdxPEifMzMl2LrVuXt91y458vKcQR4e7sgP8hYt7FCpXFmxb+Lj\n2YnhfRs+MMTDXouDfRaHq/psMAC//OIckW/dKsOVK86ht14voF07Z5C3a2dDoK4czcezk+gXJiEi\nouLpdECXLjZ06WKDzQYcPCjDxo3OMP/pJwV++kkBuVxAixYFu9ejonxirEUi4Mib3I69Fgf7LA53\n91kQgN9/Lzjg7fjxgmWhGza0559PXqeOf18BjY9nJ+42vw0fGOJhr8XBPotD7D6npBQc8LZvnww2\nmzOxH3rIOU/epYsNjz/ufwvD8PHsxPC+DR8Y4mGvxcE+i8OTfc7JAbZtc47It22Tw2BwBnlIiAMd\nOjh3r7dubYNW65HyXIqPZyeG9234wBAPey0O9lkc3tLnmwvDbNggx+bNcqSnOw9402gEtGrlnCOP\ni7OjQgWfeIm/g7f02dMY3rfhA0M87LU42GdxeGOfHQ4gMVGav3v9zBnnPLlUKqBJEzvi4uyIjbWh\nfn2Hz+xe98Y+ewKPNici8lNSKfDYYw489pgFb79twblzkvwD3n77TYYDB+QAVNDrBTRtakezZna0\naGFDgwa+E+ZUGEfe5HbstTjYZ3H4Wp8zMiTYs0eGvXtl2LdPjnPnCpZy0+nuDHOFwoPF3sLX+uwu\nHHkTEQWgsDABvXvb0Lu3DYAZaWkS7Nsny//Yvl2O7dudI3OdTsATT9jRvLkdzZvb0LCh94Q5Fcbw\nJiIKIBERt4a58xrlt4b5jh1y7NjhDHOttnCYR0czzL0Fw5uIKICFhwvo1cuGXr0KwvzAgZu72WXY\nuVOOnTsLwrxJk8JhrlR6tv5AxfAmIqJ84eECevSwoUcPZ5hnZBQO8127nBdVuRnmjz9uR4sWznnz\nRo3sDHORMLyJiKhYYWECnnrKhqeecoZ5ZmbhMP/lFzl++cUZJRpN4TCPiWGYuwvDm4iISi00VED3\n7jZ07+4M86wsCfbvL5gz//VXOX79tSDMGzd2hnnz5s6ROS936hoMbyIium8VKhQO88uXC8J8714Z\ndu+WY/duZ9So1c6RuXPO3DkyZ5jfH4Y3ERG5TPnyArp1s6Fbt4IwP3Cg+DBv3LhwmKvVnqzedzC8\niYjIbcqXF9C1qw1duzrD/MoV4MABeX6Y790rw549zihSqQrCvFMnoHJloFw5T1bvvbjCGrkdey0O\n9lkc7LNrZWcXhPm+fTIkJUkhCAUXKq9SxYF69eyoX9+B+vWdtxERgl9fy/xWvDDJbfgEFA97LQ72\nWRzss3tdvQocOCDDqVNa/PabDSdPSpGVJS10nwoVHKhXr3CoV68uQCotZqM+jMujEhGR1ytXDujU\nyY4BA4DMTBMEwblwzMmTUpw8Kcu/LTjf3EmrFVC3bsHovH59O2rXdvjtAXEMbyIi8loSiXNJ14gI\n56VNb8rJAZKSCsI8KUmKo0elOHRIln8fhUJArVqOQrvc69a1I6jowaxPYXgTEZHPKVsWaNHCeQ45\nYAUAmEzA6dMFI/SkJBlOnZIiOVmG5csLFmWvVq3wCL1ePQfCwnxiBjkfw5uIiPyCRgM0auRAo0aO\n/O/ZbMC5c9JCI/STJ2VYt06BdesKfjc83FEozOvXt+Ohh7z3wDiGNxER+S25HKhd24HatR3o08d5\nupogABcvSgqN0E+elGLbNjm2bSuIxTJlhPyD4m7e1qzpHVdWY3gTEVFAkUiAypUFVK5sQ5cuBd+/\nfFly2whdemO1uIKoVKkE1KlTeIT+6KMOaLXi/hsY3kRERHAuKNO6tR2tWxccGJebC5w6VXiX+6lT\nUhw7VnBgnFQqoEYNB2Jj7Zg61SzKyJzhTUREVAy9HmjSxIEmTQrm0a1W4I8/pPlhfnPX+w8/SPHW\nW2YEB7u/LoY3ERHRPVAocGORGAcSEpzz6A6H8+A4sS6B6ofr0RAREYlLKhUvuAGGNxERkc9heBMR\nEfkYhjcREZGPYXgTERH5GIY3ERGRj2F4ExER+RiGNxERkY9heBMREfkYhjcREZGPYXgTERH5GIY3\nERGRj5EIgiB4uggiIiIqPY68iYiIfAzDm4iIyMcwvImIiHwMw5uIiMjHMLyJiIh8DMObiIjIxwRk\neH/wwQeIj49HQkICTpw44ely/NaHH36I+Ph4PP3009iyZYuny/FreXl5aN++PdasWePpUvzaunXr\n8NRTT6F3797YtWuXp8vxSwaDASNHjsSAAQOQkJCA3bt3e7okryT3dAFiO3jwIM6fP48VK1bg3Llz\nGD9+PFasWOHpsvzOgQMH8Oeff2LFihXIzs5Gr1690KFDB0+X5be+/vprlC1b1tNl+LXs7GzMnj0b\nq1evhtFoxKxZs9C6dWtPl+V31q5di2rVqmHMmDFIT0/HoEGDsGnTJk+X5XUCLrz379+P9u3bAwBq\n1KiBnJwc5ObmQq/Xe7gy//L444+jQYMGAIAyZcrAZDLBbrdDJpN5uDL/c+7cOZw9e5ZB4mb79+9H\ns2bNoNfrodfrMWXKFE+X5JeCg4Pxxx9/AACuXbuG4OBgD1fknQJut3lWVlahB0NISAgyMzM9WJF/\nkslk0Gq1AIBVq1bhySefZHC7yYwZM/DWW295ugy/d/HiReTl5eHFF1/Ec889h/3793u6JL/UtWtX\npKamIi4uDv3798fYsWM9XZJXCriR9+24Oqx7bdu2DatWrcKCBQs8XYpf+vHHHxEdHY3KlSt7upSA\ncPXqVXz55ZdITU3FwIEDsXPnTkgkEk+X5Vd++uknREVFYf78+Th9+jTGjx/PYzmKEHDhHRYWhqys\nrPyvMzIyEBoa6sGK/Nfu3bsxZ84c/Pe//0VQUJCny/FLu3btwr///otdu3YhLS0NSqUSERERaN68\nuadL8zvly5dHo0aNIJfLUaVKFeh0Oly5cgXly5f3dGl+5ejRo4iNjQUAPPLII8jIyOCUWxECbrd5\nixYtsHnzZgBAcnIywsLCON/tBtevX8eHH36IuXPnoly5cp4ux299/vnnWL16NX744Qc888wzGDFi\nBIPbTWJjY3HgwAE4HA5kZ2fDaDRyPtYNHnroIRw/fhwAkJKSAp1Ox+AuQsCNvGNiYlC3bl0kJCRA\nIpFg0qRJni7JL23YsAHZ2dl47bXX8r83Y8YMREVFebAqovsXHh6Ojh07om/fvgCACRMmQCoNuPGP\n28XHx2P8+PHo378/bDYbJk+e7OmSvBIvCUpERORj+LaRiIjIxzC8iYiIfAzDm4iIyMcwvImIiHwM\nw5uIiMjHMLyJ/FDt2rVhs9kAOFescpX169fD4XAAAAYMGAC73e6ybRNR6TG8ifyY3W7HV1995bLt\nzZo1Kz+8Fy1axMUziDwk4BZpIQok48ePR0pKCoYMGYIFCxZgw4YNWLx4MQRBQEhICKZOnYrg4GDE\nxMSgT58+cDgcGD9+PCZNmoS//voLFosFDRs2xIQJEzBz5kycP38egwcPxpdffoknnngCycnJsFgs\nmDhxItLS0mCz2dCjRw8899xzWLNmDfbt2weHw4G///4bFStWxKxZs7gWOJErCETkd2rVqiVYrVbh\n33//FVq2bCkIgiCkpqYK3bt3F8xmsyAIgvDdd98J06ZNEwRBEGrXri3s2bNHEARBuHLlirBo0aL8\nbXXs2FH4448/Cm331s/nzJkjTJ48WRAEQTCZTEKbNm2ECxcuCKtXrxbatm0rmEwmweFwCO3atROS\nk5PFaQCRn+PImyhAJCYmIjMzE0OHDgUAWCwWVKpUCYDz6noxMTEAnNdfv3TpEuLj46FUKpGZmYns\n7Oxit3v8+HH07t0bAKBWq1GvXj0kJycDABo0aAC1Wg0AiIyMRE5Ojtv+fUSBhOFNFCCUSiUaNGiA\nuXPnFvlzhUIBAPj5559x8uRJLFmyBHK5PD+Yi3P7bnBBEPK/d/ucuMDVmIlcggesEfkxqVSaf9R5\n/fr1ceLECWRmZgIANm7ciG3btt3xO5cvX0a1atUgl8uRlJSECxcuwGKxAHAG9c3t3dSwYUPs3r0b\nAGA0GpGcnIy6deu6859FFPAY3kR+LCwsDBUqVEDv3r0RFBSEt99+G8OHD0e/fv2watUqREdH3/E7\nnTp1wrFjx9C/f39s2bIFQ4YMwdSpU5GTk4OWLVvi6aefxoULF/LvP2DAABgMBvTr1w+DBg3CiBEj\n8nfHE5F78KpiREREPu+6Iq0AAAA7SURBVIYjbyIiIh/D8CYiIvIxDG8iIiIfw/AmIiLyMQxvIiIi\nH8PwJiIi8jEMbyIiIh/D8CYiIvIx/w/YkvjF85lCNQAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}