{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CarRacing in colab.ipynb","version":"0.3.2","provenance":[{"file_id":"1Cq7hRaX30AEAVmoYbRpmtIKw9wzbAXYz","timestamp":1555875489733},{"file_id":"1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t","timestamp":1554917601484},{"file_id":"1A75J2xFYjpJvNWXCSM1Xcty7K3WIGrud","timestamp":1542848369662}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"odNaDE1zyrL2","colab_type":"text"},"cell_type":"markdown","source":["# Install dependancies\n","\n","Dacă ceva nu merge, renunțați la `> /dev/null` pentru a vă asigura că instalarea a mers blană.\n"]},{"metadata":{"id":"8-AxnvAVyzQQ","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install gym pyvirtualdisplay > /dev/null 2>&1\n","!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TCelFzWY9MBI","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get update > /dev/null 2>&1\n","!apt-get install cmake > /dev/null 2>&1\n","!pip install --upgrade setuptools 2>&1\n","!pip install ez_setup > /dev/null 2>&1\n","!pip install gym[atari] > /dev/null 2>&1\n","!pip install box2d-py > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"APXSx7hg19TH","colab_type":"text"},"cell_type":"markdown","source":["# Imports and Helper functions\n"]},{"metadata":{"id":"pdb2JwZy4jGj","colab_type":"code","colab":{}},"cell_type":"code","source":["import gym\n","from gym import logger as gymlogger\n","from gym.wrappers import Monitor\n","gymlogger.set_level(40) #error only\n","import tensorflow as tf\n","import numpy as np\n","import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import math\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","\n","from IPython import display as ipythondisplay\n","\n","import gym\n","from gym import logger as gymlogger\n","from gym.wrappers import Monitor\n","gymlogger.set_level(40) #error only\n","import tensorflow as tf\n","import numpy as np\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import random\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import math\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","from pyvirtualdisplay import Display"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nQEtc28G4niA","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1400, 900))\n","display.start()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G9UWeToN4r7D","colab_type":"code","colab":{}},"cell_type":"code","source":["# Luat de aici: https://star-ai.github.io/Rendering-OpenAi-Gym-in-Colaboratory/\n","\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else: \n","    print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","  env = Monitor(env, './video', force=True)\n","  return env"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W3BGbWOu179M","colab_type":"text"},"cell_type":"markdown","source":["# CarRacing - vizualizare"]},{"metadata":{"id":"7BmIlXhe9Q89","colab_type":"code","colab":{}},"cell_type":"code","source":["env = wrap_env(gym.make(\"CarRacing-v0\"))\n","observation = env.reset()\n","\n","while True:\n","    env.render()\n","    action = env.action_space.sample() \n","    observation, reward, done, info = env.step(action) \n","           \n","    if done: \n","        break;\n","env.close()\n","\n","show_video()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-tyAcww0hlAX","colab_type":"text"},"cell_type":"markdown","source":["# CarRacing - fără vizualizare"]},{"metadata":{"id":"8nj5sjsk15IT","colab_type":"code","colab":{}},"cell_type":"code","source":["env = wrap_env(gym.make(\"CarRacing-v0\"))\n","env.action_space = [[1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, 0, 0.8]]\n","NR_ACTIONS = len(env.action_space)\n","env.reset()\n","print(obs.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aNSMHP1QfMXC","colab_type":"code","colab":{}},"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fr10a3VlbqMH","colab_type":"code","colab":{}},"cell_type":"code","source":["Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","\n","class ReplayMemory(object):\n","\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        \"\"\"Saves a transition.\"\"\"\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YtfEBY_HbrL0","colab_type":"code","colab":{}},"cell_type":"code","source":["class DQN(nn.Module):\n","\n","    def __init__(self, h, w, outputs):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        # Number of Linear input connections depends on output of conv2d layers\n","        # and therefore the input image size, so compute it.\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 32\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w8v82JGqHR01","colab_type":"code","colab":{}},"cell_type":"code","source":["resize = T.Compose([T.ToPILImage(),\n","                    T.Resize((96, 96), interpolation=Image.CUBIC), # TODO adjust sizes\n","                    T.ToTensor()])\n","\n","def get_screen():\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    \n","    # Resize, and add a batch dimension (BCHW)\n","    return resize(screen).unsqueeze(0).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xBvmjLDEbu6J","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 128\n","GAMMA = 0.999\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 200\n","TARGET_UPDATE = 10\n","\n","# Get screen size so that we can initialize layers correctly based on shape\n","# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n","# which is the result of a clamped and down-scaled render buffer in get_screen()\n","env.reset()\n","init_screen = get_screen()\n","_, _, screen_height, screen_width = init_screen.shape\n","\n","# Get number of actions from gym action space\n","n_actions = env.action_space.n\n","\n","policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.RMSprop(policy_net.parameters())\n","memory = ReplayMemory(10000)\n","\n","\n","steps_done = 0\n","\n","\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            # t.max(1) will return largest column value of each row.\n","            # second column on max result is index of where max element was\n","            # found, so we pick action with the larger expected reward.\n","            return policy_net(state).max(1)[1].view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n","\n","\n","episode_durations = []"],"execution_count":0,"outputs":[]}]}